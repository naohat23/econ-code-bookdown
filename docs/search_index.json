[["index.html", "エコノミストのためのR はじめに 目次 参考文献・ウェブサイト", " エコノミストのためのR 服部直樹 2022-06-27 はじめに 本書は、エコノミストがRを使用して経済・金融データ分析を行うための方法をまとめたものです。 Rによるプログラミング、データ分析、計量経済学について解説した書籍は、世の中に沢山あります。しかし、エコノミストがよく使用するコードや分析方法を体系的に整理し、いつでも・どこからでもコードにアクセスできるようにしたサービスはまだ無かったので、本書を作成しました。 なお、本書のソースコードはGitHubリポジトリで管理しています。改善点があれば、イシューやプルリクエストでお知らせいただければ幸いです。 なぜRを使うのか？ データ分析を行うことができるソフトウェアは、R以外にも、EViews、Stata、Pythonといった選択肢があります。では、なぜRを使用するのでしょうか。 無料： Rは無料で使用することができます。オフィスでも、自宅でも、所属組織が変わっても同じソフトウェアを使って作業することができるため、わざわざ違うソフトウェアの使用方法を新たに覚える必要がありません。また、無料で誰でも使えるということは、世界中に多くのユーザーがいて、書籍やオンラインに情報が沢山あるということでもあります。本書もその一つです。 豊富なパッケージ： Rはデータ分析を行うための追加パッケージが大量に開発されており、用途に応じてパッケージをインストールすることで、様々なデータ分析手法を使用することが可能です。オーソドックスな計量経済分析はもちろん、機械学習、自然言語処理、地理データ分析など、Rで実施可能な分析は多岐にわたります。 データ分析に特化： RとPythonはよく比較されますが、Pythonが汎用プログラミング言語である一方、Rはデータ分析に特化しているという違いがあります。特に、Rの統合開発環境であるRStudioは、コードの記述と実行に加え、変数の内容を一覧表示したり、グラフをプロットしたり、ディレクトリやヘルプを表示したり、といった分析を補助する機能を一つの画面で操作することができ、ストレスなく作業できます。データ分析を行うのであれば、まずRを選択すべきでしょう。一方、高度な深層学習を行ったり、分析した結果を用いてアプリケーションを作成したりするのであれば、Pythonが向いているといえます。 直感的なデータ操作： Rのパッケージの一つであるtidyverseでは、直感的かつ効率的なデータ操作（データハンドリング）を行うことができます。データセットを読み込んだ後、変数の選択、フィルタ、集計、統合、新たな変数の計算、異常値の処理といった前処理をシームレスに実施し、そのまま図表作成や分析に進むことができます。また、データセットの読み込みも、ローカルからの読み込み、ウェブからのを問わず容易に行うことができます。 強力なグラフ作成機能： Rのggplot2パッケージは強力なグラフ作成機能をもち、折れ線グラフ、棒グラフ、散布図といったおなじみのグラフだけでなく、ヒートマップ、QQプロット、ステップグラフ、ドットプロット、箱ひげ図、ヴァイオリングラフ、ジッターグラフ、複合グラフ（ファセット）などの高度なグラフを作成することができます。グラフは日本語表記にも対応しており、フォーマットを設定すれば、そのままレポートにも使用可能です。 本書で出来ること エコノミストがRを使用してデータ分析を行う方法を、順序だてて学ぶことができます。 Rの設定、Rの演算やオブジェクトの取り扱い方といった基本的な使用方法、tidyverseパッケージを使ってデータを自由に操作する方法、季節調整やトレンドなどの時系列データ特有の処理、ggplot2パッケージを使ったグラフ作成、データの分析方針を立てるための探索的データ分析（EDA）、計量経済学の基礎である線形単回帰・重回帰について解説しています。 すべてRのコードを記載していますので、自分の環境で結果を再現することが可能です。 今後、マクロ計量経済学ではベクトル自己回帰（VAR）モデル、ミクロ計量経済学ではパネルデータ分析、操作変数法、統計的因果推論のトピックについて追加する予定です。 本書で出来ないこと 本書はデータ分析の手法とコードの解説を主な目的にしており、その背景にある数学的な解説は行っていません。数学的な解説が必要な場合は、参考文献を参照してください。また、データ分析の手法について、エコノミストが日常業務で使用することが比較的少ない機械学習、深層学習、自然言語処理の手法は、現時点では取り上げていません。 目次 Rの設定 Rを使用するにあたり、まず必要な環境構築を行います。RとRStudioのインストール、バージョン確認、Rの機能を拡張するパッケージのインストールとインポート、グラフ作成の事前設定に加え、本書で使用するサンプルデータセットを紹介します。また、オフィスや大学などのプロキシ環境下でRを使用する際に必要なプロキシ設定についても解説します。 Rの基本的な使用方法 Rで作業を始める前に、プログラミング言語としてのRの基本的な使用方法を簡単に紹介します。プログラムの実行方法、ショートカットキー、演算方法、ベクトル・行列・データフレーム・リストなど各種データの取り扱い方法、if文やforループなどの制御構文、データの読み込み・書き出し方法、オブジェクトのセーブ・ロード方法について解説します。この章をまず一読したうえで次章以降へ進み、後から必要に応じてリファレンス的に使用するのが良いでしょう。 tidyverseによるデータ操作 Rで直感的なデータ操作用を行うパッケージであるtidyverseの使用方法を紹介します。変数選択や各種条件によるフィルタ、並べ替えなどの基本的な操作に加え、新たな変数の作成、集計、重複処理、欠損地処理、補完処理、サンプリング、縦型・横型の変換といったデータ前処理の手法についても解説します。読み込んだデータを分析に「使える」ようにするために必須の内容です。 時系列データ操作 経済・金融分析に欠かせない時系列データの操作方法を紹介します。ラグ・リード系列や変化率系列の計算方法、頻度変換、季節調整（X13、STL分解）、トレンド推定（HPフィルタ、一般化加法モデル）などのトピックを取り上げています。 ggplot2によるグラフ作成 ggplot2パッケージを主に使用したグラフ作成方法について記載しています。最初に、GUI形式でどのようなグラフを作成するか検討する方法を紹介したうえで、ggplot2によるコード記述形式のグラフ作成方法を解説します。取り上げるグラフは、1次元・2次元の度数分布、密度グラフ、ヒストグラム、QQプロット、散布図、バブルチャート、棒グラフ、円グラフ、折れ線グラフ、ステップグラフ、面グラフ、箱ひげ図（ボックスプロット）、ヴァイオリングラフ、ジッターグラフ、ドットプロット、複合グラフ（ファセット）など、多岐にわたります。また、散布図や折れ線グラフに系列名などのテキストアノテーションを行う方法、グラフの見栄えを整える上で欠かせない色、軸、凡例、フォントなどの設定方法についても紹介しています。、 探索的データ分析（EDA） 本格的なデータ分析の方針を立てるために必要な、探索的データ分析（EDA）の方法を紹介します。具体的には、データの中身や分布、変数間の関係性・相関を一括して確認する方法について解説します。EDAは軽視されがちですが、極めて重要なプロセスであり、データ分析の成否はEDAが決めるといっても過言ではありません。 線形回帰 計量経済分析の最も基本的な手法である線形回帰の内容と、Rによる実行方法を紹介します。まず、前提として、統計学・計量経済学で使用される基本的な用語を説明します。次に、線形回帰の推定方法である最小2乗法と、統計的仮説検定について解説したうえで、実務で頻繁に用いる水準モデル、対数モデル、変化率モデル、多項式モデル、交互作用モデル、ダミー変数モデルについて、それぞれの内容と係数の解釈方法を説明します。この部分は、なるべく直感的に理解できるような説明を心がけました。最後に、それらのモデルをRで推定する方法を、西山 他（2019）の実証例を解く形で紹介します。 ベクトル自己回帰モデル 現在作成中です。 パネルデータ分析 現在作成中です。 統計的因果推論 現在作成中です。 参考文献・ウェブサイト Rプログラミング・データ分析 入門・初級 馬場真哉 (2020) 『R言語ではじめるプログラミングとデータ分析』ソシム株式会社 松村優哉・湯谷啓明・紀ノ定保礼・前田和寛 (2021) 『改訂2版 Rユーザのための RStudio［実践］入門』技術評論社 中級 Wickham, H., and Grolemund, G. (2017) 『Rではじめるデータサイエンス』オライリー・ジャパン Wickham and Grolemund (2017) の原著版 “R for Data Science”は、こちらのウェブサイトで全文閲覧できます。 計量経済学 入門・初級 山本勲 (2015) 『実証分析のための計量経済学ー正しい手法と結果の読み方ー』中央経済社 中級 Hanck, C., Arnold, M., Gerber, A., and Schmelzer, M., (2021) “Introduction to Econometrics with R” Hyndman, R.J., and Athanasopoulos, G. (2018) “Forecasting: principles and practice, 2nd edition”, OTexts: Melbourne, Australia. Sax, C., and Eddelbuettel, D., (2018) “Seasonal Adjustment by X-13ARIMA-SEATS in R” 奥本佳伸 (2016) 「季節調整法プログラム センサス局法X-13ARIMA-SEATSを日本のいくつかの経済統計データに適用した結果とその検討」千葉大学『経済研究』第30巻第4号 西山慶彦・新谷元嗣・川口大司・奥井亮 (2019) 『計量経済学』有斐閣 西山 他 (2019) の実証例のRコードは、北川梨津 (2020) 「西山 他『計量経済学』のためのR」が提供しています。 マクリン謙一郎 (2022) 「再現性問題における統計学の役割と責任」日本評論社『経済セミナー』2022年6・7月号 通巻 726号 上級 末石直也 (2015) 『計量経済学ーミクロデータ分析へのいざないー』日本評論社 村尾博 (2019) 『Rで学ぶVAR実証分析ー時系列分析の基礎から予測までー』オーム社 "],["rの設定.html", "1 Rの設定 1.1 設定全般 1.2 プロキシサーバーの設定 1.3 パッケージ 1.4 グラフの設定 1.5 サンプルデータセット 1.6 R起動時に実行する設定", " 1 Rの設定 第1章「Rの設定」では、Rを使用する際の各種設定について解説します。Rのインストール、プロキシサーバーの設定、パッケージのインストール・インポート、グラフの設定など、Rの使用に欠かせない様々な設定について記載しています。 また、本書で使用するサンプルデータセットも、この章で紹介しています。特に、ウェブから読み込む外部データセットについては、この章で取得方法を記載していますので、確認してください。 この章の最後に、Rを起動時に実行すべき設定をまとめています。実際にRを使用する際にご利用ください。 1.1 設定全般 Rのインストール RはThe Comprehensive R Archive Networkからダウンロードしてインストールしてください。2020年にバージョン4へメジャーアップデートが行われており、本書でもバージョン4を使用しています。 Rの統合開発環境であるRStudioは、開発元のrstudio.comからインストールできます。上部メニューのDOWNLOADからダウンロードページに進み、RStudio DesktopのFree版をダウンロードしてインストールしてください。 Windows環境でRの一部のパッケージを使用する際、Rtoolsというツールが必要な場合がありますので、こちらのウェブサイトからRのバージョンに合ったものをダウンロードしてインストールします。 Rのバージョン確認 Rのバージョン情報を出力します。 version ## _ ## platform x86_64-w64-mingw32 ## arch x86_64 ## os mingw32 ## system x86_64, mingw32 ## status ## major 4 ## minor 1.3 ## year 2022 ## month 03 ## day 10 ## svn rev 81868 ## language R ## version.string R version 4.1.3 (2022-03-10) ## nickname One Push-Up セッション情報の確認 Rのバージョンに加え、使用環境、パッケージ情報を出力します。 sessionInfo() ## R version 4.1.3 (2022-03-10) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19044) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.932 LC_CTYPE=Japanese_Japan.932 ## [3] LC_MONETARY=Japanese_Japan.932 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.932 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.26 digest_0.6.29 R6_2.5.1 jsonlite_1.8.0 ## [5] magrittr_2.0.3 evaluate_0.15 stringi_1.7.6 rlang_1.0.2 ## [9] cli_3.2.0 rstudioapi_0.13 jquerylib_0.1.4 bslib_0.3.1 ## [13] rmarkdown_2.13 tools_4.1.3 stringr_1.4.0 xfun_0.30 ## [17] yaml_2.3.5 fastmap_1.1.0 compiler_4.1.3 htmltools_0.5.2 ## [21] knitr_1.38 sass_0.4.1 オブジェクトを全削除 変数をすべて削除してワークスペースを初期化します。 rm(list = ls()) 警告の非表示 Rが出力する警告（Warning）を非表示にします。 options(warn = -1) 関数が出力する警告やメッセージの非表示 関数が出力する警告やメッセージはoptions(warn = -1)で非表示にできないため、関数毎に、必要に応じてsuppressWarnings()関数やsuppressMessages()関数を使用します。 suppressWarnings(警告を出力する関数) suppressMessages(メッセージを出力する関数) 1.2 プロキシサーバーの設定 オフィスや大学などのプロキシ環境ではプロキシサーバーの設定を行ってください。なお、下記のコードは認証プロキシには非対応です。 # プロキシサーバーとポートを記入 proxy_url &lt;- &quot;http://proxyserver:port/&quot; # Rのシステム環境変数を設定 Sys.setenv(&quot;http_proxy&quot; = proxy_url) Sys.setenv(&quot;https_proxy&quot; = proxy_url) # Rのダウンロードオプションを設定 options(download.file.method = &quot;libcurl&quot;) options(timeout = NA) 1.3 パッケージ 使用するパッケージ一覧 tidyverse系 lubridate：日付処理 magrittr：パイプ処理 tidyverse：モダンなデータ分析用パッケージセット readxl：Excelファイルの読み込み 図表系 esquisse：shinyを使用したGUI形式の直感的な図表作成 geofacet：地図形式の複合グラフ（ファセット）配置 ggplotgui：shinyを使用したGUI形式の直感的な図表作成 ggpubr：論文形式の図表作成 ggsci：科学系論文の雑誌別カラーパレット ggrepel：散布図のラベル付与 hexbin：geom_hex()関数を使用するために必要なパッケージ lemon：複合グラフ（ファセット）の軸・目盛り表示 RColorBrewer：カラーパレット 統計系 corrplot：相関係数行列の計算・可視化 corrr：相関係数行列の計算・可視化 DataExplorer：探索的データ分析の一括実行 estimatr：線形回帰モデルの推定 fpp2：時系列データ予測の教科書用に開発されたパッケージ GGally：ペアプロットなどのデータ可視化 mFilter：HPフィルタ mgcv：一般化加法モデル（GAM） plm：パネルデータモデル psych：心理統計パッケージ seasonal：コマンド形式の季節調整 seasonalview：GUI形式の季節調整 sigmoid：シグモイド関数 SmartEDA：探索的データ分析の一括実行 tidyquant：金融時系列データ分析 その他 openxlsx：Excelのxlsxファイルの読み込み・編集・書き出し pblapply：プログレスバーを表示するapply()関数ファミリー パッケージのインストールとインポート パッケージのインストールはinstall.packages()関数、インストールしたパッケージのインポート（呼び出し）はlibrary()関数で実行します。一度インストールすれば、その後はインポートするだけでパッケージを使用することができます。 # パッケージ一覧 packages &lt;- c( &quot;lubridate&quot;, &quot;magrittr&quot;, &quot;tidyverse&quot;, &quot;readxl&quot;, &quot;esquisse&quot;, &quot;geofacet&quot;, &quot;ggplotgui&quot;, &quot;ggpubr&quot;, &quot;ggsci&quot;, &quot;ggrepel&quot;, &quot;hexbin&quot;, &quot;lemon&quot;, &quot;RColorBrewer&quot;, &quot;corrplot&quot;, &quot;corrr&quot;, &quot;DataExplorer&quot;, &quot;estimatr&quot;, &quot;fpp2&quot;, &quot;GGally&quot;, &quot;mFilter&quot;, &quot;mgcv&quot;, &quot;plm&quot;, &quot;psych&quot;, &quot;seasonal&quot;, &quot;seasonalview&quot;, &quot;sigmoid&quot;, &quot;SmartEDA&quot;, &quot;tidyquant&quot;, &quot;openxlsx&quot;, &quot;pbapply&quot; ) # インストールしていないパッケージがあればインストール new_packages &lt;- packages[!(packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new_packages)) { install.packages(new_packages) } # パッケージをインポート for (pkg in packages) { library(pkg, character.only = TRUE) } # 変数を削除 rm( new_packages, packages, pkg ) Rのパッケージは開発者が随時アップデートしていますが、自動で反映されることはありません。パッケージをアップデートする場合は、次のコードを実行してください。 # パッケージをすべてアップデート update.packages() # アップデートの対象になる古いバージョンのパッケージ一覧を出力 old.packages() # パッケージを指定してアップデート install.packages(&quot;tidyverse&quot;) 1.4 グラフの設定 レポートやスライドに掲載するためのグラフは、主にRのggplot2パッケージで作成します。 グラフのテーマ設定 本書では、実務上Excelと併用することを想定しているため、Excelで出力されるグラフに似たテーマであるtheme_light()を設定します。ggplot2パッケージにデフォルトで用意されている様々なテーマについては、公式ウェブサイトを参照してください。 theme_set(theme_light()) グラフのフォント設定 Windows上でRを使用する場合は、日本語フォントをグラフ上で表示するために以下の設定が必要です。ここでは代表的なフォントとしてMeiryo UIとYu Gothic UIを設定します。それぞれのフォントにMEIRYO、YUGOというキーを割り当て、ggplot2パッケージでグラフを作成する際にキーを指定します。 windowsFonts(&quot;MEIRYO&quot; = windowsFont(&quot;Meiryo UI&quot;)) windowsFonts(&quot;YUGO&quot; = windowsFont(&quot;Yu Gothic UI&quot;)) 1.5 サンプルデータセット 本書で使用するサンプルデータセットの一覧です。Rの本体もしくはパッケージから呼び出せるデータセットと、ウェブから取得する外部データセットがあります。 Rのサンプルデータセット Rのサンプルデータセットは、help(データセット名)を実行するとヘルプ画面で詳細を確認できます。 unemp seasonalパッケージに含まれるunempデータセットは、1990年1月から2016年11月までの米国の失業者数（単位：千人）の月次データ（原数値）です。データ形式はts型です。 データ出所リンク seasonal::unemp ## Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## 1990 7413 7296 6852 6620 6533 6884 7137 7008 7003 6892 7396 7525 ## 1991 8787 9121 8995 8226 8435 8992 8792 8439 8270 8232 8494 8755 ## 1992 10186 10401 9913 9135 9389 10366 10099 9605 9316 8813 9086 9045 ## 1993 10158 10004 9478 8835 8807 9473 9223 8655 8302 8296 8094 7959 ## 1994 9492 9262 8874 8078 7656 8251 8281 7868 7379 7155 6973 6690 ## 1995 8101 7685 7480 7378 7185 7727 7892 7457 7167 6884 7024 6872 ## 1996 8270 7858 7700 7124 7166 7377 7693 6868 6700 6577 6816 6680 ## 1997 7933 7647 7399 6551 6398 7094 6981 6594 6403 5995 5914 5957 ## 1998 7069 6804 6816 5643 5764 6534 6567 6173 6039 5831 5711 5565 ## 1999 6604 6563 6119 5688 5507 6271 6319 5826 5661 5372 5380 5245 ## 2000 6316 6284 6069 5212 5460 5959 6028 5863 5359 5153 5336 5264 ## 2001 6647 6523 6509 6004 5901 6816 6858 7017 6766 7175 7617 7773 ## 2002 9051 8823 8776 8255 7969 8758 8693 8271 7790 7769 8170 8209 ## 2003 9395 9260 9018 8501 8500 9649 9319 8830 8436 8169 8269 7945 ## 2004 9144 8770 8834 7837 7792 8616 8518 7940 7545 7531 7665 7599 ## 2005 8444 8549 7986 7335 7287 7870 7839 7327 7259 6964 7271 6956 ## 2006 7608 7692 7255 6804 6655 7341 7602 7086 6625 6272 6576 6491 ## 2007 7649 7400 6913 6532 6486 7295 7556 7088 6952 6773 6917 7371 ## 2008 8221 7953 8027 7287 8076 8933 9433 9479 9199 9469 10015 10999 ## 2009 13009 13699 13895 13248 13973 15095 15201 14823 14538 14547 14407 14740 ## 2010 16147 15991 15678 14609 14369 14885 15137 14759 14140 13903 14282 13997 ## 2011 14937 14542 14060 13237 13421 14409 14428 14008 13520 13102 12613 12692 ## 2012 13541 13430 12904 11910 12271 13184 13400 12696 11742 11741 11404 11844 ## 2013 13181 12500 11815 11014 11302 12248 12083 11462 10885 10773 10271 9984 ## 2014 10855 10893 10537 9079 9443 9893 10307 9787 8962 8680 8630 8331 ## 2015 9498 9095 8682 7966 8370 8638 8805 8162 7628 7597 7573 7542 ## 2016 8309 8219 8116 7413 7207 8144 8267 7996 7658 7447 7066 gasoline fpp2パッケージに含まれるgasolineデータセットは、1991年2月2日から2017年１月20日までの米国ガソリン生産量（単位：百万バレル／日）の週次データです。データ形式はts型です。 iris datasetsパッケージに含まれるirisデータセットは、データ分析で良く使用される有名なデータで、3種類のアヤメの萼（がく）と花弁の長さ・幅のデータを格納しています。データ型はdata.frame形式です。 iris_tbl &lt;- as.tibble(iris) iris_tbl ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # ... with 140 more rows mtcars datasetsパッケージに含まれるmtcarsデータセットは、米国で1973～1974年に発売された32車種のデザインや諸元に関するデータです。燃費、排気量、馬力、重量などのデータが格納されています。データ型はdata.frame形式です。 mtcars ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 mpg ggplot2パッケージに含まれるmpgデータセットは、米国で1999～2008年に発売された38車種の燃費関連データです。自動車メーカー名、モデル名、排気量、都市部と高速道路の燃費などのデータが格納されています。データ型はtibble形式です。 データ出所リンク mpg ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto~ f 18 29 p comp~ ## 2 audi a4 1.8 1999 4 manu~ f 21 29 p comp~ ## 3 audi a4 2 2008 4 manu~ f 20 31 p comp~ ## 4 audi a4 2 2008 4 auto~ f 21 30 p comp~ ## 5 audi a4 2.8 1999 6 auto~ f 16 26 p comp~ ## 6 audi a4 2.8 1999 6 manu~ f 18 26 p comp~ ## 7 audi a4 3.1 2008 6 auto~ f 18 27 p comp~ ## 8 audi a4 quattro 1.8 1999 4 manu~ 4 18 26 p comp~ ## 9 audi a4 quattro 1.8 1999 4 auto~ 4 16 25 p comp~ ## 10 audi a4 quattro 2 2008 4 manu~ 4 20 28 p comp~ ## # ... with 224 more rows diamonds ggplot2パッケージに含まれるdiamondsデータセットは、約54,000個のダイヤモンドの価格、カラット、色、大きさなどの情報を格納しています。データ型はtibble形式です。 diamonds ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4 4.05 2.39 ## # ... with 53,930 more rows economics ggplot2パッケージに含まれるeconomicsデータセットは、米国の消費・雇用関連の時系列データで、日付（date）、個人消費支出（pce）、人口（pop）、個人貯蓄率（psavert）、失業期間の中央値（uempmed）、失業者数（unemploy）のデータを格納しています。データ型はtibble形式です。 economics ## # A tibble: 574 x 6 ## date pce pop psavert uempmed unemploy ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1967-07-01 507. 198712 12.6 4.5 2944 ## 2 1967-08-01 510. 198911 12.6 4.7 2945 ## 3 1967-09-01 516. 199113 11.9 4.6 2958 ## 4 1967-10-01 512. 199311 12.9 4.9 3143 ## 5 1967-11-01 517. 199498 12.8 4.7 3066 ## 6 1967-12-01 525. 199657 11.8 4.8 3018 ## 7 1968-01-01 531. 199808 11.7 5.1 2878 ## 8 1968-02-01 534. 199920 12.3 4.5 3001 ## 9 1968-03-01 544. 200056 11.7 4.1 2877 ## 10 1968-04-01 544 200208 12.3 4.6 2709 ## # ... with 564 more rows 外部データセット 外部データセットはウェブから読み込むため、プロキシ環境ではプロキシサーバーの設定が必要です。 # プロキシサーバーとポートを記入 proxy_url &lt;- &quot;http://proxyserver:port/&quot; # Rのシステム環境変数を設定 Sys.setenv(&quot;http_proxy&quot; = proxy_url) Sys.setenv(&quot;https_proxy&quot; = proxy_url) # Rのダウンロードオプションを設定 options(download.file.method = &quot;libcurl&quot;) options(timeout = NA) OWIDのCOVID-19データセット Our World in Dataの新型コロナウイルス関連データセットです。データの詳細はOur World in Dataのウェブサイトを参照してください。 Hannah Ritchie, Edouard Mathieu, Lucas Rodés-Guirao, Cameron Appel, Charlie Giattino, Esteban Ortiz-Ospina, Joe Hasell, Bobbie Macdonald, Diana Beltekian and Max Roser (2020) - “Coronavirus Pandemic (COVID-19)”. Published online at OurWorldInData.org. Retrieved from: ‘https://ourworldindata.org/coronavirus’ [Online Resource] # Our World in Dataの新型コロナデータをtibble形式で読み込み data_owid &lt;- readr::read_csv(file = &quot;https://covid.ourworldindata.org/data/owid-covid-data.csv&quot;, # ファイルパス／URL col_names = TRUE, # ヘッダー（列名データ）の有無 col_types = NULL, # 各列の型の指定（c：文字列型、d：数値型、D：日付型、l：論理値型） skip = 0) # 読み込み時に上からスキップする行数 # 使用するデータを絞り込み data_owid %&lt;&gt;% dplyr::select(continent, location, date, total_cases, new_cases, new_cases_smoothed, total_deaths, new_deaths, total_cases_per_million, new_cases_per_million, total_deaths_per_million, new_deaths_per_million, people_fully_vaccinated, stringency_index) #%&gt;% #dplyr::filter(location %in% c(&quot;Japan&quot;, &quot;United States&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Italy&quot;)) # データをコンソールに出力 data_owid ## # A tibble: 197,003 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2020-02-24 5 5 NA ## 2 Asia Afghanistan 2020-02-25 5 0 NA ## 3 Asia Afghanistan 2020-02-26 5 0 NA ## 4 Asia Afghanistan 2020-02-27 5 0 NA ## 5 Asia Afghanistan 2020-02-28 5 0 NA ## 6 Asia Afghanistan 2020-02-29 5 0 0.714 ## 7 Asia Afghanistan 2020-03-01 5 0 0.714 ## 8 Asia Afghanistan 2020-03-02 5 0 0 ## 9 Asia Afghanistan 2020-03-03 5 0 0 ## 10 Asia Afghanistan 2020-03-04 5 0 0 ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 日本の産業別就業者数 総務省が公表する労働力調査の長期時系列データのうち、2002年1月以降の産業別就業者数（表番号：1-c-3）を格納したデータセットです。詳細はe-Statの該当ページを参照してください。 # 総務省の労働力調査データをdata.frame形式で読み込み data_labor &lt;- openxlsx::read.xlsx(xlsxFile = &quot;https://www.e-stat.go.jp/stat-search/file-download?statInfId=000031831374&amp;fileKind=0&quot;, # ファイルパス／URL sheet = 1, # シートインデックス／シート名 startRow = 10, # 読み込み開始行 colNames = FALSE, # 列名データの有無 rowNames = FALSE, # 行名データの有無 rows = NULL, # 読み込む列（NULLですべて読み込み） cols = NULL) # 読み込む行（NULLですべて読み込み） # 不要な列を削除 data_labor %&lt;&gt;% dplyr::select(-X1, -X2, -X3, -X6) # 列名を追加 colnames(data_labor) &lt;- c(&quot;総数&quot;, &quot;農林&quot;, &quot;建設&quot;, &quot;製造&quot;, &quot;情報通信&quot;, &quot;運輸・郵便&quot;, &quot;卸・小売&quot;, &quot;金融・保険&quot;, &quot;不動産・物品賃貸&quot;, &quot;学術・専門・技術&quot;, &quot;宿泊・飲食&quot;, &quot;生活関連・娯楽&quot;, &quot;教育&quot;, &quot;医療・福祉&quot;, &quot;複合サービス&quot;, &quot;その他サービス&quot;, &quot;公務&quot;) # NAを含む行を削除 data_labor %&lt;&gt;% tidyr::drop_na(everything()) # すべての列を数値型に変換 data_labor %&lt;&gt;% dplyr::mutate(across(everything(), as.double)) # 日付列を追加 data_labor %&lt;&gt;% dplyr::mutate(date = seq(from = as.Date(&quot;2002-01-01&quot;), to = as.Date(&quot;2002-01-01&quot;) + months(dim(data_labor)[1] - 1), by = &quot;1 month&quot;), .before = &quot;総数&quot;) # tibble形式に変換 data_labor %&lt;&gt;% tibble::as_tibble() # データをコンソールに出力 data_labor ## # A tibble: 244 x 18 ## date 総数 農林 建設 製造 情報通信 `運輸・郵便` `卸・小売` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2002-01-01 6267 224 589 1210 153 331 1131 ## 2 2002-02-01 6248 227 611 1201 156 324 1075 ## 3 2002-03-01 6297 242 628 1238 156 323 1081 ## 4 2002-04-01 6333 278 624 1213 159 315 1121 ## 5 2002-05-01 6356 307 607 1194 157 322 1134 ## 6 2002-06-01 6373 311 594 1223 159 330 1115 ## 7 2002-07-01 6374 294 622 1199 160 328 1116 ## 8 2002-08-01 6371 288 620 1207 164 326 1085 ## 9 2002-09-01 6353 286 621 1183 171 333 1081 ## 10 2002-10-01 6355 271 642 1176 160 333 1116 ## # ... with 234 more rows, and 10 more variables: `金融・保険` &lt;dbl&gt;, ## # `不動産・物品賃貸` &lt;dbl&gt;, `学術・専門・技術` &lt;dbl&gt;, `宿泊・飲食` &lt;dbl&gt;, ## # `生活関連・娯楽` &lt;dbl&gt;, 教育 &lt;dbl&gt;, `医療・福祉` &lt;dbl&gt;, 複合サービス &lt;dbl&gt;, ## # その他サービス &lt;dbl&gt;, 公務 &lt;dbl&gt; 日本の県内総生産 内閣府が公表する県内総生産データセットです（生産側、名目、2008SNA、平成23年基準計数）。詳細は内閣府のウェブサイトを参照してください。ここではデータをdata.frame形式で読み込み、前処理して縦型のtibble形式に変換します。 # 内閣府の県内総生産データをdata.frame形式で読み込み data_gdp_pref &lt;- openxlsx::read.xlsx(xlsxFile = &quot;https://www.esri.cao.go.jp/jp/sna/data/data_list/kenmin/files/contents/tables/2018/soukatu1.xlsx&quot;, # ファイルパス／URL sheet = 1, # シートインデックス／シート名 startRow = 5, # 読み込み開始行 colNames = TRUE, # 列名データの有無 rowNames = FALSE, # 行名データの有無 rows = 5:53, # 読み込む列（NULLですべて読み込み） cols = NULL) # 読み込む行（NULLですべて読み込み） # データの型変換等を行い、縦型に変形したうえで、変化率系列を作成し、tibble形式に変換 data_gdp_pref %&lt;&gt;% dplyr::mutate(across(`2006`:`2018`, as.double)) %&gt;% dplyr::rename(pref_code = X1, pref_name = X2) %&gt;% dplyr::select(-X16) %&gt;% tidyr::pivot_longer(cols = c(-&quot;pref_code&quot;, -&quot;pref_name&quot;), names_to = &quot;year&quot;, values_to = &quot;gdp_nominal&quot;) %&gt;% dplyr::mutate(across(c(pref_code, year), as.double)) %&gt;% dplyr::arrange(pref_code, year) %&gt;% dplyr::group_by(pref_name) %&gt;% dplyr::mutate(gdp_nominal_pchg = 100 * (gdp_nominal / dplyr::lag(gdp_nominal, n = 1) - 1)) %&gt;% dplyr::ungroup() %&gt;% tibble::as_tibble() data_gdp_pref ## # A tibble: 611 x 5 ## pref_code pref_name year gdp_nominal gdp_nominal_pchg ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 北海道 2006 19316568 NA ## 2 1 北海道 2007 19137599 -0.927 ## 3 1 北海道 2008 18457858 -3.55 ## 4 1 北海道 2009 18219113 -1.29 ## 5 1 北海道 2010 18122675 -0.529 ## 6 1 北海道 2011 18071493 -0.282 ## 7 1 北海道 2012 17923502 -0.819 ## 8 1 北海道 2013 18242119 1.78 ## 9 1 北海道 2014 18579766 1.85 ## 10 1 北海道 2015 19128504 2.95 ## # ... with 601 more rows 西山 他（2019） 本書の第7章以降の計量経済学パートでは、西山 他（2019）の実証例で使用されているサンプルデータセットを使用します。サンプルデータセットは、西山 他（2019）のサポートウェブサイトで配布されています。 1.6 R起動時に実行する設定 ここまでに紹介した各種設定のうち、Rを起動したときに毎回実行する必要があるものをひとまとめにしました。 # 全変数を削除 rm(list = ls()) # 警告の非表示 options(warn = -1) # プロキシ設定（使用環境に応じproxyserverとportを記入） proxy_url &lt;- &quot;http://proxyserver:port/&quot; Sys.setenv(&quot;http_proxy&quot; = proxy_url) Sys.setenv(&quot;https_proxy&quot; = proxy_url) options(download.file.method = &quot;libcurl&quot;) options(timeout = NA) # パッケージのインストールとインポート packages &lt;- c( &quot;lubridate&quot;, &quot;magrittr&quot;, &quot;tidyverse&quot;, &quot;readxl&quot;, &quot;esquisse&quot;, &quot;geofacet&quot;, &quot;ggplotgui&quot;, &quot;ggpubr&quot;, &quot;ggsci&quot;, &quot;ggrepel&quot;, &quot;hexbin&quot;, &quot;lemon&quot;, &quot;RColorBrewer&quot;, &quot;corrplot&quot;, &quot;corrr&quot;, &quot;DataExplorer&quot;, &quot;estimatr&quot;, &quot;fpp2&quot;, &quot;GGally&quot;, &quot;mfilter&quot;, &quot;mgcv&quot;, &quot;plm&quot;, &quot;psych&quot;, &quot;seasonal&quot;, &quot;seasonalview&quot;, &quot;sigmoid&quot;, &quot;SmartEDA&quot;, &quot;tidyquant&quot;, &quot;openxlsx&quot;, &quot;pbapply&quot; ) new_packages &lt;- packages[!(packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new_packages)) { install.packages(new_packages) } for (pkg in packages) { library(pkg, character.only = TRUE) } rm( new_packages, packages, pkg ) # グラフ設定 theme_set(theme_light()) windowsFonts(&quot;MEIRYO&quot; = windowsFont(&quot;Meiryo UI&quot;)) windowsFonts(&quot;YUGO&quot; = windowsFont(&quot;Yu Gothic UI&quot;)) "],["rの基本的な使用方法.html", "2 Rの基本的な使用方法 2.1 主要ショートカットキー 2.2 基本操作 2.3 演算 2.4 ベクトル 2.5 行列 2.6 データフレーム 2.7 リスト 2.8 制御構文 2.9 データの読み込み・書き出し 2.10 オブジェクトのセーブ・ロード", " 2 Rの基本的な使用方法 第2章「Rの基本的な使用方法」では、Rの基本的な使用方法について解説します。本節の内容は基礎部分のみのため、詳細は、馬場（2020）、松村 他（2021）、Wickham &amp; Grolemund（2017）などを参照してください。 RStudioでコードを編集するパネルをソース（Source）と呼びます。RStudioの左上のパネルがソースで、コンソール（Console）パネルの上にあります。ソースが表示されていない場合は、FileメニューからNew Fileに進み、R Scriptを選択すると、ソースが表示されます。 ソースにコードを記述し、記述したコードの行にカーソルがある状態でCtrl + Enterを押すと、コンソールに実行結果が表示されます。 2.1 主要ショートカットキー Alt + Shift + K： キーボードショートカットを表示 編集 Ctrl + S： 保存 Ctrl + A： すべて選択 Ctrl + Shift + R： セクション区切りを挿入 Ctrl + Shift + C： 選択範囲をコメントアウト／コメントアウト解除 Ctrl + Shift + M： パイプオペレータ%&gt;%を挿入 実行 Ctrl + Enter： カーソルがある行／選択している部分のコードを実行 Ctrl + Alt + T： カーソルがあるセクションのコードをすべて実行 Ctrl + Alt + R： すべてのコードを実行 その他 F1： カーソルがある関数のヘルプを表示 2.2 基本操作 # 代入は &lt;- か = x &lt;- 2 x ## [1] 2 # シャープでコメントアウト（実行されない） 2.3 演算 四則計算 # 足し算 1 + 1 ## [1] 2 # 引き算 3 - 1 ## [1] 2 # 掛け算 2 * 3 ## [1] 6 # 割り算 10 / 5 ## [1] 2 # 割り算の整数の商 10 %/% 3 ## [1] 3 # 割り算の余り 10 %% 3 ## [1] 1 # べき乗 3 ** 2 ## [1] 9 3 ^ 2 ## [1] 9 数値計算 # 自然対数 log(10) ## [1] 2.302585 # ネイピア数のべき乗 exp(1) ## [1] 2.718282 # 平方根 sqrt(2) ## [1] 1.414214 # 絶対値 abs(-5) ## [1] 5 一致・大小関係 # 一致 2 == 2 ## [1] TRUE # 不一致 3 != 2 ## [1] TRUE # より大きい 3 &gt; 2 ## [1] TRUE # 以上 3 &gt;= 3 ## [1] TRUE # より小さい 2 &lt; 3 ## [1] TRUE # 以下 2 &lt;= 2 ## [1] TRUE 包含・集合関係 # 包含関係 1:5 %in% c(1, 2, 5) ## [1] TRUE TRUE FALSE FALSE TRUE # 和集合 union(seq(0, 20, 2), seq(0, 20, 3)) ## [1] 0 2 4 6 8 10 12 14 16 18 20 3 9 15 # 共通部分 intersect(seq(0, 20, 2), seq(0, 20, 3)) ## [1] 0 6 12 18 # 差分 setdiff(seq(0, 20, 2), seq(0, 20, 3)) ## [1] 2 4 8 10 14 16 20 2.4 ベクトル ベクトルの作成 ベクトルは複数の要素を一つにまとめたデータ構造で、c()関数で作成します。一つのベクトルには単一のデータ型のみ格納でき、数値型や文字列型のデータを混在させることはできません。 # 数値型ベクトルの作成 vec_1 &lt;- c(11, 12, 13, 14, 15) vec_1 ## [1] 11 12 13 14 15 # 文字列型ベクトルの作成 vec_2 &lt;- c(&quot;Hello&quot;, &quot;World&quot;) vec_2 ## [1] &quot;Hello&quot; &quot;World&quot; # 数値型データと文字列型データを混在させると、すべて文字列型に変換される c(1, 2, &quot;A&quot;, &quot;B&quot;) ## [1] &quot;1&quot; &quot;2&quot; &quot;A&quot; &quot;B&quot; ベクトル要素へのアクセス ベクトルでは、ベクトル[要素のインデックス]の形でインデックスを指定して各要素にアクセスすることができます。なお、Pythonなど他のプログラミング言語のインデックスは0から始まりますが、Rのインデックスは1から始まる点に注意してください。 # ベクトルの要素へのアクセス vec_1[1] ## [1] 11 vec_1[5] ## [1] 15 vec_1[2:4] ## [1] 12 13 14 rev(vec_1)[1] ## [1] 15 規則性があるベクトルの作成 規則性があるベクトルを作成するには、コロン（:）、seq()関数、rep()関数を使用します。 # 1から10までの等差数列 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 # 0から20までの2つ置きの数列 seq(from = 0, to = 20, by = 2) ## [1] 0 2 4 6 8 10 12 14 16 18 20 # 1から10までを4等分する等差数列 seq(from = 1, to = 10, length.out = 4) ## [1] 1 4 7 10 # 要素の繰り返し rep(x = 2, times = 5) ## [1] 2 2 2 2 2 # ベクトルの繰り返し rep(x = c(1, 2), times = 3) ## [1] 1 2 1 2 1 2 # ベクトルの各要素の繰り返し rep(x = c(1, 2), each = 3) ## [1] 1 1 1 2 2 2 ベクトルの演算 ベクトルの演算を行うと、ベクトルの対応する要素どうしが計算され、計算結果としてベクトルが出力されます。ベクトルの長さが異なる場合は、短い方のベクトルが使いまわされて長さを合わせます。 *演算子はベクトルの要素どうしの掛け算を行う点に注意してください。ベクトルの内積を計算するには%*%演算子を使用します。 vec_3 &lt;- c(1, 2, 3) vec_4 &lt;- c(5, 6, 7) # ベクトル要素の足し算 vec_3 + vec_4 ## [1] 6 8 10 # ベクトル要素の引き算 vec_3 - vec_4 ## [1] -4 -4 -4 # ベクトル要素の掛け算 vec_3 * vec_4 ## [1] 5 12 21 # ベクトル要素の割り算 vec_3 / vec_4 ## [1] 0.2000000 0.3333333 0.4285714 # ベクトルの内積 vec_3 %*% vec_4 ## [,1] ## [1,] 38 2.5 行列 行列の作成 行列はmatrix()関数を使用し、ベクトルを複数の列・行に分割する形で作成します。 # ベクトルを複数列に分割して行列を作成 mat_1 &lt;- matrix( data = 1:10, ncol = 2 ) mat_1 ## [,1] [,2] ## [1,] 1 6 ## [2,] 2 7 ## [3,] 3 8 ## [4,] 4 9 ## [5,] 5 10 # ベクトルを複数行に分割して行列を作成 mat_2 &lt;- matrix( data = 1:10, nrow = 2 ) mat_2 ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 3 5 7 9 ## [2,] 2 4 6 8 10 行列の要素へのアクセス 行列の要素にアクセスするには、ベクトルと同様に行列[要素の行インデックス, 要素の列インデックス]の形でインデックスを指定します。 # 行列の3行目・1列目の要素を取得 mat_1[3, 1] ## [1] 3 # 行列の4行目全体を取得 mat_1[4, ] ## [1] 4 9 # 行列の2列目全体を取得 mat_1[, 2] ## [1] 6 7 8 9 10 # 行列の1～3行目を取得 mat_1[1:3, ] ## [,1] [,2] ## [1,] 1 6 ## [2,] 2 7 ## [3,] 3 8 # 行列の1～3行目以外を取得 mat_1[-1:-3, ] ## [,1] [,2] ## [1,] 4 9 ## [2,] 5 10 行列の演算 行列の演算を行うと、行列の対応する要素どうしが計算され、計算結果として行列が出力されます。 *演算子は行列の要素どうしの掛け算を行う点に注意してください。行列の積を計算するには%*%演算子を使用します。 mat_2 &lt;- matrix( data = 1:4, ncol = 2 ) mat_3 &lt;- matrix( data = 5:8, ncol = 2 ) # 行列要素の足し算 mat_2 + mat_3 ## [,1] [,2] ## [1,] 6 10 ## [2,] 8 12 # 行列要素の引き算 mat_2 - mat_3 ## [,1] [,2] ## [1,] -4 -4 ## [2,] -4 -4 # 行列要素の掛け算 mat_2 * mat_3 ## [,1] [,2] ## [1,] 5 21 ## [2,] 12 32 # 行列要素の割り算 mat_2 / mat_3 ## [,1] [,2] ## [1,] 0.2000000 0.4285714 ## [2,] 0.3333333 0.5000000 # 各行の和 rowSums(mat_2) ## [1] 4 6 # 各列の和 colSums(mat_2) ## [1] 3 7 # 行列の積 mat_2 %*% mat_3 ## [,1] [,2] ## [1,] 23 31 ## [2,] 34 46 # 行列の転置 t(mat_2) ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 # 逆行列 solve(mat_2) ## [,1] [,2] ## [1,] -2 1.5 ## [2,] 1 -0.5 2.6 データフレーム データフレームは、同じ長さの列ベクトルを複数まとめた行列形式のデータ構造で、実務で最も頻繁に使用します。Excelのスプレッドシートのイメージに近く、実際にCSV形式のファイルをRに読み込むとデータフレーム形式のオブジェクトが作成されます。 なお、データフレームには、Rにもともと備わっているdata.frame形式と、tidyverseパッケージによって導入されたtibble形式の2種類があります。両者にはいくつか違いがありますが、data.frame形式を使いやすくしたものがtibble形式と言えます。詳細はtibbleパッケージの公式ウェブサイトを参照してください。 データフレームの作成 tibble形式のデータフレームは、tibble()関数を使用して列名 = 要素の形で作成します。データフレームではすべての列ベクトルの要素数が同じになるようにします。 df_1 &lt;- tibble( x = 1:5, y = 6:10, z = x ^ 2 + y ) df_1 ## # A tibble: 5 x 3 ## x y z ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 6 7 ## 2 2 7 11 ## 3 3 8 17 ## 4 4 9 25 ## 5 5 10 35 データフレームの要素へのアクセス データフレームでは、データフレーム$列名の形でドルマークを使用して各列ベクトルにアクセスすることができます。また、データフレーム$列名[要素インデックス]で各列ベクトルの要素にアクセスできます。 df_1$x ## [1] 1 2 3 4 5 df_1$z[3] ## [1] 17 その他に、角括弧を使用して要素にアクセスすることもできます。ここで、一重の角括弧と二重の角括弧では実行結果が異なる点に注意してください。一重角括弧では、データフレームの一部を分割したものとして、結果がtibble形式で出力されます。一方、二重角括弧では、tibble形式の中に格納されているベクトルや単一の数値といった要素そのものが出力されます。 df_1[&quot;x&quot;] ## # A tibble: 5 x 1 ## x ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 df_1[1] ## # A tibble: 5 x 1 ## x ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 df_1[2, 2] ## # A tibble: 1 x 1 ## y ## &lt;int&gt; ## 1 7 df_1[[&quot;x&quot;]] ## [1] 1 2 3 4 5 df_1[[1]] ## [1] 1 2 3 4 5 df_1[[2, 2]] ## [1] 7 その他のデータフレームの機能 df_2 &lt;- tibble( letters = LETTERS, numbers = 1:26 ) df_2 ## # A tibble: 26 x 2 ## letters numbers ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 ## 2 B 2 ## 3 C 3 ## 4 D 4 ## 5 E 5 ## 6 F 6 ## 7 G 7 ## 8 H 8 ## 9 I 9 ## 10 J 10 ## # ... with 16 more rows # データフレームの上部のみ表示 head(df_2) ## # A tibble: 6 x 2 ## letters numbers ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 ## 2 B 2 ## 3 C 3 ## 4 D 4 ## 5 E 5 ## 6 F 6 # データフレームの下部のみ表示 tail(df_2) ## # A tibble: 6 x 2 ## letters numbers ## &lt;chr&gt; &lt;int&gt; ## 1 U 21 ## 2 V 22 ## 3 W 23 ## 4 X 24 ## 5 Y 25 ## 6 Z 26 # データフレームの列名一覧を出力 colnames(df_2) ## [1] &quot;letters&quot; &quot;numbers&quot; 2.7 リスト リストは、単一の数値、文字列、ベクトル、データフレームなど、様々な種類のデータを格納することができる容器のようなものです。リストそのものをリストに格納することもできます。リストはlist()関数で作成します。リストに格納する各要素には、それぞれ名前を付けることができます。 リストの作成 list_1 &lt;- list( number = 1, string = &quot;a&quot;, vector = c(10, 11, 12), matrix = matrix(1:9, ncol = 3) ) list_1 ## $number ## [1] 1 ## ## $string ## [1] &quot;a&quot; ## ## $vector ## [1] 10 11 12 ## ## $matrix ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 リストの要素へのアクセス リストでは、データフレームと同様にリスト$要素名の形でドルマークを使用して各要素にアクセスすることができます。 list_1$number ## [1] 1 list_1$matrix ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 また、ベクトルや行列と同様に、リスト[[要素インデックス]]でも各要素にアクセスすることができます。ここで、角括弧が二重である点に注意してください。 list_1[[3]] ## [1] 10 11 12 2.8 制御構文 制御構文には、条件分岐を行うifやelse、同じ操作の繰り返しを行うforやwhile、エラー処理を行うtryがあります。 if/else文 if文は、if (条件) {処理}の形で記述します。else ifで追加条件、elseで「その他すべて」の条件を意味します。 x &lt;- 5 if (x &lt; 2) { print(&quot;A&quot;) } else if (x &gt;= 2 &amp; x &lt; 6) { print(&quot;B&quot;) } else { print(&quot;C&quot;) } ## [1] &quot;B&quot; forループ for文は、for (変数 in 変数に逐次代入する要素) {処理}の形で記述します。変数はカウンタではない点に注意してください。 for (i in 1:5) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 for (letter in letters[1:6]) { print(letter) } ## [1] &quot;a&quot; ## [1] &quot;b&quot; ## [1] &quot;c&quot; ## [1] &quot;d&quot; ## [1] &quot;e&quot; ## [1] &quot;f&quot; 変数をカウンタとして使用したい場合は、seq_along()関数をfor (変数 in seq_along(変数に逐次代入する要素を格納したベクトル等))の形で用いると、自動的に要素数に応じたインデックスを変数に代入してくれます。 for (i in seq_along(letters[1:6])) { print(str_c(i, &quot;_&quot;, letters[1:6][i])) } ## [1] &quot;1_a&quot; ## [1] &quot;2_b&quot; ## [1] &quot;3_c&quot; ## [1] &quot;4_d&quot; ## [1] &quot;5_e&quot; ## [1] &quot;6_f&quot; whileループ while文は、while (繰り返し処理を続ける条件) {処理}の形で記述します。while文を使う際は、「繰り返し処理を続ける条件」が有限回数で終わるように処理内容を工夫します（そうしないと無限ループになります）。例えば、下記のように条件を「カウンタが正の値」にしておき、処理の中でカウンタが減少するように書くのが一般的です。 count &lt;- 3 while (count &gt; 0) { print(count) count &lt;- count - 1 } ## [1] 3 ## [1] 2 ## [1] 1 breakによる繰り返しの終了 while文の処理の中でbreak文を用い、ループを強制的に終了させることができます。 vec_break &lt;- c(10, 20, 30, 40, 50) index &lt;- 1 while(TRUE) { # indexがvec_breakの要素数を超えると繰り返しを終了 if (index &gt; length(vec_break)) { break } print(vec_break[index]) index &lt;- index + 1 } ## [1] 10 ## [1] 20 ## [1] 30 ## [1] 40 ## [1] 50 tryによるエラー処理 エラーを起こす可能性がある処理をtry()関数のexpr = {}内に記述することで、エラーが発生しても処理を続けることができます。 list_try &lt;- list(1, 2, 3, &quot;4&quot;, 5) for (i in seq_along(list_try)) { try( expr = { # エラーの可能性がある処理 x &lt;- log(list_try[[i]]) print(x) }, silent = FALSE # TRUEにするとエラーの内容を非表示 ) } ## [1] 0 ## [1] 0.6931472 ## [1] 1.098612 ## Error in log(list_try[[i]]) : 数学関数に数値でない引数が渡されました ## [1] 1.609438 2.9 データの読み込み・書き出し CSVデータの読み込み CSVデータの読み込みには、readrパッケージのread_csv()関数を使用します。ローカルネットワークのファイルパス、ウェブのURLどちらからの読み込みにも対応しています。 data &lt;- readr::read_csv(file = &quot;directory/file.csv&quot;, # ファイルパス／URL（拡張子が必要） col_names = TRUE, # ヘッダー（列名データ）の有無 col_types = NULL, # 各列の型の指定（c：文字列型、d：数値型、D：日付型、l：論理値型） skip = 0) # 読み込み時に上からスキップする行数 Excelデータの読み込み（xls形式） readrパッケージのread_excel()関数は、Excelのxls形式、xlsx形式どちらも読み込み可能です。ただし、読み込み元としてpath引数に指定できるのはローカルネットワーク内のファイルパスだけで、ウェブのURLからの読み込みはできません。 data &lt;- readxl::read_excel(path = &quot;directory/file.xls&quot;, # ファイルパス（拡張子が必要、URLは不可） sheet = NULL, # シートインデックス／シート名 col_names = TRUE, # ヘッダー（列名データ）の有無 col_types = NULL, # 各列の型の指定（c：文字列型、d：数値型、D：日付型、l：論理値型） skip = 0) # 読み込み時に上からスキップする行数 Excelデータの読み込み（xlsx形式） openxlsxパッケージのread.xlsx()関数であれば、ローカルネットワーク内のファイルパスとウェブのURLどちらからでも読み込みが可能です。ただし、読み込めるファイル形式はxlsx形式のみで、xls形式には対応していません。 data &lt;- openxlsx::read.xlsx(xlsxFile = &quot;directory/file.xlsx&quot;, # ファイルパス／URL（拡張子が必要） sheet = 1, # シートインデックス／シート名 startRow = 5, # 読み込み開始行 colNames = TRUE, # 列名データの有無 rowNames = FALSE, # 行名データの有無 rows = 5:53, # 読み込む列（NULLですべて読み込み） cols = NULL) # 読み込む行（NULLですべて読み込み） CSVデータの書き出し CSVデータを書き出す（CSVファイルとして保存する）には、write.csv()関数を使用します。 write.csv(..., # 書き出すオブジェクト名（クオーテーションは不要） file = &quot;directory/file.csv&quot;, # 書き出し先のファイルパス（拡張子が必要） row.names = FALSE) # 行番号を付与するか 2.10 オブジェクトのセーブ・ロード セーブ RのオブジェクトをRData形式で保存します。 save(..., # セーブするオブジェクト名（クオーテーションは不要） file = &quot;directory/file.RData&quot;) # セーブ先のファイルパス（拡張子が必要） ロード 保存したRData形式のオブジェクトを読み込みます。 load(file = &quot;directory/file.RData&quot;) # ロード元ファイルパス（拡張子が必要） "],["tidyverseによるデータ操作.html", "3 tidyverseによるデータ操作 3.1 第3章の準備 3.2 tidyverseとは 3.3 列の選択 3.4 列名の変更 3.5 行のフィルタ 3.6 行の並べ替え 3.7 列の作成・修正 3.8 グループ化 3.9 集計 3.10 縦型・横型の変換 3.11 データの結合 3.12 重複処理 3.13 欠損値処理 3.14 補完処理 3.15 サンプリング", " 3 tidyverseによるデータ操作 第3章「tidyverseによるデータ操作」では、tidyverseのdplyrパッケージとtidyrパッケージを使用した、直感的かつ効率的なデータ操作について解説します。 3.1 第3章の準備 パッケージのインポート library(magrittr) library(tidyverse) library(tidyquant) 外部データセットの取得 この章では、外部データセットとして以下のデータを使用します。第1章のコードを使用してあらかじめウェブからデータセットを取得してください。 OWIDのCOVID-19データセット： data_owid 3.2 tidyverseとは tidyverseは、Rでデータを直感的・効率的に操作・可視化するために開発された様々なパッケージを、ひとまとめにしたものです。本節では、tidyverseに含まれるパッケージのうち、データ操作に関わるdplyrパッケージとtidyrパッケージを主に使用します。 dplyr：データに様々な操作を加えるパッケージ tidyr：データをtidy dataに変形するためのパッケージ tidy dataとは、tidyverseの開発者であるHadley Wickham氏が提唱した概念で、機械処理しやすいデータ形式のことを言います。具体的には、以下の条件を満たすデータです。 1つの列が1つの変数を表す 1つの行が1つのレコードを表す 1つのテーブルが1つのデータセットだけを含む tidy data（縦型・横型データ） 例えば、国別・産業別GDPの時系列データであれば、国の列、産業の列、時点の列、データ（GDP）の列、の4列で構成されるデータがtidy dataです。こうしたデータを縦型データとも呼びます。パネルデータは一般的に縦型データの構造になっています。 一方、国や産業が横方向に並んでいる場合（例：日本・製造業のGDPの列、日本・飲食業のGDPの列、米国・金融業のGDPの列…など）は、tidy data（縦型データ）ではなく、横型データと呼ばれます。 tidy dataは属性条件によるフィルタがかけやすいなど、データ処理が列方向に一括して行えるため、機械処理に適しています。tidy dataの詳細については、松村 他（2021）を参照してください。 tidyverseの特徴 dplyrパッケージやtidyrパッケージの関数は、もとのデータに対して変更を一切加えません。データを操作した結果を残しておくためには、結果をオブジェクトに代入する必要があります。なお、代入先をもとのデータのオブジェクトにすると、データの内容が書き換えられます。 tidyverseでは、magrittrパッケージの機能の一つであるパイプ%&gt;%が多用されます。パイプは、データに対して適用した関数の結果を、次の関数へと受け渡すものです。パイプを連続して使用することで、処理の途中の結果をいちいちオブジェクトに代入することなく、一括して複数の処理を行うことができます。 このコードは、mpgデータセットに対する複数の関数の処理をパイプでつなげたものです。 # mpgデータセットからmanufacturer列とcty列を選択し、manufacturer列でフィルタしたうえで、 # cty列を10倍し、結果をresultオブジェクトに保存する例 result &lt;- mpg %&gt;% dplyr::select(manufacturer, cty) %&gt;% dplyr::filter(manufacturer == &quot;toyota&quot;) %&gt;% dplyr::mutate(cty_10 = cty * 10) print(result) ## # A tibble: 34 x 3 ## manufacturer cty cty_10 ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 toyota 15 150 ## 2 toyota 16 160 ## 3 toyota 15 150 ## 4 toyota 15 150 ## 5 toyota 16 160 ## 6 toyota 14 140 ## 7 toyota 21 210 ## 8 toyota 21 210 ## 9 toyota 21 210 ## 10 toyota 21 210 ## # ... with 24 more rows 3.3 列の選択 データセットから列（変数）を選択するには、dplyr::select()関数を使用します。 列名で選択 data_owid %&gt;% dplyr::select(location, date, new_cases) ## # A tibble: 197,003 x 3 ## location date new_cases ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-02-24 5 ## 2 Afghanistan 2020-02-25 0 ## 3 Afghanistan 2020-02-26 0 ## 4 Afghanistan 2020-02-27 0 ## 5 Afghanistan 2020-02-28 0 ## 6 Afghanistan 2020-02-29 0 ## 7 Afghanistan 2020-03-01 0 ## 8 Afghanistan 2020-03-02 0 ## 9 Afghanistan 2020-03-03 0 ## 10 Afghanistan 2020-03-04 0 ## # ... with 196,993 more rows 列名を格納したベクトルで選択 cols &lt;- c(&quot;location&quot;, &quot;date&quot;, &quot;new_cases&quot;) data_owid %&gt;% dplyr::select(cols) ## Note: Using an external vector in selections is ambiguous. ## i Use `all_of(cols)` instead of `cols` to silence this message. ## i See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;. ## This message is displayed once per session. ## # A tibble: 197,003 x 3 ## location date new_cases ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-02-24 5 ## 2 Afghanistan 2020-02-25 0 ## 3 Afghanistan 2020-02-26 0 ## 4 Afghanistan 2020-02-27 0 ## 5 Afghanistan 2020-02-28 0 ## 6 Afghanistan 2020-02-29 0 ## 7 Afghanistan 2020-03-01 0 ## 8 Afghanistan 2020-03-02 0 ## 9 Afghanistan 2020-03-03 0 ## 10 Afghanistan 2020-03-04 0 ## # ... with 196,993 more rows 列を非選択（削除） data_owid %&gt;% dplyr::select(-location) ## # A tibble: 197,003 x 13 ## continent date total_cases new_cases new_cases_smoothed total_deaths ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia 2020-02-24 5 5 NA NA ## 2 Asia 2020-02-25 5 0 NA NA ## 3 Asia 2020-02-26 5 0 NA NA ## 4 Asia 2020-02-27 5 0 NA NA ## 5 Asia 2020-02-28 5 0 NA NA ## 6 Asia 2020-02-29 5 0 0.714 NA ## 7 Asia 2020-03-01 5 0 0.714 NA ## 8 Asia 2020-03-02 5 0 0 NA ## 9 Asia 2020-03-03 5 0 0 NA ## 10 Asia 2020-03-04 5 0 0 NA ## # ... with 196,993 more rows, and 7 more variables: new_deaths &lt;dbl&gt;, ## # total_cases_per_million &lt;dbl&gt;, new_cases_per_million &lt;dbl&gt;, ## # total_deaths_per_million &lt;dbl&gt;, new_deaths_per_million &lt;dbl&gt;, ## # people_fully_vaccinated &lt;dbl&gt;, stringency_index &lt;dbl&gt; 列名に特定の文字列を含む列を選択 data_owid %&gt;% dplyr::select(location, date, contains(&quot;cases&quot;)) ## # A tibble: 197,003 x 7 ## location date total_cases new_cases new_cases_smoot~ total_cases_per~ ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanist~ 2020-02-24 5 5 NA 0.126 ## 2 Afghanist~ 2020-02-25 5 0 NA 0.126 ## 3 Afghanist~ 2020-02-26 5 0 NA 0.126 ## 4 Afghanist~ 2020-02-27 5 0 NA 0.126 ## 5 Afghanist~ 2020-02-28 5 0 NA 0.126 ## 6 Afghanist~ 2020-02-29 5 0 0.714 0.126 ## 7 Afghanist~ 2020-03-01 5 0 0.714 0.126 ## 8 Afghanist~ 2020-03-02 5 0 0 0.126 ## 9 Afghanist~ 2020-03-03 5 0 0 0.126 ## 10 Afghanist~ 2020-03-04 5 0 0 0.126 ## # ... with 196,993 more rows, and 1 more variable: new_cases_per_million &lt;dbl&gt; 列名が特定の文字列から始まる列を選択 data_owid %&gt;% dplyr::select(location, date, starts_with(&quot;new_cases&quot;)) ## # A tibble: 197,003 x 5 ## location date new_cases new_cases_smoothed new_cases_per_million ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-02-24 5 NA 0.126 ## 2 Afghanistan 2020-02-25 0 NA 0 ## 3 Afghanistan 2020-02-26 0 NA 0 ## 4 Afghanistan 2020-02-27 0 NA 0 ## 5 Afghanistan 2020-02-28 0 NA 0 ## 6 Afghanistan 2020-02-29 0 0.714 0 ## 7 Afghanistan 2020-03-01 0 0.714 0 ## 8 Afghanistan 2020-03-02 0 0 0 ## 9 Afghanistan 2020-03-03 0 0 0 ## 10 Afghanistan 2020-03-04 0 0 0 ## # ... with 196,993 more rows 列名が特定の文字列で終わる列を選択 data_owid %&gt;% dplyr::select(location, date, ends_with(c(&quot;cases&quot;, &quot;deaths&quot;))) ## # A tibble: 197,003 x 6 ## location date total_cases new_cases total_deaths new_deaths ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-02-24 5 5 NA NA ## 2 Afghanistan 2020-02-25 5 0 NA NA ## 3 Afghanistan 2020-02-26 5 0 NA NA ## 4 Afghanistan 2020-02-27 5 0 NA NA ## 5 Afghanistan 2020-02-28 5 0 NA NA ## 6 Afghanistan 2020-02-29 5 0 NA NA ## 7 Afghanistan 2020-03-01 5 0 NA NA ## 8 Afghanistan 2020-03-02 5 0 NA NA ## 9 Afghanistan 2020-03-03 5 0 NA NA ## 10 Afghanistan 2020-03-04 5 0 NA NA ## # ... with 196,993 more rows 特定の型の列を選択 data_owid %&gt;% dplyr::select(where(is.character) | where(is.Date)) ## # A tibble: 197,003 x 3 ## continent location date ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; ## 1 Asia Afghanistan 2020-02-24 ## 2 Asia Afghanistan 2020-02-25 ## 3 Asia Afghanistan 2020-02-26 ## 4 Asia Afghanistan 2020-02-27 ## 5 Asia Afghanistan 2020-02-28 ## 6 Asia Afghanistan 2020-02-29 ## 7 Asia Afghanistan 2020-03-01 ## 8 Asia Afghanistan 2020-03-02 ## 9 Asia Afghanistan 2020-03-03 ## 10 Asia Afghanistan 2020-03-04 ## # ... with 196,993 more rows 3.4 列名の変更 データセットの列名（変数名）を変更するときは、dplyr::rename()関数を使用します。 data_owid %&gt;% dplyr::rename(country = location) ## # A tibble: 197,003 x 14 ## continent country date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2020-02-24 5 5 NA ## 2 Asia Afghanistan 2020-02-25 5 0 NA ## 3 Asia Afghanistan 2020-02-26 5 0 NA ## 4 Asia Afghanistan 2020-02-27 5 0 NA ## 5 Asia Afghanistan 2020-02-28 5 0 NA ## 6 Asia Afghanistan 2020-02-29 5 0 0.714 ## 7 Asia Afghanistan 2020-03-01 5 0 0.714 ## 8 Asia Afghanistan 2020-03-02 5 0 0 ## 9 Asia Afghanistan 2020-03-03 5 0 0 ## 10 Asia Afghanistan 2020-03-04 5 0 0 ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 3.5 行のフィルタ データセットの行のフィルタ（特定の条件を満たすデータの抽出）を行うには、dplyr::filter()関数を使用します。 条件に一致する行 data_owid %&gt;% dplyr::filter(location == &quot;Japan&quot;) ## # A tibble: 887 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Japan 2020-01-22 2 NA NA ## 2 Asia Japan 2020-01-23 2 0 NA ## 3 Asia Japan 2020-01-24 2 0 NA ## 4 Asia Japan 2020-01-25 2 0 NA ## 5 Asia Japan 2020-01-26 4 2 NA ## 6 Asia Japan 2020-01-27 4 0 NA ## 7 Asia Japan 2020-01-28 7 3 0.714 ## 8 Asia Japan 2020-01-29 7 0 0.714 ## 9 Asia Japan 2020-01-30 11 4 1.29 ## 10 Asia Japan 2020-01-31 15 4 1.86 ## # ... with 877 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 条件に一致しない行（NOT条件） NOT条件は!=演算子を使用します。 data_owid %&gt;% dplyr::filter(continent != &quot;Asia&quot;) ## # A tibble: 142,997 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Europe Albania 2020-02-25 NA NA NA ## 2 Europe Albania 2020-02-26 NA NA NA ## 3 Europe Albania 2020-02-27 NA NA NA ## 4 Europe Albania 2020-02-28 NA NA NA ## 5 Europe Albania 2020-02-29 NA NA NA ## 6 Europe Albania 2020-03-01 NA NA NA ## 7 Europe Albania 2020-03-02 NA NA NA ## 8 Europe Albania 2020-03-03 NA NA NA ## 9 Europe Albania 2020-03-04 NA NA NA ## 10 Europe Albania 2020-03-05 NA NA NA ## # ... with 142,987 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 複数条件 dplyr::filter()関数内で複数条件を指定すると、左から順番に条件が適用されます。 data_owid %&gt;% dplyr::filter(location == &quot;Japan&quot;, date &gt;= &quot;2021-01-01&quot;, date &lt;= &quot;2021-01-07&quot;) ## # A tibble: 7 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Japan 2021-01-01 239005 3256 3502. ## 2 Asia Japan 2021-01-02 242076 3071 3385. ## 3 Asia Japan 2021-01-03 245242 3166 3417. ## 4 Asia Japan 2021-01-04 248585 3343 3552. ## 5 Asia Japan 2021-01-05 253534 4949 3741. ## 6 Asia Japan 2021-01-06 259583 6049 4052. ## 7 Asia Japan 2021-01-07 267225 7642 4497. ## # ... with 8 more variables: total_deaths &lt;dbl&gt;, new_deaths &lt;dbl&gt;, ## # total_cases_per_million &lt;dbl&gt;, new_cases_per_million &lt;dbl&gt;, ## # total_deaths_per_million &lt;dbl&gt;, new_deaths_per_million &lt;dbl&gt;, ## # people_fully_vaccinated &lt;dbl&gt;, stringency_index &lt;dbl&gt; AND・OR条件を明示的に指定した複数条件 左から順番に条件を適用しないためには、&amp;演算子と|演算子で明示的にAND条件とOR条件を指定します。 data_owid %&gt;% dplyr::filter((date == &quot;2022-01-01&quot;) &amp; (location == &quot;Japan&quot; | location == &quot;United States&quot;)) ## # A tibble: 2 x 14 ## continent location date total_cases new_cases new_cases_smooth~ ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Japan 2022-01-01 1732752 456 344. ## 2 North America United States 2022-01-01 55024381 188764 405168. ## # ... with 8 more variables: total_deaths &lt;dbl&gt;, new_deaths &lt;dbl&gt;, ## # total_cases_per_million &lt;dbl&gt;, new_cases_per_million &lt;dbl&gt;, ## # total_deaths_per_million &lt;dbl&gt;, new_deaths_per_million &lt;dbl&gt;, ## # people_fully_vaccinated &lt;dbl&gt;, stringency_index &lt;dbl&gt; %in%演算子によるOR条件 複数の値が格納されたベクトルと%in%演算子を用いて、OR条件で行をフィルタします。この場合は、日本と米国のレコードを抽出しています。 locations &lt;- c(&quot;Japan&quot;, &quot;United States&quot;) data_owid %&gt;% dplyr::filter(location %in% locations, date == &quot;2021-01-01&quot;) ## # A tibble: 2 x 14 ## continent location date total_cases new_cases new_cases_smooth~ ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Japan 2021-01-01 239005 3256 3502. ## 2 North America United States 2021-01-01 20370219 178902 206423. ## # ... with 8 more variables: total_deaths &lt;dbl&gt;, new_deaths &lt;dbl&gt;, ## # total_cases_per_million &lt;dbl&gt;, new_cases_per_million &lt;dbl&gt;, ## # total_deaths_per_million &lt;dbl&gt;, new_deaths_per_million &lt;dbl&gt;, ## # people_fully_vaccinated &lt;dbl&gt;, stringency_index &lt;dbl&gt; OR条件の否定 %in%演算子によるOR条件を!で否定します。この場合は、日本・米国以外を抽出しています。 data_owid %&gt;% dplyr::filter(!location %in% locations, date == &quot;2021-01-01&quot;) ## # A tibble: 226 x 14 ## continent location date total_cases new_cases new_cases_smoot~ ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2021-01-01 52513 183 131. ## 2 &lt;NA&gt; Africa 2021-01-01 2788203 27749 23359. ## 3 Europe Albania 2021-01-01 58316 0 419. ## 4 Africa Algeria 2021-01-01 99897 287 351. ## 5 Europe Andorra 2021-01-01 8117 68 51.6 ## 6 Africa Angola 2021-01-01 17568 15 67 ## 7 North America Anguilla 2021-01-01 13 0 0.286 ## 8 North America Antigua and ~ 2021-01-01 159 0 0.571 ## 9 South America Argentina 2021-01-01 1629594 4080 7863. ## 10 Asia Armenia 2021-01-01 159738 329 425 ## # ... with 216 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 関数による条件指定 data_owid %&gt;% dplyr::filter(date == max(date)) ## # A tibble: 229 x 14 ## continent location date total_cases new_cases new_cases_smoot~ ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2022-06-26 182149 77 69 ## 2 &lt;NA&gt; Africa 2022-06-26 12027514 3922 6898. ## 3 Europe Albania 2022-06-26 279077 284 238. ## 4 Africa Algeria 2022-06-26 266038 8 9 ## 5 Europe Andorra 2022-06-26 43774 NA NA ## 6 Africa Angola 2022-06-26 99761 0 0 ## 7 North America Anguilla 2022-06-26 3411 0 5.29 ## 8 North America Antigua and ~ 2022-06-26 8625 0 6.29 ## 9 South America Argentina 2022-06-26 9367172 25680 3669. ## 10 Asia Armenia 2022-06-26 423104 0 8.57 ## # ... with 219 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 論理値を返す関数による条件指定 is.na()関数のように倫理値を返す関数は、==演算子がなくてもフィルタ条件として使用することができます。 data_owid %&gt;% dplyr::filter(is.na(new_cases)) ## # A tibble: 8,206 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2020-03-20 24 NA NA ## 2 Asia Afghanistan 2022-01-03 158183 NA NA ## 3 Europe Albania 2020-02-25 NA NA NA ## 4 Europe Albania 2020-02-26 NA NA NA ## 5 Europe Albania 2020-02-27 NA NA NA ## 6 Europe Albania 2020-02-28 NA NA NA ## 7 Europe Albania 2020-02-29 NA NA NA ## 8 Europe Albania 2020-03-01 NA NA NA ## 9 Europe Albania 2020-03-02 NA NA NA ## 10 Europe Albania 2020-03-03 NA NA NA ## # ... with 8,196 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 3.6 行の並べ替え データセットの行を並べ替えるには、dplyr::arrange()関数を使用します。 昇順ソート data_owid %&gt;% dplyr::arrange(new_cases) ## # A tibble: 197,003 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2020-02-25 5 0 NA ## 2 Asia Afghanistan 2020-02-26 5 0 NA ## 3 Asia Afghanistan 2020-02-27 5 0 NA ## 4 Asia Afghanistan 2020-02-28 5 0 NA ## 5 Asia Afghanistan 2020-02-29 5 0 0.714 ## 6 Asia Afghanistan 2020-03-01 5 0 0.714 ## 7 Asia Afghanistan 2020-03-02 5 0 0 ## 8 Asia Afghanistan 2020-03-03 5 0 0 ## 9 Asia Afghanistan 2020-03-04 5 0 0 ## 10 Asia Afghanistan 2020-03-05 5 0 0 ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 降順ソート data_owid %&gt;% dplyr::arrange(-new_cases) ## # A tibble: 197,003 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 &lt;NA&gt; World 2022-01-19 339424957 4079883 3096548. ## 2 &lt;NA&gt; World 2022-01-21 346992314 3835509 3249217. ## 3 &lt;NA&gt; World 2022-01-18 335345074 3760114 3006384. ## 4 &lt;NA&gt; World 2022-01-27 366703190 3751437 3363769. ## 5 &lt;NA&gt; World 2022-01-20 343156805 3731848 3174998. ## 6 &lt;NA&gt; World 2022-01-26 362951753 3655101 3360971. ## 7 &lt;NA&gt; World 2022-01-25 359296652 3651109 3421654 ## 8 &lt;NA&gt; World 2022-01-28 370320392 3617202 3332583. ## 9 &lt;NA&gt; World 2022-01-12 317749122 3448737 2783549. ## 10 &lt;NA&gt; World 2022-01-24 355645543 3420342 3437226. ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 降順ソート（日付型） 日付型のデータは-演算子で降順ソートができないため、desc()関数を使用します。 data_owid %&gt;% dplyr::arrange(desc(date)) ## # A tibble: 197,003 x 14 ## continent location date total_cases new_cases new_cases_smoot~ ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2022-06-26 182149 77 69 ## 2 &lt;NA&gt; Africa 2022-06-26 12027514 3922 6898. ## 3 Europe Albania 2022-06-26 279077 284 238. ## 4 Africa Algeria 2022-06-26 266038 8 9 ## 5 Europe Andorra 2022-06-26 43774 NA NA ## 6 Africa Angola 2022-06-26 99761 0 0 ## 7 North America Anguilla 2022-06-26 3411 0 5.29 ## 8 North America Antigua and ~ 2022-06-26 8625 0 6.29 ## 9 South America Argentina 2022-06-26 9367172 25680 3669. ## 10 Asia Armenia 2022-06-26 423104 0 8.57 ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 複数条件によるソート dplyr::arrange()関数内で複数条件を指定すると、左から順番に適用します。 data_owid %&gt;% dplyr::arrange(desc(date), -new_cases) ## # A tibble: 197,003 x 14 ## continent location date total_cases new_cases new_cases_smoot~ ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 &lt;NA&gt; World 2022-06-26 543602146 276302 662107. ## 2 &lt;NA&gt; High income 2022-06-26 319274034 203959 536784. ## 3 &lt;NA&gt; Asia 2022-06-26 156342581 107628 116122. ## 4 &lt;NA&gt; Europe 2022-06-26 203663592 64958 300633. ## 5 &lt;NA&gt; European Union 2022-06-26 147290542 60923 274714. ## 6 Europe Italy 2022-06-26 18234242 49325 50726 ## 7 &lt;NA&gt; Upper middle inc~ 2022-06-26 131184454 45055 98986. ## 8 Asia Taiwan 2022-06-26 3613345 39642 45467 ## 9 &lt;NA&gt; South America 2022-06-26 59220309 37609 79850. ## 10 &lt;NA&gt; Oceania 2022-06-26 9661693 31884 34099. ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 3.7 列の作成・修正 データセットの列を追加・修正するには、dplyr::mutate()関数を使用します。 まず、使用するサンプルデータを作成します。 data_owid_jp &lt;- data_owid %&gt;% dplyr::select(location, date, new_cases, new_deaths) %&gt;% dplyr::filter(location == &quot;Japan&quot;, date &gt;= &quot;2022-01-01&quot;) 新たな列の作成 既存の列（変数）の計算結果として、新たな列を追加します。=演算子の左側が新たに作成する列名、右側が計算式です。作成する際、.before引数もしくは.after引数に既存の列名を指定すると、指定した列の前後に新たな列を挿入します。.before引数、.after引数を指定しなければ、新たな列は最右列に追加されます。 data_owid_jp %&gt;% dplyr::mutate(death_rate = new_deaths / new_cases, .after = &quot;date&quot;) ## # A tibble: 177 x 5 ## location date death_rate new_cases new_deaths ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Japan 2022-01-01 0 456 0 ## 2 Japan 2022-01-02 0.00419 477 2 ## 3 Japan 2022-01-03 0.00149 672 1 ## 4 Japan 2022-01-04 0.000870 1149 1 ## 5 Japan 2022-01-05 0.000402 2490 1 ## 6 Japan 2022-01-06 0.000233 4297 1 ## 7 Japan 2022-01-07 0.000165 6070 1 ## 8 Japan 2022-01-08 0.000241 8302 2 ## 9 Japan 2022-01-09 0.000124 8071 1 ## 10 Japan 2022-01-10 0.000319 6265 2 ## # ... with 167 more rows 既存の列の修正 =演算子の左側に既存の列名を指定すると、当該列を修正します。 data_owid %&gt;% dplyr::mutate(location = factor(location)) ## # A tibble: 197,003 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;fct&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2020-02-24 5 5 NA ## 2 Asia Afghanistan 2020-02-25 5 0 NA ## 3 Asia Afghanistan 2020-02-26 5 0 NA ## 4 Asia Afghanistan 2020-02-27 5 0 NA ## 5 Asia Afghanistan 2020-02-28 5 0 NA ## 6 Asia Afghanistan 2020-02-29 5 0 0.714 ## 7 Asia Afghanistan 2020-03-01 5 0 0.714 ## 8 Asia Afghanistan 2020-03-02 5 0 0 ## 9 Asia Afghanistan 2020-03-03 5 0 0 ## 10 Asia Afghanistan 2020-03-04 5 0 0 ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 条件付き系列の作成 dplyr::case_when()関数の中に、「既存の系列を用いた条件 ~ 条件を満たす場合にとる値」の形で条件式を書き、新たな系列を作成します。複数条件を指定した場合、左から順番に条件が適用されます。「その他すべて」の条件はTRUEで指定します。 # 単一条件を指定してダミー変数を作成 data_owid_jp %&gt;% dplyr::mutate(dummy = dplyr::case_when(new_cases &lt; 3000 ~ 1, TRUE ~ 0)) ## # A tibble: 177 x 5 ## location date new_cases new_deaths dummy ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Japan 2022-01-01 456 0 1 ## 2 Japan 2022-01-02 477 2 1 ## 3 Japan 2022-01-03 672 1 1 ## 4 Japan 2022-01-04 1149 1 1 ## 5 Japan 2022-01-05 2490 1 1 ## 6 Japan 2022-01-06 4297 1 0 ## 7 Japan 2022-01-07 6070 1 0 ## 8 Japan 2022-01-08 8302 2 0 ## 9 Japan 2022-01-09 8071 1 0 ## 10 Japan 2022-01-10 6265 2 0 ## # ... with 167 more rows # 複数条件を指定 data_owid_jp %&gt;% dplyr::mutate(case = dplyr::case_when(new_cases &lt; 1000 ~ &quot;A&quot;, (new_cases &gt;= 5000 &amp; new_cases &lt; 8000) ~ &quot;B&quot;, TRUE ~ &quot;other&quot;)) ## # A tibble: 177 x 5 ## location date new_cases new_deaths case ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Japan 2022-01-01 456 0 A ## 2 Japan 2022-01-02 477 2 A ## 3 Japan 2022-01-03 672 1 A ## 4 Japan 2022-01-04 1149 1 other ## 5 Japan 2022-01-05 2490 1 other ## 6 Japan 2022-01-06 4297 1 other ## 7 Japan 2022-01-07 6070 1 B ## 8 Japan 2022-01-08 8302 2 other ## 9 Japan 2022-01-09 8071 1 other ## 10 Japan 2022-01-10 6265 2 B ## # ... with 167 more rows 複数列の一括処理 dplyr::mutate()関数内でacross()関数を用い、対象の列と処理方法を指定して一括処理します。~ {}は無名関数（ラムダ式）を表し、波括弧の中のドットはチルダの左側の値を代入することを意味します。 # new_casesからnew_deathまでのすべての列を1000で除す data_owid_jp %&gt;% dplyr::mutate(across(new_cases:new_deaths, ~ {. / 1000})) ## # A tibble: 177 x 4 ## location date new_cases new_deaths ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Japan 2022-01-01 0.456 0 ## 2 Japan 2022-01-02 0.477 0.002 ## 3 Japan 2022-01-03 0.672 0.001 ## 4 Japan 2022-01-04 1.15 0.001 ## 5 Japan 2022-01-05 2.49 0.001 ## 6 Japan 2022-01-06 4.30 0.001 ## 7 Japan 2022-01-07 6.07 0.001 ## 8 Japan 2022-01-08 8.30 0.002 ## 9 Japan 2022-01-09 8.07 0.001 ## 10 Japan 2022-01-10 6.26 0.002 ## # ... with 167 more rows # new_casesからnew_deathまでのすべての列の前期比変化率を計算 data_owid_jp %&gt;% dplyr::mutate(across(new_cases:new_deaths, ~ {. / dplyr::lag(., n = 1)})) ## # A tibble: 177 x 4 ## location date new_cases new_deaths ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Japan 2022-01-01 NA NA ## 2 Japan 2022-01-02 1.05 Inf ## 3 Japan 2022-01-03 1.41 0.5 ## 4 Japan 2022-01-04 1.71 1 ## 5 Japan 2022-01-05 2.17 1 ## 6 Japan 2022-01-06 1.73 1 ## 7 Japan 2022-01-07 1.41 1 ## 8 Japan 2022-01-08 1.37 2 ## 9 Japan 2022-01-09 0.972 0.5 ## 10 Japan 2022-01-10 0.776 2 ## # ... with 167 more rows # すべての列を文字列型に変換 data_owid_jp %&gt;% dplyr::mutate(across(everything(), as.character)) ## # A tibble: 177 x 4 ## location date new_cases new_deaths ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Japan 2022-01-01 456 0 ## 2 Japan 2022-01-02 477 2 ## 3 Japan 2022-01-03 672 1 ## 4 Japan 2022-01-04 1149 1 ## 5 Japan 2022-01-05 2490 1 ## 6 Japan 2022-01-06 4297 1 ## 7 Japan 2022-01-07 6070 1 ## 8 Japan 2022-01-08 8302 2 ## 9 Japan 2022-01-09 8071 1 ## 10 Japan 2022-01-10 6265 2 ## # ... with 167 more rows 3.8 グループ化 データセットを属性ごとにグループ化するには、dplyr::group_by()関数を使用します。グループ化するだけでは変化はありませんが、dplyr::filter()関数や、次のdplyr::summarise()関数とあわせて使用することで、より柔軟なデータセット操作が可能になります。 単一の列でグループ化 見た目は変わりませんが、データをprint()関数で出力するとデータの属性を示す冒頭箇所の2行目にGroupsが追加されています。 data_owid %&gt;% dplyr::group_by(location) %&gt;% print() ## # A tibble: 197,003 x 14 ## # Groups: location [244] ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2020-02-24 5 5 NA ## 2 Asia Afghanistan 2020-02-25 5 0 NA ## 3 Asia Afghanistan 2020-02-26 5 0 NA ## 4 Asia Afghanistan 2020-02-27 5 0 NA ## 5 Asia Afghanistan 2020-02-28 5 0 NA ## 6 Asia Afghanistan 2020-02-29 5 0 0.714 ## 7 Asia Afghanistan 2020-03-01 5 0 0.714 ## 8 Asia Afghanistan 2020-03-02 5 0 0 ## 9 Asia Afghanistan 2020-03-03 5 0 0 ## 10 Asia Afghanistan 2020-03-04 5 0 0 ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 複数の列でグループ化 data_owid %&gt;% dplyr::group_by(continent, location) %&gt;% print() ## # A tibble: 197,003 x 14 ## # Groups: continent, location [244] ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2020-02-24 5 5 NA ## 2 Asia Afghanistan 2020-02-25 5 0 NA ## 3 Asia Afghanistan 2020-02-26 5 0 NA ## 4 Asia Afghanistan 2020-02-27 5 0 NA ## 5 Asia Afghanistan 2020-02-28 5 0 NA ## 6 Asia Afghanistan 2020-02-29 5 0 0.714 ## 7 Asia Afghanistan 2020-03-01 5 0 0.714 ## 8 Asia Afghanistan 2020-03-02 5 0 0 ## 9 Asia Afghanistan 2020-03-03 5 0 0 ## 10 Asia Afghanistan 2020-03-04 5 0 0 ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; グループ化＆フィルタ グループ化と行のフィルタを組み合わせて、グループ別にフィルタを適用します。ここでは、グループ別の最大値を抽出しています。 data_owid %&gt;% dplyr::group_by(location) %&gt;% dplyr::filter(new_cases == max(new_cases, na.rm = TRUE)) ## # A tibble: 230 x 14 ## # Groups: location [229] ## continent location date total_cases new_cases new_cases_smoot~ ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2021-06-17 96531 3243 1520. ## 2 &lt;NA&gt; Africa 2021-12-30 9703618 60523 42669. ## 3 Europe Albania 2022-01-09 219694 4789 1258. ## 4 Africa Algeria 2022-01-25 241406 2521 1978. ## 5 Europe Andorra 2022-01-20 32201 2313 472. ## 6 Africa Angola 2021-12-28 76787 5035 1460. ## 7 North America Anguilla 2022-05-10 2984 196 28 ## 8 North America Antigua and ~ 2022-02-10 7321 468 84.1 ## 9 South America Argentina 2022-01-14 6932972 139853 113877. ## 10 Asia Armenia 2022-02-03 379266 4388 3007. ## # ... with 220 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; グループ化の解除 dplyr::ungroup()関数でグループ化を解除します。グループ化の有無でフィルタや集計の結果が変わるため、思わぬ事故を防ぐためにも、所定の結果を得た後はグループ化を解除しておくことを推奨します。 data_owid %&gt;% dplyr::group_by(location) %&gt;% dplyr::ungroup() ## # A tibble: 197,003 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2020-02-24 5 5 NA ## 2 Asia Afghanistan 2020-02-25 5 0 NA ## 3 Asia Afghanistan 2020-02-26 5 0 NA ## 4 Asia Afghanistan 2020-02-27 5 0 NA ## 5 Asia Afghanistan 2020-02-28 5 0 NA ## 6 Asia Afghanistan 2020-02-29 5 0 0.714 ## 7 Asia Afghanistan 2020-03-01 5 0 0.714 ## 8 Asia Afghanistan 2020-03-02 5 0 0 ## 9 Asia Afghanistan 2020-03-03 5 0 0 ## 10 Asia Afghanistan 2020-03-04 5 0 0 ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; 3.9 集計 グループ化したデータセットに対してdplyr::summarise()関数を使用すると、グループ別に集計操作を行うことができます。 グループ別の集計 # 指定した列のグループ別の平均値を計算 data_owid %&gt;% dplyr::group_by(location) %&gt;% dplyr::summarise(new_cases_mean = mean(new_cases, na.rm = TRUE)) ## # A tibble: 244 x 2 ## location new_cases_mean ## &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan 214. ## 2 Africa 13885. ## 3 Albania 332. ## 4 Algeria 312. ## 5 Andorra 51.9 ## 6 Angola 120. ## 7 Anguilla 4.15 ## 8 Antigua and Barbuda 10.3 ## 9 Argentina 11072. ## 10 Armenia 499. ## # ... with 234 more rows # 指定した列のグループ別の最大値を計算 data_owid %&gt;% dplyr::group_by(location) %&gt;% dplyr::summarise(new_cases_max = max(new_cases, na.rm = TRUE)) ## # A tibble: 244 x 2 ## location new_cases_max ## &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan 3243 ## 2 Africa 60523 ## 3 Albania 4789 ## 4 Algeria 2521 ## 5 Andorra 2313 ## 6 Angola 5035 ## 7 Anguilla 196 ## 8 Antigua and Barbuda 468 ## 9 Argentina 139853 ## 10 Armenia 4388 ## # ... with 234 more rows クロス集計 dplyr::group_by()関数で複数条件を指定してグループ化すると、クロス集計を行うことができます。 data_owid %&gt;% dplyr::group_by(location, lubridate::year(date)) %&gt;% dplyr::summarise(new_cases_mean = mean(new_cases, na.rm = TRUE)) ## `summarise()` has grouped output by &#39;location&#39;. You can override using the ## `.groups` argument. ## # A tibble: 711 x 3 ## # Groups: location [244] ## location `lubridate::year(date)` new_cases_mean ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 2020 168. ## 2 Afghanistan 2021 290. ## 3 Afghanistan 2022 137. ## 4 Africa 2020 8548. ## 5 Africa 2021 19116. ## 6 Africa 2022 12837. ## 7 Albania 2020 196. ## 8 Albania 2021 416. ## 9 Albania 2022 389 ## 10 Algeria 2020 320. ## # ... with 701 more rows 複数列の一括処理 dplyr::summarise()関数内でacross()関数を用い、対象の列と処理方法を指定して一括処理します。 # new_casesとnew_deathsの列について、グループ別の合計値を計算 data_owid %&gt;% dplyr::group_by(location) %&gt;% dplyr::summarise(across(c(new_cases, new_deaths), sum, na.rm = TRUE)) ## # A tibble: 244 x 3 ## location new_cases new_deaths ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 182157 7717 ## 2 Africa 12010429 254711 ## 3 Albania 279077 3497 ## 4 Algeria 266038 6875 ## 5 Andorra 43774 155 ## 6 Angola 99761 1903 ## 7 Anguilla 3411 10 ## 8 Antigua and Barbuda 8627 141 ## 9 Argentina 9367172 129070 ## 10 Armenia 423104 8631 ## # ... with 234 more rows # 列名がcasesで終わる列すべてについて、グループ別の合計値を計算 # 列名per_millionで終わる列すべてについて、グループ別の平均値を計算 data_owid %&gt;% dplyr::group_by(location) %&gt;% dplyr::summarise(across(ends_with(&quot;cases&quot;), sum, na.rm = TRUE), across(ends_with(&quot;per_million&quot;), mean, na.rm = TRUE)) ## # A tibble: 244 x 7 ## location total_cases new_cases total_cases_per_m~ new_cases_per_m~ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 78807309 182157 2317. 5.37 ## 2 Africa 4529793588 12010429 3817. 10.1 ## 3 Albania 101981026 279077 42259. 116. ## 4 Algeria 113571060 266038 2984. 6.99 ## 5 Andorra 12608449 43774 192440. 671. ## 6 Angola 33489405 99761 1190. 3.55 ## 7 Anguilla 608115 3411 48972. 275. ## 8 Antigua and Barbuda 2004045 8627 24281. 105. ## 9 Argentina 3127738069 9367172 81066. 243. ## 10 Armenia 172835780 423104 68668. 168. ## # ... with 234 more rows, and 2 more variables: total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt; # 数値型の列すべてについて、グループ別の平均値を計算 data_owid %&gt;% dplyr::group_by(location) %&gt;% dplyr::summarise(across(is.double, mean, na.rm = TRUE)) ## # A tibble: 244 x 13 ## location date total_cases new_cases new_cases_smoot~ total_deaths ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 2021-04-25 92280. 214. 215. 4141. ## 2 Africa 2021-04-20 5242817. 13885. 13944. 128379. ## 3 Albania 2021-04-26 121406. 332. 333. 1872. ## 4 Algeria 2021-04-26 133143. 312. 314. 3752. ## 5 Andorra 2021-04-29 14886. 51.9 51.9 105. ## 6 Angola 2021-05-08 40397. 120. 121. 903. ## 7 Anguilla 2021-05-12 741. 4.15 4.18 6.30 ## 8 Antigua and B~ 2021-05-04 2397. 10.3 10.4 53.1 ## 9 Argentina 2021-03-29 3697090. 11072. 11112. 68703. ## 10 Armenia 2021-04-15 203816. 499. 502. 4230. ## # ... with 234 more rows, and 7 more variables: new_deaths &lt;dbl&gt;, ## # total_cases_per_million &lt;dbl&gt;, new_cases_per_million &lt;dbl&gt;, ## # total_deaths_per_million &lt;dbl&gt;, new_deaths_per_million &lt;dbl&gt;, ## # people_fully_vaccinated &lt;dbl&gt;, stringency_index &lt;dbl&gt; 3.10 縦型・横型の変換 tidyrパッケージのpivot_longer()関数とpivot_wider()関数を使用して、縦型データ（tidy data）と横型データの変換を行います。なお、縦型データは、ggplot2パッケージによるグラフ作成で多用します。 まず、使用するサンプルデータを作成します。 data_owid_cases &lt;- data_owid %&gt;% dplyr::select(location, date, new_cases) %&gt;% dplyr::filter(date &gt;= &quot;2021-01-01&quot;) %&gt;% dplyr::arrange(date) data_owid_cases ## # A tibble: 128,619 x 3 ## location date new_cases ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 Afghanistan 2021-01-01 183 ## 2 Africa 2021-01-01 27749 ## 3 Albania 2021-01-01 0 ## 4 Algeria 2021-01-01 287 ## 5 Andorra 2021-01-01 68 ## 6 Angola 2021-01-01 15 ## 7 Anguilla 2021-01-01 0 ## 8 Antigua and Barbuda 2021-01-01 0 ## 9 Argentina 2021-01-01 4080 ## 10 Armenia 2021-01-01 329 ## # ... with 128,609 more rows 縦型データを横型データに変換 data_owid_cases_wide &lt;- data_owid_cases %&gt;% tidyr::pivot_wider(id_cols = &quot;date&quot;, names_from = &quot;location&quot;, values_from = &quot;new_cases&quot;) data_owid_cases_wide ## # A tibble: 542 x 245 ## date Afghanistan Africa Albania Algeria Andorra Angola Anguilla ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2021-01-01 183 27749 0 287 68 15 0 ## 2 2021-01-02 73 22890 675 262 49 40 0 ## 3 2021-01-03 123 21995 447 249 26 34 2 ## 4 2021-01-04 200 21775 185 237 57 42 0 ## 5 2021-01-05 102 26845 660 228 59 72 0 ## 6 2021-01-06 94 35789 725 247 40 108 0 ## 7 2021-01-07 102 35437 697 262 0 110 0 ## 8 2021-01-08 125 36440 673 275 141 92 0 ## 9 2021-01-09 68 35072 655 256 97 90 0 ## 10 2021-01-10 89 31638 562 231 0 37 0 ## # ... with 532 more rows, and 237 more variables: `Antigua and Barbuda` &lt;dbl&gt;, ## # Argentina &lt;dbl&gt;, Armenia &lt;dbl&gt;, Aruba &lt;dbl&gt;, Asia &lt;dbl&gt;, Australia &lt;dbl&gt;, ## # Austria &lt;dbl&gt;, Azerbaijan &lt;dbl&gt;, Bahamas &lt;dbl&gt;, Bahrain &lt;dbl&gt;, ## # Bangladesh &lt;dbl&gt;, Barbados &lt;dbl&gt;, Belarus &lt;dbl&gt;, Belgium &lt;dbl&gt;, ## # Belize &lt;dbl&gt;, Benin &lt;dbl&gt;, Bermuda &lt;dbl&gt;, Bhutan &lt;dbl&gt;, Bolivia &lt;dbl&gt;, ## # `Bonaire Sint Eustatius and Saba` &lt;dbl&gt;, `Bosnia and Herzegovina` &lt;dbl&gt;, ## # Botswana &lt;dbl&gt;, Brazil &lt;dbl&gt;, `British Virgin Islands` &lt;dbl&gt;, ... 横型データを縦型データに変換 data_owid_cases_long &lt;- data_owid_cases_wide %&gt;% tidyr::pivot_longer(cols = -&quot;date&quot;, names_to = &quot;location&quot;, values_to = &quot;new_cases&quot;) data_owid_cases_long ## # A tibble: 132,248 x 3 ## date location new_cases ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2021-01-01 Afghanistan 183 ## 2 2021-01-01 Africa 27749 ## 3 2021-01-01 Albania 0 ## 4 2021-01-01 Algeria 287 ## 5 2021-01-01 Andorra 68 ## 6 2021-01-01 Angola 15 ## 7 2021-01-01 Anguilla 0 ## 8 2021-01-01 Antigua and Barbuda 0 ## 9 2021-01-01 Argentina 4080 ## 10 2021-01-01 Armenia 329 ## # ... with 132,238 more rows 3.11 データの結合 複数のデータセットのオブジェクトを結合して一つのデータセットにするには、dplyrパッケージのjoin()関数ファミリーを使用します。join()関数は、結合方法によって4種類に分かれています。 まず、使用するサンプルデータを確認します。 band_members ## # A tibble: 3 x 2 ## name band ## &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones ## 2 John Beatles ## 3 Paul Beatles band_instruments ## # A tibble: 3 x 2 ## name plays ## &lt;chr&gt; &lt;chr&gt; ## 1 John guitar ## 2 Paul bass ## 3 Keith guitar 内部結合 dplyr::inner_join()関数は、両方のデータに共通して存在する行のみ結合し、その他の行は削除します。 dplyr::inner_join(band_members, band_instruments, by = &quot;name&quot;) ## # A tibble: 2 x 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Beatles guitar ## 2 Paul Beatles bass 左外部結合 dplyr::left_join()関数は、左側のデータに存在する行のみ結合し、その他の行は削除します。 dplyr::left_join(band_members, band_instruments, by = &quot;name&quot;) ## # A tibble: 3 x 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones &lt;NA&gt; ## 2 John Beatles guitar ## 3 Paul Beatles bass 右外部結合 dplyr::right_join()関数は、右側のデータに存在する行のみ結合し、その他の行は削除します。 dplyr::right_join(band_members, band_instruments, by = &quot;name&quot;) ## # A tibble: 3 x 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Beatles guitar ## 2 Paul Beatles bass ## 3 Keith &lt;NA&gt; guitar 完全外部結合 dplyr::full_join()関数は、両方のデータのすべての行を結合し、行を削除しません。 dplyr::full_join(band_members, band_instruments, by = &quot;name&quot;) ## # A tibble: 4 x 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones &lt;NA&gt; ## 2 John Beatles guitar ## 3 Paul Beatles bass ## 4 Keith &lt;NA&gt; guitar 3.12 重複処理 重複行の抽出 重複している行を抽出するには、dplyr::group_by()関数、dplyr::filter()関数、dplyr::n()関数を組み合わせて使用します。dplyr::n()関数は、dplyr::group_by()関数で指定したグループのサイズを返す関数です。 # 指定した列を対象にして、重複している行を抽出 mpg %&gt;% dplyr::group_by(manufacturer, model, displ, year, cyl, trans, cty, hwy) %&gt;% dplyr::filter(dplyr::n() &gt; 1) ## # A tibble: 18 x 11 ## # Groups: manufacturer, model, displ, year, cyl, trans, cty, hwy [9] ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chevrolet c1500 sub~ 5.3 2008 8 auto~ r 14 20 r suv ## 2 chevrolet c1500 sub~ 5.3 2008 8 auto~ r 14 20 r suv ## 3 dodge caravan 2~ 3.3 1999 6 auto~ f 16 22 r mini~ ## 4 dodge caravan 2~ 3.3 1999 6 auto~ f 16 22 r mini~ ## 5 dodge caravan 2~ 3.3 2008 6 auto~ f 17 24 r mini~ ## 6 dodge caravan 2~ 3.3 2008 6 auto~ f 17 24 r mini~ ## 7 dodge dakota pi~ 4.7 2008 8 auto~ 4 14 19 r pick~ ## 8 dodge dakota pi~ 4.7 2008 8 auto~ 4 14 19 r pick~ ## 9 dodge durango 4~ 4.7 2008 8 auto~ 4 13 17 r suv ## 10 dodge durango 4~ 4.7 2008 8 auto~ 4 13 17 r suv ## 11 dodge ram 1500 ~ 4.7 2008 8 manu~ 4 12 16 r pick~ ## 12 dodge ram 1500 ~ 4.7 2008 8 auto~ 4 13 17 r pick~ ## 13 dodge ram 1500 ~ 4.7 2008 8 auto~ 4 13 17 r pick~ ## 14 dodge ram 1500 ~ 4.7 2008 8 manu~ 4 12 16 r pick~ ## 15 ford explorer ~ 4 1999 6 auto~ 4 14 17 r suv ## 16 ford explorer ~ 4 1999 6 auto~ 4 14 17 r suv ## 17 honda civic 1.6 1999 4 auto~ f 24 32 r subc~ ## 18 honda civic 1.6 1999 4 auto~ f 24 32 r subc~ 重複行の削除 重複している行を削除するには、dplyr::distinct()関数を使用します。 # すべての列を対象にして、重複している行を削除 data_owid %&gt;% dplyr::distinct() ## # A tibble: 197,003 x 14 ## continent location date total_cases new_cases new_cases_smoothed ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 2020-02-24 5 5 NA ## 2 Asia Afghanistan 2020-02-25 5 0 NA ## 3 Asia Afghanistan 2020-02-26 5 0 NA ## 4 Asia Afghanistan 2020-02-27 5 0 NA ## 5 Asia Afghanistan 2020-02-28 5 0 NA ## 6 Asia Afghanistan 2020-02-29 5 0 0.714 ## 7 Asia Afghanistan 2020-03-01 5 0 0.714 ## 8 Asia Afghanistan 2020-03-02 5 0 0 ## 9 Asia Afghanistan 2020-03-03 5 0 0 ## 10 Asia Afghanistan 2020-03-04 5 0 0 ## # ... with 196,993 more rows, and 8 more variables: total_deaths &lt;dbl&gt;, ## # new_deaths &lt;dbl&gt;, total_cases_per_million &lt;dbl&gt;, ## # new_cases_per_million &lt;dbl&gt;, total_deaths_per_million &lt;dbl&gt;, ## # new_deaths_per_million &lt;dbl&gt;, people_fully_vaccinated &lt;dbl&gt;, ## # stringency_index &lt;dbl&gt; # 指定した列を対象にして、重複している行を削除 data_owid %&gt;% dplyr::distinct(continent, location) ## # A tibble: 244 x 2 ## continent location ## &lt;chr&gt; &lt;chr&gt; ## 1 Asia Afghanistan ## 2 &lt;NA&gt; Africa ## 3 Europe Albania ## 4 Africa Algeria ## 5 Europe Andorra ## 6 Africa Angola ## 7 North America Anguilla ## 8 North America Antigua and Barbuda ## 9 South America Argentina ## 10 Asia Armenia ## # ... with 234 more rows 3.13 欠損値処理 欠損値（NA）がある行を削除したり、NAのレコードを他の値で置き換えたりするには、tidyrパッケージのdrop_na()関数、replace_na()関数、fill()関数を使用します。 まず、使用するサンプルデータを作成します。 data_owid_vaccinated &lt;- data_owid %&gt;% dplyr::select(location, date, people_fully_vaccinated) %&gt;% dplyr::filter(location %in% c(&quot;Japan&quot;, &quot;United States&quot;, &quot;United Kingdom&quot;), date &gt;= &quot;2021-01-01&quot;) %&gt;% dplyr::arrange(date) %&gt;% tidyr::pivot_wider(id_cols = &quot;date&quot;, names_from = &quot;location&quot;, values_from = &quot;people_fully_vaccinated&quot;) tail(data_owid_vaccinated) ## # A tibble: 6 x 4 ## date Japan `United Kingdom` `United States` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-06-21 102311098 NA 222123223 ## 2 2022-06-22 102314549 NA NA ## 3 2022-06-23 102316683 NA NA ## 4 2022-06-24 NA NA NA ## 5 2022-06-25 NA NA NA ## 6 2022-06-26 NA NA NA NAの削除 特定の列を対象にして、NAが含まれている行を削除するには、tidyr::drop_na()関数で列名を指定します。 data_owid_vaccinated %&gt;% tidyr::drop_na(Japan) %&gt;% tail() ## # A tibble: 6 x 4 ## date Japan `United Kingdom` `United States` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-06-18 102298735 NA 222098880 ## 2 2022-06-19 102302895 NA 222106166 ## 3 2022-06-20 102307177 NA 222119988 ## 4 2022-06-21 102311098 NA 222123223 ## 5 2022-06-22 102314549 NA NA ## 6 2022-06-23 102316683 NA NA すべての列を対象にして、NAが含まれている行を削除するには、tidyr::drop_na()関数の中でeverything()関数を使用します。 data_owid_vaccinated %&gt;% tidyr::drop_na(everything()) %&gt;% tail() ## # A tibble: 6 x 4 ## date Japan `United Kingdom` `United States` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-06-10 102212582 50052124 221901038 ## 2 2022-06-11 102235673 50064052 221920340 ## 3 2022-06-12 102241698 50069860 221931694 ## 4 2022-06-13 102248512 50074143 221961735 ## 5 2022-06-14 102255544 50077673 221991861 ## 6 2022-06-15 102262236 50082651 222022705 NAの置換 特定の列のNAを別の値に置き換えるには、tidyr::replace_na()関数で列名と置換する値を指定します。 data_owid_vaccinated %&gt;% dplyr::mutate(Japan = tidyr::replace_na(data = Japan, replace = 0)) %&gt;% tail() ## # A tibble: 6 x 4 ## date Japan `United Kingdom` `United States` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-06-21 102311098 NA 222123223 ## 2 2022-06-22 102314549 NA NA ## 3 2022-06-23 102316683 NA NA ## 4 2022-06-24 0 NA NA ## 5 2022-06-25 0 NA NA ## 6 2022-06-26 0 NA NA NAを他の値に置き換える列が複数ある場合は、dplyr::mutate_at()関数で列名を複数指定して一括処理します。 data_owid_vaccinated %&gt;% dplyr::mutate_at(vars(-date), tidyr::replace_na, replace = 0) %&gt;% tail() ## # A tibble: 6 x 4 ## date Japan `United Kingdom` `United States` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-06-21 102311098 0 222123223 ## 2 2022-06-22 102314549 0 0 ## 3 2022-06-23 102316683 0 0 ## 4 2022-06-24 0 0 0 ## 5 2022-06-25 0 0 0 ## 6 2022-06-26 0 0 0 NAのフィル 特定の列のNAを同じ列の前後の値でフィルするには、tidyr::fill()関数で列名を指定します。.direction引数が\"down\"なら上にある値を使用して下向きにフィル、\"up\"なら下にある値を使用して上向きにフィルします。 data_owid_vaccinated %&gt;% tidyr::fill(Japan, .direction = &quot;down&quot;) %&gt;% tail() ## # A tibble: 6 x 4 ## date Japan `United Kingdom` `United States` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-06-21 102311098 NA 222123223 ## 2 2022-06-22 102314549 NA NA ## 3 2022-06-23 102316683 NA NA ## 4 2022-06-24 102316683 NA NA ## 5 2022-06-25 102316683 NA NA ## 6 2022-06-26 102316683 NA NA すべての列のNAの値をフィルする場合は、tidyr::fill()関数の中でeverything()関数を使用します。 data_owid_vaccinated %&gt;% tidyr::fill(c(-date, everything()), .direction = &quot;down&quot;) %&gt;% tail() ## # A tibble: 6 x 4 ## date Japan `United Kingdom` `United States` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-06-21 102311098 50082651 222123223 ## 2 2022-06-22 102314549 50082651 222123223 ## 3 2022-06-23 102316683 50082651 222123223 ## 4 2022-06-24 102316683 50082651 222123223 ## 5 2022-06-25 102316683 50082651 222123223 ## 6 2022-06-26 102316683 50082651 222123223 3.14 補完処理 データセットが特定の属性の組み合わせのレコード（行）を欠いている場合や、時系列データで特定の時点のレコード（行）が含まれていない場合は、tidyr::complete()関数で補完することができます。 まず、使用するサンプルデータを作成します。 # サンプルデータ1 data_complete_1 &lt;- tibble( group = c(1:2, 1, 2), item_id = c(1:2, 2, 3), item_name = c(&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;), value1 = c(1, NA, 3, 4), value2 = 4:7 ) data_complete_1 ## # A tibble: 4 x 5 ## group item_id item_name value1 value2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 1 a 1 4 ## 2 2 2 a NA 5 ## 3 1 2 b 3 6 ## 4 2 3 b 4 7 # サンプルデータ2 data_complete_2 &lt;- tibble( date = as.Date(c(&quot;2022-01-01&quot;, &quot;2022-01-03&quot;, &quot;2022-01-04&quot;)), value = c(11, 13, 14) ) data_complete_2 ## # A tibble: 3 x 2 ## date value ## &lt;date&gt; &lt;dbl&gt; ## 1 2022-01-01 11 ## 2 2022-01-03 13 ## 3 2022-01-04 14 組み合わせ候補の補完 tidyr::complete()関数の中で列名を指定し、当該変数のすべての組み合わせ候補を補完します。補完した行の値はNAになります。 data_complete_1 %&gt;% tidyr::complete(group, item_id, item_name) ## # A tibble: 12 x 5 ## group item_id item_name value1 value2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 1 a 1 4 ## 2 1 1 b NA NA ## 3 1 2 a NA NA ## 4 1 2 b 3 6 ## 5 1 3 a NA NA ## 6 1 3 b NA NA ## 7 2 1 a NA NA ## 8 2 1 b NA NA ## 9 2 2 a NA 5 ## 10 2 2 b NA NA ## 11 2 3 a NA NA ## 12 2 3 b 4 7 tidyr::nesting()関数に複数の列名を指定すると、それらの列について実現値のユニークな組み合わせをあらかじめ求め、それと別の列とのすべての組み合わせ候補を補完します。 data_complete_1 %&gt;% tidyr::complete(group, tidyr::nesting(item_id, item_name)) ## # A tibble: 8 x 5 ## group item_id item_name value1 value2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 1 a 1 4 ## 2 1 2 a NA NA ## 3 1 2 b 3 6 ## 4 1 3 b NA NA ## 5 2 1 a NA NA ## 6 2 2 a NA 5 ## 7 2 2 b NA NA ## 8 2 3 b 4 7 時系列データの補完 時系列データの欠損期間を補完するには、full_seq()関数を使用します。 # 日次データの欠損日を補完 data_complete_2 %&gt;% tidyr::complete(date = full_seq(date, period = 1)) ## # A tibble: 4 x 2 ## date value ## &lt;date&gt; &lt;dbl&gt; ## 1 2022-01-01 11 ## 2 2022-01-02 NA ## 3 2022-01-03 13 ## 4 2022-01-04 14 3.15 サンプリング データセットからデータをサンプリングするには、dplyr::sample関数ファミリーを使用します。ここでは、53940サンプルあるdiamondsデータセットからサンプリングを行います。 diamonds ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4 4.05 2.39 ## # ... with 53,930 more rows サンプル数を決めてサンプリングするには、dplyr::sample_n()関数を使用します。 diamonds %&gt;% dplyr::sample_n(size = 1000) ## # A tibble: 1,000 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.75 Ideal I SI1 61.8 56 13393 7.67 7.71 4.75 ## 2 1.13 Very Good E SI2 60.3 58 5052 6.78 6.86 4.11 ## 3 0.5 Ideal H IF 61.1 58 1844 5.1 5.14 3.13 ## 4 1.02 Premium H VS1 62.1 59 5569 6.43 6.38 3.98 ## 5 0.38 Premium I VS2 62.5 58 633 4.58 4.61 2.87 ## 6 0.3 Ideal G VS1 61.8 57 624 4.29 4.32 2.66 ## 7 0.47 Premium G VS2 61 59 1116 5.03 5 3.06 ## 8 0.6 Ideal D VS2 62.8 57 2061 5.37 5.39 3.38 ## 9 0.82 Ideal I VS1 61.4 57 2557 5.98 6.03 3.69 ## 10 2.25 Very Good J SI2 58.4 63 13597 8.6 8.65 5.04 ## # ... with 990 more rows サンプル数をオリジナルデータセットのサンプル数の比率で決定する場合は、dplyr::sample_frac()関数を使用します。 diamonds %&gt;% dplyr::sample_frac(size = 0.1) ## # A tibble: 5,394 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.01 Very Good F SI2 60.8 63 4017 6.38 6.32 3.86 ## 2 0.3 Premium E VS2 62.9 58 844 4.24 4.22 2.66 ## 3 0.32 Premium H VVS1 62.7 57 936 4.41 4.36 2.75 ## 4 2.38 Very Good J VS2 62.6 59 16126 8.49 8.52 5.32 ## 5 0.9 Very Good D SI1 59.6 62 4693 6.19 6.22 3.7 ## 6 1.02 Premium G SI1 61 59 4633 6.44 6.48 3.94 ## 7 0.42 Ideal G VVS1 61.4 56 1235 4.83 4.81 2.96 ## 8 0.81 Premium H VS1 61.7 58 3107 5.98 5.95 3.68 ## 9 1.05 Premium G VS2 61.8 58 6181 6.59 6.52 4.05 ## 10 0.33 Very Good H VS2 62 59 521 4.4 4.44 2.74 ## # ... with 5,384 more rows "],["時系列データ操作.html", "4 時系列データ操作 4.1 第4章の準備 4.2 データ変換 4.3 時系列データの頻度変換 4.4 季節調整（X-13） 4.5 季節調整（STL分解） 4.6 トレンド推定", " 4 時系列データ操作 第4章「時系列データ操作」では、時系列データに特有のデータ操作方法について解説します。時系列データ特有の操作とは、変化率やラグなどのデータ変換、日次・月次などの頻度変換、季節調整、トレンド推定などです。 Rで時系列データを扱う方法には、主に次の2つがあります。 まず、第3章で使用したtibble形式です。tibble形式は複数の列を含むデータフレームの形状をしており、データそのものを格納する列と、日付型データを格納する列を組み合わせることで、時系列データを扱うことができます。 もう一つはts型です。ts型はデータと日付があらかじめセットになった一次元のデータ構造で、季節調整を行うseasonalパッケージなどで使用されます。 4.1 第4章の準備 パッケージのインポート library(forecast) library(mgcv) library(pbapply) library(seasonal) library(seasonalview) library(tidyquant) library(tidyverse) library(zoo) 外部データセットの取得 この章では、外部データセットとして以下のデータを使用します。第1章のコードを使用してあらかじめウェブからデータセットを取得してください。 OWIDのCOVID-19データセット： data_owid 日本の産業別就業者数： data_labor 4.2 データ変換 ここでは、時系列データのラグ・リード系列、変化率、移動平均を計算する方法を解説します。 まず、Our World in Dataのdata_owidデータセットから使用するサンプルデータを作成します。 data_owid_jp &lt;- data_owid %&gt;% dplyr::select(location, date, new_cases, new_deaths) %&gt;% dplyr::filter(location == &quot;Japan&quot;, date &gt;= &quot;2022-01-01&quot;) ラグ・リード系列の作成 dplyr::lag()関数とdplyr::leag()関数で、既存の列のラグ・リード系列を作成します。 # 1期ラグの系列を追加 data_owid_jp %&gt;% dplyr::mutate(new_cases_lag = dplyr::lag(new_cases, n = 1)) ## # A tibble: 177 x 5 ## location date new_cases new_deaths new_cases_lag ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Japan 2022-01-01 456 0 NA ## 2 Japan 2022-01-02 477 2 456 ## 3 Japan 2022-01-03 672 1 477 ## 4 Japan 2022-01-04 1149 1 672 ## 5 Japan 2022-01-05 2490 1 1149 ## 6 Japan 2022-01-06 4297 1 2490 ## 7 Japan 2022-01-07 6070 1 4297 ## 8 Japan 2022-01-08 8302 2 6070 ## 9 Japan 2022-01-09 8071 1 8302 ## 10 Japan 2022-01-10 6265 2 8071 ## # ... with 167 more rows 変化率系列の作成 dplyr::lag()関数で、既存の列の変化率系列を作成します。 # 前期比変化率（％表示）の系列を追加 data_owid_jp %&gt;% dplyr::mutate(new_cases_chg = 100 * (new_cases / dplyr::lag(new_cases, n = 1) - 1)) ## # A tibble: 177 x 5 ## location date new_cases new_deaths new_cases_chg ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Japan 2022-01-01 456 0 NA ## 2 Japan 2022-01-02 477 2 4.61 ## 3 Japan 2022-01-03 672 1 40.9 ## 4 Japan 2022-01-04 1149 1 71.0 ## 5 Japan 2022-01-05 2490 1 117. ## 6 Japan 2022-01-06 4297 1 72.6 ## 7 Japan 2022-01-07 6070 1 41.3 ## 8 Japan 2022-01-08 8302 2 36.8 ## 9 Japan 2022-01-09 8071 1 -2.78 ## 10 Japan 2022-01-10 6265 2 -22.4 ## # ... with 167 more rows 移動平均系列の作成 zooパッケージのrollmean()関数で、移動平均系列を作成します。 # 後方7日移動平均の系列を追加 data_owid_jp %&gt;% dplyr::mutate(new_cases_7dma = zoo::rollmean(new_cases, # 移動平均を作成するもとの系列名 k = 7, # 移動平均の期間 na.pad = TRUE, # 系列の先端部分で移動平均を計算できない箇所をNAで埋めるか align = &quot;right&quot;)) # left：前方移動平均、center：中央移動平均、right：後方移動平均 ## # A tibble: 177 x 5 ## location date new_cases new_deaths new_cases_7dma ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Japan 2022-01-01 456 0 NA ## 2 Japan 2022-01-02 477 2 NA ## 3 Japan 2022-01-03 672 1 NA ## 4 Japan 2022-01-04 1149 1 NA ## 5 Japan 2022-01-05 2490 1 NA ## 6 Japan 2022-01-06 4297 1 NA ## 7 Japan 2022-01-07 6070 1 2230. ## 8 Japan 2022-01-08 8302 2 3351 ## 9 Japan 2022-01-09 8071 1 4436. ## 10 Japan 2022-01-10 6265 2 5235. ## # ... with 167 more rows 4.3 時系列データの頻度変換 tidyverseと整合性がある金融時系列データ分析用のtidyquantパッケージに含まれるtq_transmute()関数を用いて、時系列データの頻度変換（高頻度データから低頻度データへの変換）を行います。 なお、tidyquantは頻度変換以外にも様々な分析機能があります。詳しくは公式ウェブサイトを参照してください。 まず、Our World in Dataのdata_owidデータセットから、使用するサンプルデータを作成します。tq_transmute()関数に入力する時系列データは、原則として横型データである点に留意してください。 # サンプルデータ（日次） data_owid_cases_wide &lt;- data_owid %&gt;% dplyr::select(location, date, new_cases) %&gt;% dplyr::filter(date &gt;= &quot;2021-01-01&quot;) %&gt;% dplyr::arrange(date) %&gt;% tidyr::pivot_wider(id_cols = &quot;date&quot;, names_from = &quot;location&quot;, values_from = &quot;new_cases&quot;) 日次データを週次データに変換 tidyquant::tq_transmute()関数を使用して日次データを週次データに変換すると、月曜～日曜のデータがFUNに指定した関数で集計され、日曜の日付で記録されます。 data_owid_cases_wide %&gt;% tidyquant::tq_transmute(select = -date, mutate_fun = apply.weekly, FUN = mean, na.rm = TRUE) ## # A tibble: 78 x 245 ## date Afghanistan Africa Albania Algeria Andorra Angola Anguilla ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2021-01-03 126. 24211. 374 266 47.7 29.7 0.667 ## 2 2021-01-10 111. 31857. 594. 248 56.3 78.7 0 ## 3 2021-01-17 70.7 29727. 585 241. 71 97.4 0 ## 4 2021-01-24 87.3 25102. 655. 252. 66.6 74.9 0 ## 5 2021-01-31 61.1 18531. 836. 249 55.4 56.7 0.143 ## 6 2021-02-07 44.6 14379. 1030. 250. 44.9 41.4 0.143 ## 7 2021-02-14 22.4 11848. 1106. 232. 36 40 0.143 ## 8 2021-02-21 16 10877. 1024. 172. 28 21.9 0 ## 9 2021-02-28 15.7 9707. 989. 168. 23.9 41.1 0 ## 10 2021-03-07 19 9535. 819. 163. 25.1 39.9 0 ## # ... with 68 more rows, and 237 more variables: `Antigua and Barbuda` &lt;dbl&gt;, ## # Argentina &lt;dbl&gt;, Armenia &lt;dbl&gt;, Aruba &lt;dbl&gt;, Asia &lt;dbl&gt;, Australia &lt;dbl&gt;, ## # Austria &lt;dbl&gt;, Azerbaijan &lt;dbl&gt;, Bahamas &lt;dbl&gt;, Bahrain &lt;dbl&gt;, ## # Bangladesh &lt;dbl&gt;, Barbados &lt;dbl&gt;, Belarus &lt;dbl&gt;, Belgium &lt;dbl&gt;, ## # Belize &lt;dbl&gt;, Benin &lt;dbl&gt;, Bermuda &lt;dbl&gt;, Bhutan &lt;dbl&gt;, Bolivia &lt;dbl&gt;, ## # `Bonaire Sint Eustatius and Saba` &lt;dbl&gt;, `Bosnia and Herzegovina` &lt;dbl&gt;, ## # Botswana &lt;dbl&gt;, Brazil &lt;dbl&gt;, `British Virgin Islands` &lt;dbl&gt;, ... なお、日曜～土曜のデータを集計し日曜の日付で記録したい場合は、rollmean()関数を使用して前方7日移動平均を計算し、日曜の値を抽出します。 data_owid_cases_wide %&gt;% dplyr::mutate(across(-date, rollmean, k = 7, na.pad = TRUE, align = &quot;left&quot;)) %&gt;% dplyr::filter(lubridate::wday(date) == 1) ## # A tibble: 78 x 245 ## date Afghanistan Africa Albania Algeria Andorra Angola Anguilla ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2021-01-03 116. 30479 577. 251. 60 78.3 0.286 ## 2 2021-01-10 76.9 30443. 598. 243. 64.6 87 0 ## 3 2021-01-17 88.7 26023. 604. 251. 65.9 86 0 ## 4 2021-01-24 64.1 19162. 830 250. 55.1 59.3 0.143 ## 5 2021-01-31 46 14925. 994. 215. 45.9 40 0.143 ## 6 2021-02-07 20.4 12066. 1111. 269. 36.7 38.1 0.143 ## 7 2021-02-14 15.3 11007. 1011. 179. 29.9 24.3 0 ## 8 2021-02-21 18.1 9721. 1022. 171. 25.3 40.4 0 ## 9 2021-02-28 19 9670. 838. 163. 24.3 39 0 ## 10 2021-03-07 17 10201. 678. 148. 29.9 38.3 0.429 ## # ... with 68 more rows, and 237 more variables: `Antigua and Barbuda` &lt;dbl&gt;, ## # Argentina &lt;dbl&gt;, Armenia &lt;dbl&gt;, Aruba &lt;dbl&gt;, Asia &lt;dbl&gt;, Australia &lt;dbl&gt;, ## # Austria &lt;dbl&gt;, Azerbaijan &lt;dbl&gt;, Bahamas &lt;dbl&gt;, Bahrain &lt;dbl&gt;, ## # Bangladesh &lt;dbl&gt;, Barbados &lt;dbl&gt;, Belarus &lt;dbl&gt;, Belgium &lt;dbl&gt;, ## # Belize &lt;dbl&gt;, Benin &lt;dbl&gt;, Bermuda &lt;dbl&gt;, Bhutan &lt;dbl&gt;, Bolivia &lt;dbl&gt;, ## # `Bonaire Sint Eustatius and Saba` &lt;dbl&gt;, `Bosnia and Herzegovina` &lt;dbl&gt;, ## # Botswana &lt;dbl&gt;, Brazil &lt;dbl&gt;, `British Virgin Islands` &lt;dbl&gt;, ... 日次データを月次データに変換 tidyquant::tq_transmute()関数を使用して日次データを月次データに変換すると、月初～月末のデータがFUNに指定した関数で集計され、月末の日付で記録されます。 data_owid_cases_wide %&gt;% tidyquant::tq_transmute(select = -date, mutate_fun = apply.monthly, FUN = mean, na.rm = TRUE) ## # A tibble: 18 x 245 ## date Afghanistan Africa Albania Algeria Andorra Angola Anguilla ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2021-01-31 86.9 26102. 639. 249. 60.9 72.4 0.0968 ## 2 2021-02-28 24.7 11703. 1037. 205. 33.2 36.1 0.0714 ## 3 2021-03-31 23.9 10321. 580. 132. 36.9 48.5 0.226 ## 4 2021-04-30 110. 11347. 198. 164. 40.7 145. 2.27 ## 5 2021-05-31 390. 9119. 39.7 220. 16.0 255. 0.516 ## 6 2021-06-30 1561. 22139. 6.87 357. 6.13 143. 0 ## 7 2021-07-31 919. 38865. 18.1 1025. 24.7 127. 0.129 ## 8 2021-08-31 196. 34873. 429. 796. 11.5 154. 3.35 ## 9 2021-09-30 65.1 17350. 791. 243. 6.3 301. 6.4 ## 10 2021-10-31 34.7 6251. 489. 99.8 9.48 253. 17.3 ## 11 2021-11-30 34.6 5468. 488. 136. 53.3 24.5 14.7 ## 12 2021-12-31 25.6 34489. 332. 255. 214. 530. 9.29 ## 13 2022-01-31 162. 36481. 1559. 1087. 394. 533 21.0 ## 14 2022-02-28 383. 15932. 465 458. 72.9 22.3 8.25 ## 15 2022-03-31 132. 7282. 68.2 23.7 65.3 13.8 4.68 ## 16 2022-04-30 37.7 3801. 47.7 3.63 44.2 3.93 2.93 ## 17 2022-05-31 47.4 6860. 32.1 3.35 49.8 15.3 13.4 ## 18 2022-06-26 69.3 5486. 114. 5.92 40 0 8 ## # ... with 237 more variables: `Antigua and Barbuda` &lt;dbl&gt;, Argentina &lt;dbl&gt;, ## # Armenia &lt;dbl&gt;, Aruba &lt;dbl&gt;, Asia &lt;dbl&gt;, Australia &lt;dbl&gt;, Austria &lt;dbl&gt;, ## # Azerbaijan &lt;dbl&gt;, Bahamas &lt;dbl&gt;, Bahrain &lt;dbl&gt;, Bangladesh &lt;dbl&gt;, ## # Barbados &lt;dbl&gt;, Belarus &lt;dbl&gt;, Belgium &lt;dbl&gt;, Belize &lt;dbl&gt;, Benin &lt;dbl&gt;, ## # Bermuda &lt;dbl&gt;, Bhutan &lt;dbl&gt;, Bolivia &lt;dbl&gt;, ## # `Bonaire Sint Eustatius and Saba` &lt;dbl&gt;, `Bosnia and Herzegovina` &lt;dbl&gt;, ## # Botswana &lt;dbl&gt;, Brazil &lt;dbl&gt;, `British Virgin Islands` &lt;dbl&gt;, ... 日次データを四半期データに変換 tidyquant::tq_transmute()関数を使用して日次データを四半期データに変換すると、期初～期末のデータがFUNに指定した関数で集計され、期末の日付で記録されます。 data_owid_cases_wide %&gt;% tidyquant::tq_transmute(select = -date, mutate_fun = apply.quarterly, FUN = mean, na.rm = TRUE) ## # A tibble: 6 x 245 ## date Afghanistan Africa Albania Algeria Andorra Angola Anguilla ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2021-03-31 45.8 16187. 743. 195. 44.0 52.9 0.133 ## 2 2021-06-30 684. 14146. 80.9 247. 20.9 182. 0.923 ## 3 2021-09-30 397. 30504. 409. 693. 14.2 193. 3.26 ## 4 2021-12-31 31.6 15510. 436. 164. 92.6 272. 13.8 ## 5 2022-03-31 221 20031. 705. 525. 181. 195. 11.4 ## 6 2022-06-26 50.6 5394. 62.1 4.22 45.2 6.80 8.17 ## # ... with 237 more variables: `Antigua and Barbuda` &lt;dbl&gt;, Argentina &lt;dbl&gt;, ## # Armenia &lt;dbl&gt;, Aruba &lt;dbl&gt;, Asia &lt;dbl&gt;, Australia &lt;dbl&gt;, Austria &lt;dbl&gt;, ## # Azerbaijan &lt;dbl&gt;, Bahamas &lt;dbl&gt;, Bahrain &lt;dbl&gt;, Bangladesh &lt;dbl&gt;, ## # Barbados &lt;dbl&gt;, Belarus &lt;dbl&gt;, Belgium &lt;dbl&gt;, Belize &lt;dbl&gt;, Benin &lt;dbl&gt;, ## # Bermuda &lt;dbl&gt;, Bhutan &lt;dbl&gt;, Bolivia &lt;dbl&gt;, ## # `Bonaire Sint Eustatius and Saba` &lt;dbl&gt;, `Bosnia and Herzegovina` &lt;dbl&gt;, ## # Botswana &lt;dbl&gt;, Brazil &lt;dbl&gt;, `British Virgin Islands` &lt;dbl&gt;, ... 4.4 季節調整（X-13） ここでは、seasonalパッケージを用いた時系列データへの季節調整方法について解説します。 seasonalパッケージでは、米国商務省センサス局が開発したX-13ARIMA-SEATSを用いて、ts型の月次データ、四半期データ、半期データに対し季節調整を適用することができます。 seasonalパッケージや、X-13ARIMA-SEATSの詳細については、Sax &amp; Eddelbuettel（2018）や、奥本（2016）を参照してください。 サンプルデータとして、ts型データであるseasonal::unempデータセットを用い、seasonalパッケージの使用方法を確認します。 ts型データの可視化 季節調整の前に、データを確認します。ts型データはplot()関数でグラフを作成できます。 plot(seasonal::unemp) X-13ARIMA-SEATSの実施方法 seasonalパッケージでは、seas()関数を使用してts型データにX-13ARIMA-SEATSを適用します。seas()関数は、季節調整の結果を格納したseas型のオブジェクトを返します。 # seas()関数で季節調整を実行 m &lt;- seasonal::seas(x = seasonal::unemp) # 季節調整の結果を出力 summary(m) ## ## Call: ## seasonal::seas(x = seasonal::unemp) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## AR-Nonseasonal-01 0.94360 0.03441 27.43 &lt;2e-16 *** ## MA-Nonseasonal-01 0.82540 0.05654 14.60 &lt;2e-16 *** ## MA-Seasonal-12 0.85071 0.03362 25.30 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## SEATS adj. ARIMA: (1 1 1)(0 1 1) Obs.: 323 Transform: none ## AICc: 4324, BIC: 4339 QS (no seasonality in final): 0 ## Box-Ljung (no autocorr.): 22.04 Shapiro (normality): 0.9946 plot()関数で、原数値と季節調整値のグラフを作成できます。黒色の線が原数値、赤色の線が季節調整値です。外れ値がある場合はグラフ中に外れ値が表示されます。 plot(m) 季節調整値を出力するには、seasonal::final()関数を使用します。 # 季節調整値をunemp_saに格納 unemp_sa &lt;- seasonal::final(m) # unemp_saの折れ線グラフを作成 plot(unemp_sa, type = &quot;l&quot;) monthplot()関数を使用すると、季節変動（Seasonal component）と不規則変動（Seasonal irregular component）を月別に確認することができます。 monthplot(m) 実例：月次データの季節調整 ここでは、日本の産業別就業者数データセットdata_laborに対し、月次の季節調整を適用します。data_laborはtibble形式のデータフレームの中に、日付型の列と、複数の数値型のデータの列を格納したものです。 tibble形式のデータフレームに格納されている数値型データをts型データに変換する tibble形式のデータフレームをリスト形式に変換する pblapply()で一括してseas()関数の季節調整を適用する。季節調整エラーはtry()関数で処理する 季節調整エラーを取得する 季節調整値を取得する エラーが生じた系列は原数値を取得する # data_laborから一部を抽出 data_labor_nsa &lt;- data_labor %&gt;% dplyr::select(date, `総数`, `製造`, `情報通信`) # 数値型データをts型データに変換 data_labor_ts &lt;- data_labor_nsa %&gt;% dplyr::select(-date) %&gt;% ts(frequency = 12, # 月次データの場合は12を指定 start = c(lubridate::year(data_labor$date[1]), lubridate::month(data_labor$date[1]))) # データ開始年月を指定 # tibble形式をリスト形式に変換 data_labor_ts %&lt;&gt;% as.list() # pblapply()関数で一括してseas()関数の季節調整を適用 # 季節調整でエラーが発生する可能性があるため、try()関数でエラー処理を行う result &lt;- pblapply(data_labor_ts, function(e) try(suppressMessages(seas(e, transform.function = &quot;auto&quot;)), silent = TRUE)) # 季節調整エラーを取得 result_iserror &lt;- sapply(result, class) == &quot;try-error&quot; # 季節調整値を取得し、tibble形式データフレームのdata_labor_saに格納 data_labor_sa &lt;- do.call(cbind, lapply(result[!result_iserror], final)) %&gt;% tibble::as_tibble() %&gt;% dplyr::bind_cols(data_labor[, 1], .) # エラーが生じた系列は原数値を取得してdata_labor_saに追加 for (col in which(result_iserror)) { data_labor_sa &lt;- data_labor[, names(result[col])] %&gt;% dplyr::bind_cols(data_labor_sa) } # data_labor_saの列をdata_labor_nsaの列順で並べ替え data_labor_sa %&lt;&gt;% dplyr::select(all_of(names(data_labor_nsa))) 個別系列の季節調整結果を可視化するには、plot()関数を使用します。一部の系列は季節性がないと判断されるため、季節調整が行われていません。 plot(result[[which(names(result) == &quot;総数&quot;)]]) plot(result[[which(names(result) == &quot;製造&quot;)]]) plot(result[[which(names(result) == &quot;情報通信&quot;)]]) 4.5 季節調整（STL分解） 上で紹介したX-13ARIMA-SEATSは、月次データ、四半期データ、半期データに適用できますが、週次データや日次データには適用できません。そこで、週次データや日次データの季節調整を行うためにstatsパッケージのstl()関数によるSTL分解を使用します。 STL分解とは、Seasonal Decomposition of Time Series by Loessの略で、時系列データを季節変動、トレンド変動、不規則変動に分解する手法です。 STL分解の実施方法 STL分解を行うには、ts型の時系列データに対し、statsパッケージのstl()関数を適用します。stl()関数はSTL分解の結果を格納したstl型のオブジェクトを返します。 # stl()関数でSTL分解を実行 m &lt;- stats::stl(x = seasonal::unemp, s.window = &quot;periodic&quot;) # STL分解の結果を可視化 plot(m) 季節調整値を出力するには、stl()関数が返すstl型オブジェクトに格納されているtime.seriesにアクセスします。time.seriesには、季節変動（seasonal）、トレンド変動（trend）、不規則変動（remainder）の順番にデータが格納されています。 # 季節調整値（トレンド）をunemp_saに格納 unemp_sa &lt;- m$time.series[, &quot;trend&quot;] # unemp_saの折れ線グラフを作成 plot(unemp_sa, type = &quot;l&quot;) 週次データのSTL分解 STL分解は、seasonal::unempのような月次データだけでなく、より高頻度なデータにも適用できるのが特徴です。 ここでは、週次データであるfpp2::gasolineデータセットに対し、STL分解を適用します。週次データはts()関数におけるfrequency引数が52.18となっています。これは、うるう年を考慮した1年の平均日数365.25日を7で割った値であり、週次データは一周期が52.18週であることを示しています。 # データの確認 head(fpp2::gasoline) ## Time Series: ## Start = 1991.1 ## End = 1991.19582477755 ## Frequency = 52.1785714285714 ## [1] 6.621 6.433 6.582 7.224 6.875 6.947 # データの可視化 plot(fpp2::gasoline) # stl()関数でSTL分解を実行 m &lt;- stats::stl(x = fpp2::gasoline, s.window = &quot;periodic&quot;) # STL分解の結果を可視化 plot(m) 日次データのSTL分解（単一周期） さらに、STL分解は日次データにも適用可能です。日次データの周期性は通常、週、月、年の3種類あると考えられます。ただし、ts型では一種類の周期性しか指定できないため、ここでは週を一周期に設定し、ts()関数のfrequency引数に7を指定して、STL分解を行います。 使用するデータは、Our World in Dataのdata_owidデータセットにおける、日本の新規感染者数です。 # data_owidから日本の新規感染者数（日次）を抽出 data_cases_jp &lt;- data_owid %&gt;% dplyr::filter(location == &quot;Japan&quot;) %&gt;% tidyr::drop_na(new_cases) %&gt;% dplyr::pull(new_cases) # 1週＝7日の周期を設定したts型データに変換 data_cases_jp_ts &lt;- data_cases_jp %&gt;% ts(start = c(2020, 1, 22), frequency = 7) # STL分解の結果をmに格納 m &lt;- stats::stl(x = data_cases_jp_ts, s.window = &quot;periodic&quot;) # STL分解の結果を可視化 plot(m) 日次データのSTL分解（複数周期） データに複数の周期性を設定したい場合は、ts型の拡張版であるmsts型データを用います。msts型データはforecastパッケージのmsts()関数で作成できます。 ここでは、日次データに対し、1週間＝7日と、1年＝365.25日の2種類の周期性を設定しています。 msts型データに対するSTL分解は、stats::stl()関数ではなく、forecastパッケージのmstl()関数を使用します。 # data_owidから日本の新規感染者数（日次）を抽出 data_cases_jp &lt;- data_owid %&gt;% dplyr::filter(location == &quot;Japan&quot;) %&gt;% tidyr::drop_na(new_cases) %&gt;% dplyr::pull(new_cases) # 1週間＝7日と1年＝365.25日の周期を設定したmsts型データに変換 data_cases_jp_msts &lt;- data_cases_jp %&gt;% forecast::msts(seasonal.period = c(7, 365.25), start = c(2020, 1, 22)) # STL分解の結果をmに格納 m &lt;- forecast::mstl(x = data_cases_jp_ts, s.window = &quot;periodic&quot;) # STL分解の結果を可視化 plot(m) 4.6 トレンド推定 seasonalパッケージのサンプルデータセットunemp（米国の失業者数、原数値）を対象に、トレンド推定を行う方法を解説します。 HPフィルタ HPフィルタ（Hodrick Prescott Filter）は、時系列データのトレンド成分と循環成分を推定する手法です。 具体的には、時系列データがトレンド成分\\(g_t\\)と循環成分\\(c_t\\)で構成されると仮定し、次の式のように、全期間を通して「循環成分の2乗の総和」と「トレンド成分の2階階差の2乗の総和」の加重和が最小になるような\\(g_t\\)を計算します。 ここで、\\(\\lambda\\)はトレードオフの関係にある2つの項にウェイトをつける調整パラメータです。\\(\\lambda\\)が大きいほどトレンド成分が直線に近く、\\(\\lambda\\)が小さいほどトレンド成分が元のデータに近くなります。一般的に、四半期データには\\(\\lambda = 1600\\)が、月次データには\\(\\lambda = 14400\\)が使用されます。 \\[ \\min \\Bigg\\{ \\sum_{t=1}^{T}{c_t^2} + \\lambda \\sum_{t=1}^{T}[(g_t - g_{t-1})-(g_{t-1}-g_{t-1})]^2 \\Bigg\\} \\] HPフィルタを適用するには、時系列データに対し、mFilterパッケージのhpfilter()関数を使用します。データ型は数値型ベクトル、ts型どちらでもOKです。 推定したトレンド成分、循環成分は、推定結果を格納したオブジェクトに、それぞれtrend、cycleの名称で格納されています。 result &lt;- mFilter::hpfilter(x = seasonal::unemp, # HPフィルタを適用する時系列データ（数値型ベクトル、ts型） type = &quot;lambda&quot;, freq = 14400, # ラムダの値（四半期：1600、月次：14400） drift = FALSE) # ドリフト項の有無 summary(result) ## ## Title: ## Hodrick-Prescott Filter ## ## Call: ## mFilter::hpfilter(x = seasonal::unemp, freq = 14400, type = &quot;lambda&quot;, ## drift = FALSE) ## ## Method: ## hpfilter ## ## Filter Type: ## lambda ## ## Series: ## seasonal::unemp ## ## Descriptive Statistics: ## ## seasonal::unemp Trend Cycle ## Min. : 5153 Min. : 5915 Min. :-2235.97 ## 1st Qu.: 7012 1st Qu.: 7236 1st Qu.: -473.54 ## Median : 8078 Median : 8115 Median : -78.87 ## Mean : 8766 Mean : 8766 Mean : 0.00 ## 3rd Qu.: 9476 3rd Qu.: 9235 3rd Qu.: 437.43 ## Max. :16147 Max. :14235 Max. : 2441.18 ## ## In-sample error measures: ## ME MSE MAE MPE MAPE ## -2.008e-13 5.236e+05 5.652e+02 -9.939e-03 6.582e-02 # トレンド推定結果を可視化（コンソールでEnterを押すと表示） plot(result) 一般化加法モデル（GAM） 一般化加法モデル（Generalizes Additive Model、GAM）は、線形モデルがもつ解釈性の良さを保ったまま、非線形モデルのような高い説明力を両立させる手法です。 具体的には次のように、被説明変数\\(Y\\)を、説明変数\\(X\\)を要素とする非線形関数\\(f(X)\\)の和として説明するモデルです。非線形関数を用いることにより、説明変数と被説明変数の間の複雑な関係を説明できる一方で、被説明変数がそれぞれの非線形関数の和になっていることで、被説明変数の変動要因を説明変数毎に分解することができ、高い解釈性を維持している点が特徴です。 \\[ Y_i = \\beta_0 + f_1(X_{1i}) + f_2(X_{2i}) + \\dots + f_k(X_{ki}) + u_i \\] ここでは\\(X\\)として時系列インデックスを用いることでトレンドを推定しますが、GAMはトレンド推定以外にも様々な用途に使用可能です。例えば、服部直樹（2020）「新型コロナウイルス感染症（COVID-19）の感染拡大要因は何か」では、GAMの拡張版である「交互作用項付き一般化加法モデル（GA2M）」を使用して、新型コロナウイルス感染者数の変動要因の説明を試みています（ただし、同レポートではPythonによるGA2Mの実装を用いています）。 一般化加法モデルは、mgcvパッケージのgam()関数で推定します。事前に時系列インデックスを作成し、gam()関数のformula引数で被説明変数 ~ s(時系列インデックス)と指定します。説明変数である時系列インデックスをs()に配置することにより、非線形関数を適用します（s()を用いなければ、通常の線形回帰と同じ結果になります）。 gam()関数の使用方法の詳細については、こちらのウェブサイトを参照してください。 # unempデータをベクトル形式に変換してdataに格納 data &lt;- tibble::tibble( date = seq(from = as.Date(&quot;1990-01-01&quot;), to = as.Date(&quot;2016-11-01&quot;), by = &quot;1 month&quot;), unemp = seasonal::unemp %&gt;% as.vector() ) # dataに時系列インデックスtimeを追加 data %&lt;&gt;% dplyr::mutate(time = seq_along(date)) # GAMでトレンド推定 result &lt;- mgcv::gam(formula = unemp ~ s(time), family = gaussian(), # 分布関数 sp = NULL, # 平滑度を決めるパラメータ（大きいほど直線に近く、小さいほど元データに近い。NULLで自動最適化） data = data) # 推定結果を出力 summary(result) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## unemp ~ s(time) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8765.87 44.51 196.9 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(time) 8.974 9 326.7 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.901 Deviance explained = 90.4% ## GCV = 6.6028e+05 Scale est. = 6.399e+05 n = 323 推定したトレンド系列は、推定結果を格納したオブジェクトにfitted.valuesの名称で格納されています。 data %&gt;% dplyr::mutate(unemp_fitted = result$fitted.values) ## # A tibble: 323 x 4 ## date unemp time unemp_fitted ## &lt;date&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1990-01-01 7413 1 7055. ## 2 1990-02-01 7296 2 7139. ## 3 1990-03-01 6852 3 7224. ## 4 1990-04-01 6620 4 7308. ## 5 1990-05-01 6533 5 7392. ## 6 1990-06-01 6884 6 7476. ## 7 1990-07-01 7137 7 7559. ## 8 1990-08-01 7008 8 7642. ## 9 1990-09-01 7003 9 7724. ## 10 1990-10-01 6892 10 7806. ## # ... with 313 more rows # トレンド推定結果を可視化 plot(result, # gam()関数で推定した結果を格納したオブジェクト residuals = TRUE, # 元データを表示するか se = TRUE, # 信頼区間を表示するか pch = &quot;*&quot;) # 元データのマーカー # 推定したモデルのチェック mgcv::gam.check(result) ## ## Method: GCV Optimizer: magic ## Smoothing parameter selection converged after 12 iterations. ## The RMS GCV score gradient at convergence was 2.293679 . ## The Hessian was positive definite. ## Model rank = 10 / 10 ## ## Basis dimension (k) checking results. Low p-value (k-index&lt;1) may ## indicate that k is too low, especially if edf is close to k&#39;. ## ## k&#39; edf k-index p-value ## s(time) 9.00 8.97 0.23 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 "],["ggplot2によるグラフ作成.html", "5 ggplot2によるグラフ作成 5.1 第5章の準備 5.2 ggplot2とは 5.3 ggplot2の設定 5.4 GUI形式の直感的なグラフ作成 5.5 1次元の度数分布（離散型） 5.6 1次元の度数分布（連続型） 5.7 1次元の密度グラフ 5.8 2次元の度数分布（離散型） 5.9 2次元の度数分布（連続型） 5.10 2次元の密度グラフ 5.11 QQプロット 5.12 散布図・バブルチャート 5.13 棒グラフ 5.14 円グラフ 5.15 折れ線グラフ 5.16 ステップグラフ 5.17 面グラフ 5.18 箱ひげ図・ヴァイオリングラフ 5.19 ドットプロット 5.20 色の設定 5.21 軸の設定 5.22 複合グラフ（ファセット） 5.23 地図ファセット 5.24 その他設定・保存 5.25 実例", " 5 ggplot2によるグラフ作成 第5章「ggplot2によるグラフ作成」では、tidyverseのggplot2パッケージを主に使用したグラフ作成方法について解説します。 5.1 第5章の準備 パッケージのインポート library(esquisse) library(geofacet) library(ggplotgui) library(ggpubr) library(ggsci) library(ggrepel) library(lemon) library(magrittr) library(openxlsx) library(RColorBrewer) library(readxl) library(tidyverse) 外部データセットの取得 この章では、外部データセットとして以下のデータを使用します。第1章のコードを使用してあらかじめウェブからデータセットを取得してください。 OWIDのCOVID-19データセット： data_owid 日本の県内総生産： data_gdp_pref 5.2 ggplot2とは ggplot2パッケージでは、最初にggplot()関数でグラフを作成するデータと変数を指定します。その後に、geom_histogram()などのグラフの種類を指定する関数や、scale_x_dateなどの軸設定の関数、theme()などの各種設定の関数を+演算子で追加していきます。 ggplot()関数では、まずdata引数にtibble形式の縦型データを指定します。次にmapping引数にaes()関数を指定し、aes()関数の中でX軸やY軸の変数、必要に応じてcolorやsizeなど変数の値に応じて変化させる色・サイズなどの要素を指定します。 なお、グラフの種類により、X軸、Y軸に指定できる変数の型（連続型、離散型）が決まっていますので、注意してください。 ggplot2パッケージの詳細については公式ウェブサイトを参照してください。各関数の使い方については、公式ウェブサイトのチートシートが分かりやすくまとまっています。 5.3 ggplot2の設定 第1章で紹介したggplot2の設定です。 ## ggplotのテーマ設定（Excelのグラフと類似したテーマを選択） theme_set(theme_light()) ## Windowsにおけるggplot2の日本語フォント設定 windowsFonts(&quot;MEIRYO&quot; = windowsFont(&quot;Meiryo UI&quot;)) windowsFonts(&quot;YUGO&quot; = windowsFont(&quot;Yu Gothic UI&quot;)) 5.4 GUI形式の直感的なグラフ作成 この章ではggplot2パッケージによるグラフ作成方法を紹介しますが、ggplot2はコードを記述してグラフを作成するため、試行錯誤を伴う探索的データ分析（EDA）にはあまり向いていません。 そこで、ggplot2によるグラフ作成を行う前に、GUI形式でコードを記述せずにグラフを作成できるパッケージを用い、どのようなグラフを作成するべきか検討します。 esquisseパッケージ esquisseパッケージは、ドラッグ＆ドロップでX軸・Y軸の変数や色・サイズを変化させる属性の変数を指定し、グラフを作成することができる便利なパッケージです。ただし、データセットの規模が大きいと起動に時間がかかるため、変数の数が多い場合は、あらかじめ注目する変数を絞るといった前処理が必要です。 Rで下記のコードを実行すると別のウィンドウでesquisseの画面が立ち上がり、GUI形式でインタラクティブにグラフを作成することができます。ウェブサイト上では実行できないため、各自で試してみてください。 # irisデータ esquisse::esquisser(data = iris) ## 世界の新型コロナデータの一部を抽出 data_owid %&gt;% dplyr::select(location, date, new_cases_smoothed) %&gt;% dplyr::filter(location %in% c(&quot;Japan&quot;, &quot;United States&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Italy&quot;)) %&gt;% esquisse::esquisser() ggplotguiパッケージ その他、GUI形式でグラフを作成することができるパッケージとして、ggplotguiがあります。同様にウェブサイト上では実行できないため、各自で試してみてください。 # irisデータ ggplotgui::ggplot_shiny(data = iris) ## 世界の新型コロナデータの一部を抽出 data_owid %&gt;% dplyr::select(location, date, new_cases_smoothed) %&gt;% dplyr::filter(location %in% c(&quot;Japan&quot;, &quot;United States&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Italy&quot;)) %&gt;% ggplotgui::ggplot_shiny() 5.5 1次元の度数分布（離散型） X軸：離散型変数 Y軸：なし 離散型変数の1次元の度数分布を作成するには、度数棒グラフを用います。度数棒グラフを作成するにはgeom_bar()関数を使用します。 度数棒グラフの基本形 ggplot(data = mpg, mapping = aes(x = manufacturer)) + geom_bar(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 size = 0.5, # 線の太さ width = 0.9) # 棒の幅 (0-1) 5.6 1次元の度数分布（連続型） X軸：連続型変数 Y軸：なし 連続型変数の1次元の度数分布を作成するには、ヒストグラムを用います。ヒストグラムを作成するにはgeom_histogram()関数やgeom_freqpoly()関数を使用します。 ヒストグラムの基本形 ggplot(data = mpg, mapping = aes(x = hwy)) + geom_histogram(binwidth = 5, # 階級幅 color = &quot;gray&quot;, # 線の色 fill = &quot;darkblue&quot;, # 塗りつぶしの色 size = 0.5) # 線の太さ 横並びヒストグラム グループ別のヒストグラムを横並び形式で作成するには、position引数に\"dodge\"を指定します。 ggplot(data = mpg, mapping = aes(x = hwy, fill = class)) + geom_histogram(binwidth = 5, # 階級幅 position = &quot;dodge&quot;, # 横並びポジション color = &quot;black&quot;, # 線の色 size = 0.5) # 線の太さ グループ別の度数分布はgeom_freqpoly()関数でも可視化することができます。 ggplot(data = mpg, mapping = aes(x = hwy, color = class)) + geom_freqpoly(binwidth = 5, # 階級幅 size = 0.5) # 線の太さ 積み上げヒストグラム グループ別のヒストグラムを積み上げ形式で作成するには、position引数に\"stack\"を指定します。 ggplot(data = mpg, mapping = aes(x = hwy, fill = class)) + geom_histogram(binwidth = 5, # 階級幅 position = &quot;stack&quot;, # 積み上げポジション color = &quot;black&quot;, # 線の色 size = 0.5) # 線の太さ 5.7 1次元の密度グラフ X軸：連続型変数 Y軸：なし 密度グラフはgeom_density()関数で作成します。 密度グラフの基本形 ggplot(data = mpg, mapping = aes(x = hwy)) + geom_density(kernel = &quot;gaussian&quot;, # カーネル関数の種類 color = &quot;darkblue&quot;, # 線の色 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) # 線の太さ 横並び密度グラフ グループ別の密度グラフを横並び形式で作成するには、position引数に\"dodge\"を指定します。 ggplot(data = mpg, mapping = aes(x = hwy, color = class)) + geom_density(kernel = &quot;gaussian&quot;, # カーネル関数の種類 position = &quot;dodge&quot;, # 横並びポジション linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) # 線の太さ 横並びの密度グラフはgeom_freqpoly()関数でも作成できます。geom_freqpoly()関数でmapping = aes(y = ..density..)を指定すると、各グループの度数を標準化して密度グラフに変換します。 ggplot(data = mpg, mapping = aes(x = hwy, y = ..density.., color = class)) + geom_freqpoly(binwidth = 5, # 階級幅 size = 0.5) # 線の太さ 積み上げ密度グラフ グループ別の密度グラフを積み上げ形式で作成するには、position引数に\"stack\"を指定します。 ggplot(data = mpg, mapping = aes(x = hwy, fill = class)) + geom_density(kernel = &quot;gaussian&quot;, # カーネル関数の種類 position = &quot;stack&quot;, # 積み上げポジション color = &quot;black&quot;, # 線の色 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 0.5) # 線の太さ 5.8 2次元の度数分布（離散型） X軸：離散型変数 Y軸：離散型変数 離散型変数の2次元の度数分布を作成するには、度数バブルチャートや度数ヒートマップを用います。度数バブルチャートを作成するにはgeom_count()関数を使用します。また、離散型変数の度数ヒートマップを作成するにはgeom_tile()関数を使用します。 度数バブルチャートの基本形 ggplot(data = mpg, mapping = aes(x = manufacturer, y = class)) + geom_count(alpha = 0.5, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 shape = 21, # マーカーの種類 stroke = 0.5) + # 線の太さ scale_size_area(max_size = 15) + # 変量とマーカーの面積を比例させる theme(axis.text.x = element_text(angle = 45, hjust = 1.0)) 度数ヒートマップの基本形 ggplot(data = mpg %&gt;% dplyr::count(manufacturer, class), # データの度数を格納した変数を作成 mapping = aes(x = manufacturer, y = class, fill = n)) + geom_tile(height = 1.0, # タイルの高さ width = 1.0, # タイルの幅 alpha = 1.0, # 塗りつぶしの色の透明度 color = &quot;grey&quot;, # 線の色 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 0.5) + # 線の太さ scale_fill_viridis_c() + theme(axis.text.x = element_text(angle = 45, hjust = 1.0)) 5.9 2次元の度数分布（連続型） X軸：連続型変数 Y軸：連続型変数 連続型変数の2次元の度数分布を作成するには、度数ヒートマップを用います。連続型変数の度数ヒートマップを作成するにはgeom_bin2d()関数を使用します。 度数ヒートマップの基本形 ggplot(data = diamonds, mapping = aes(x = carat, y = price)) + geom_bin2d(bins = c(100, 75), # X軸・Y軸の階級数（デフォルトは30） alpha = 1.0, # 塗りつぶしの色の透明度 color = NA, # 線の色 linetype = &quot;solid&quot;, # 線の種類 size = 0.2) + # 線の太さ scale_fill_viridis_c() 5.10 2次元の密度グラフ X軸：連続型変数 Y軸：連続型変数 2次元の密度グラフを作成するには、geom_density2d()関数ファミリーを使用します。 まず、使用するサンプルデータを作成します。データサイズが大きい場合、2次元密度グラフを作成するために時間を要するため、dplyr::sample_n()関数でサンプリングします。 diamonds_small &lt;- diamonds %&gt;% dplyr::sample_n(size = 5000) 2次元密度グラフの基本形 ggplot(data = diamonds_small, mapping = aes(x = carat, y = price)) + geom_density2d() 2次元密度グラフの塗りつぶし版 ggplot(data = diamonds_small, mapping = aes(x = carat, y = price)) + geom_density2d_filled() + scale_fill_brewer(palette = &quot;Reds&quot;, direction = 1) 5.11 QQプロット X軸・Y軸：連続型変数 QQプロットはgeom_qq()関数で作成します。他のグラフと異なり、mapping = aes(sample = 変数)で変数を指定します。 QQ（Quantile-Quantile）プロットは、データが正規分布にどの程度近いかを検証するグラフです。Y軸にデータを順番に並べた値、X軸にデータが正規分布に従うと仮定した場合にとりうる期待値を標準化した値をとり、散布図を描いたものです。 QQプロットが直線上にある場合、データは正規分布に従うと解釈できます。一方、QQプロットが直線から乖離している場合は、正規分布に従っておらず、分布にゆがみがあると解釈できます。 例えば、QQプロットが右下に凸な形状の場合は、データは右に長い裾（テール）をもちます。一方、QQプロットが左上に凸な形状の場合は、データの分布は左に長い裾（テール）をもちます。 また、QQプロットがS字状（前半は右下に凸、後半は左上に凸）の場合は、データの両裾が重い、いわゆるファット・テールの分布になります。一方、逆S字状（前半は左上に凸、後半は右下に凸）の場合は、ピーク部分が突出した分布になります。 # 右に長い裾をもつデータのQQプロット ggplot(data = iris, mapping = aes(sample = Sepal.Length)) + geom_qq_line() + geom_qq() # ファット・テールをもつデータのQQプロット ggplot(data = economics, mapping = aes(sample = unemploy)) + geom_qq_line() + geom_qq() 5.12 散布図・バブルチャート X軸：連続型変数 Y軸：連続型変数 散布図とバブルチャートはgeom_point()関数で作成します。バブルチャートの上にgeom_smooth()関数で近似曲線を重ねることができます。 まず、プロット用のデータを作成します。 data_mpg_point &lt;- mpg %&gt;% dplyr::group_by(manufacturer) %&gt;% dplyr::summarise(across(c(displ, cty, hwy), mean, na.rm = TRUE)) data_mpg_point ## # A tibble: 15 x 4 ## manufacturer displ cty hwy ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 audi 2.54 17.6 26.4 ## 2 chevrolet 5.06 15 21.9 ## 3 dodge 4.38 13.1 17.9 ## 4 ford 4.54 14 19.4 ## 5 honda 1.71 24.4 32.6 ## 6 hyundai 2.43 18.6 26.9 ## 7 jeep 4.58 13.5 17.6 ## 8 land rover 4.3 11.5 16.5 ## 9 lincoln 5.4 11.3 17 ## 10 mercury 4.4 13.2 18 ## 11 nissan 3.27 18.1 24.6 ## 12 pontiac 3.96 17 26.4 ## 13 subaru 2.46 19.3 25.6 ## 14 toyota 2.95 18.5 24.9 ## 15 volkswagen 2.26 20.9 29.2 散布図の基本形 ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 shape = 21, # マーカーの種類 size = 2.0, # マーカーの大きさ stroke = 0.5) # 線の太さ バブルチャートの基本形 バブルチャートを作成するには、ggplot()関数のmapping = aes()関数でsize引数にバブルのサイズを変化させたい変数を指定します。 ggplot(data = data_mpg_point, mapping = aes(x = cty, y = hwy, size = displ)) + # aes() 関数内のsize引数に連続型変数を指定 geom_point(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 shape = 21, # マーカーの種類 stroke = 0.5) # 線の太さ 散布図に補助線を追加 水平線、垂直線、傾き・切片のある直線といった補助線を追加するには、それぞれgeom_hline()関数、geom_vline()関数、geom_abline()関数を使用します。 ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_hline(yintercept = 20, # 水平線の縦軸との交点 color = &quot;Tomato&quot;, # 水平線の色 size = 0.5) + # 水平線の太さ geom_vline(xintercept = 20, # 垂直線の横軸との交点 color = &quot;Forestgreen&quot;, # 垂直線の色 size = 0.5) + # 垂直線の太さ geom_abline(intercept = 0, # 直線の切片 slope = 1, # 直線の傾き color = &quot;gold&quot;, # 直線の色 size = 0.5) + # 直線の太さ geom_point(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 shape = 21, # マーカーの種類 size = 2.0, # マーカーの大きさ stroke = 0.5) # 線の太さ 散布図にコネクタ線を追加 散布図のマーカー間をつなぐコネクタ線を追加するには、geom_path()関数を追加します。折れ線グラフを作成するgeom_line()関数とは異なるので注意してください。 geom_path()関数とgeom_line()関数はどちらもマーカー間をつなぐコネクタ線を追加する関数ですが、geom_path()関数はデータセット上の順番で線を引く一方、geom_line()関数はデータセット上の順番に関わらずX軸上の順番で線を引くという違いがあります。 economics %&gt;% dplyr::filter(date &gt;= &quot;2000-01-01&quot;) %&gt;% ggplot(mapping = aes(x = unemploy, y = uempmed)) + geom_path(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 size = 0.5) + # 線の大きさ geom_point(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 shape = 21, # マーカーの種類 size = 2.0, # マーカーの大きさ stroke = 0.5) # 線の太さ 散布図に近似曲線を追加 散布図に近似曲線を追加するには、geom_smooth()関数を使用します。 ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 shape = 21, # マーカーの種類 size = 2.0, # マーカーの大きさ stroke = 0.5) + # 線の太さ geom_smooth(formula = y ~ x, # 近似曲線の推計式 method = &quot;loess&quot;, # 近似手法 (lm, glm, gam, loess) alpha = 0.5, # 誤差範囲の透明度 color = &quot;black&quot;, # 近似曲線の色 fill = &quot;gray&quot;, # 誤差範囲の色 linetype = &quot;dashed&quot;, # 近似曲線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) # 近似曲線の太さ 散布図にラベルを追加 散布図にラベルを追加するには、ggrepelパッケージのgeom_text_repel()関数を使用します。geom_text_repel()関数は、散布図のマーカーとラベルが重ならないようにラベルの位置を自動で調整します。 ggplot(data = data_mpg_point, mapping = aes(x = cty, y = hwy)) + geom_point(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 shape = 21, # マーカーの種類 size = 2.0, # マーカーの大きさ stroke = 0.5) + # 線の太さ geom_text_repel(mapping = aes(label = manufacturer), seed = NA, # テキストの配置を決定するランダムシード direction = &quot;both&quot;, # テキストの整列方向 (both / x / y) hjust = 0.0, # 横方向の整列位置 (0-1) vjust = 0.5, # 縦方向の整列位置 (0-1) nudge_x = NULL, # マーカーからの横方向のスペース (NULL, 0-) nudge_y = NULL, # マーカーからの縦方向のスペース (NULL, 0-) box.padding = 0.5, # テキスト周囲のスペース (0-) point.padding = 0.1, # マーカー周囲のスペース (0-) segment.alpha = 1.0, # 引き出し線の透明度 segment.color = &quot;grey&quot;, # 引き出し線の色 segment.size = 0.5, # 引き出し線の太さ min.segment.length = 0, # 引き出し線の最低長 color = &quot;black&quot;, # テキストの色 family = &quot;YUGO&quot;, # テキストのフォント fontface = &quot;plain&quot;, # テキストの書体 (plain / bold / italic / bold.italic) size = 4.0) # テキストのサイズ バブルチャートにラベルを追加 ggplot(data = data_mpg_point, mapping = aes(x = cty, y = hwy, size = displ)) + # aes() 関数内のsize引数に連続型変数を指定 geom_point(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 shape = 21, # マーカーの種類 stroke = 0.5) + # 線の太さ geom_text_repel(mapping = aes(label = manufacturer), seed = NA, # テキストの配置を決定するランダムシード direction = &quot;both&quot;, # テキストの整列方向 (both / x / y) hjust = 0.0, # 横方向の整列位置 (0-1) vjust = 0.5, # 縦方向の整列位置 (0-1) nudge_x = NULL, # マーカーからの横方向のスペース (NULL, 0-) nudge_y = NULL, # マーカーからの縦方向のスペース (NULL, 0-) box.padding = 1.0, # テキスト周囲のスペース (0-) point.padding = 0.1, # マーカー周囲のスペース (0-) segment.alpha = 1.0, # 引き出し線の透明度 segment.color = &quot;grey&quot;, # 引き出し線の色 segment.size = 0.5, # 引き出し線の太さ min.segment.length = 0, # 引き出し線の最低長 color = &quot;black&quot;, # テキストの色 family = &quot;YUGO&quot;, # テキストのフォント fontface = &quot;plain&quot;, # テキストの書体 (plain / bold / italic / bold.italic) size = 4.0) + # テキストのサイズ scale_size_area(max_size = 15) # 変量とマーカーの面積を比例させる 5.13 棒グラフ X軸：離散型変数 Y軸：連続型変数 棒グラフはgeom_col()関数で作成します。 まず、プロット用のデータを作成します。 data_mpg_col &lt;- mpg %&gt;% dplyr::group_by(manufacturer) %&gt;% dplyr::summarise(across(c(cty, hwy), mean, na.rm = TRUE)) data_mpg_col ## # A tibble: 15 x 3 ## manufacturer cty hwy ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 audi 17.6 26.4 ## 2 chevrolet 15 21.9 ## 3 dodge 13.1 17.9 ## 4 ford 14 19.4 ## 5 honda 24.4 32.6 ## 6 hyundai 18.6 26.9 ## 7 jeep 13.5 17.6 ## 8 land rover 11.5 16.5 ## 9 lincoln 11.3 17 ## 10 mercury 13.2 18 ## 11 nissan 18.1 24.6 ## 12 pontiac 17 26.4 ## 13 subaru 19.3 25.6 ## 14 toyota 18.5 24.9 ## 15 volkswagen 20.9 29.2 data_owid_col &lt;- data_owid %&gt;% dplyr::select(location, date, new_cases) %&gt;% dplyr::filter(location %in% c(&quot;Japan&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Italy&quot;)) %&gt;% dplyr::mutate(year = str_c(lubridate::year(date), &quot;年&quot;), .after = &quot;date&quot;) %&gt;% dplyr::group_by(location, year) %&gt;% dplyr::summarise(across(new_cases, sum, na.rm = TRUE)) data_owid_col ## # A tibble: 15 x 3 ## # Groups: location [5] ## location year new_cases ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 France 2020年 2735590 ## 2 France 2021年 7706191 ## 3 France 2022年 20585956 ## 4 Germany 2020年 1719737 ## 5 Germany 2021年 5430685 ## 6 Germany 2022年 20621545 ## 7 Italy 2020年 2107314 ## 8 Italy 2021年 4018517 ## 9 Italy 2022年 12108559 ## 10 Japan 2020年 235747 ## 11 Japan 2021年 1496547 ## 12 Japan 2022年 7509090 ## 13 United Kingdom 2020年 2491790 ## 14 United Kingdom 2021年 10480124 ## 15 United Kingdom 2022年 8862722 縦棒グラフの基本形 ggplot(data = data_mpg_col, mapping = aes(x = manufacturer, y = cty)) + geom_col(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 size = 0.5, # 線の太さ width = 0.9) + # 棒の幅 (0-1) theme(axis.text.x = element_text(angle = 45, hjust = 1.0)) 横棒グラフ 横棒グラフを作成するには、縦棒グラフを作成した後にcoord_flip()関数で横棒グラフに転換します。そのため、X軸とY軸の変数指定は縦棒グラフの場合と同じです。 ggplot(data = data_mpg_col, mapping = aes(x = manufacturer, y = cty)) + geom_col(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 size = 0.5, # 線の太さ width = 0.9) + # 棒の幅 (0-1) coord_flip() 縦棒グラフの順序並べ替え 縦棒グラフのX軸の順番を並べ替えるには、X軸の変数を指定する際にfct_reorder()関数を使用します。 ggplot(data = data_mpg_col, mapping = aes(x = fct_reorder(manufacturer, -cty), y = cty)) + geom_col(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 size = 0.5, # 線の太さ width = 0.9) + # 棒の幅 (0-1) theme(axis.text.x = element_text(angle = 45, hjust = 1.0)) 縦棒グラフにラベルを追加 縦棒グラフにデータラベルを追加するには、geom_text()関数を使用します。 ggplot(data = data_mpg_col, mapping = aes(x = fct_reorder(manufacturer, -cty), y = cty)) + geom_col(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 size = 0.5, # 線の太さ width = 0.9) + # 棒の幅 (0-1) geom_text(mapping = aes(label = cty %&gt;% sprintf(fmt = &quot;%0.1f&quot;)), # sprintf() 関数で数値の表示形式を指定 vjust = -1, # 縦方向の整列位置 (0-1) color = &quot;black&quot;, # テキストの色 family = &quot;YUGO&quot;, # テキストのフォント fontface = &quot;plain&quot;, # テキストの書体 (plain / bold / italic / bold.italic) size = 4.0) + # テキストのサイズ theme(axis.text.x = element_text(angle = 45, hjust = 1.0)) 集合縦棒グラフ 複数の縦棒グラフを横並び形式で作成するには、position引数にposition_dodge()関数を指定します。 ggplot(data = data_owid_col, mapping = aes(x = location, y = new_cases, fill = year, group = rev(year))) + geom_col(position = position_dodge(width = 0.5), # 横並びポジション alpha = 1.0, # 塗りつぶしの透明度 size = 0.5, # 線の太さ width = 0.9) # 棒の幅 (0-1) 積み上げ縦棒グラフ 複数の縦棒グラフを積み上げ形式で作成するには、position引数にposition_stack()関数を指定します。 ggplot(data = data_owid_col, mapping = aes(x = location, y = new_cases, fill = year, group = rev(year))) + geom_col(position = position_stack(), # 積み上げポジション alpha = 1.0, # 塗りつぶしの透明度 size = 0.5, # 線の太さ width = 0.9) + # 棒の幅 (0-1) guides(fill = guide_legend(reverse = TRUE)) 積み上げ縦棒グラフにラベルを追加 ggplot(data = data_owid_col, mapping = aes(x = location, y = new_cases, fill = year, group = rev(year))) + geom_col(position = position_stack(), # 積み上げポジション alpha = 1.0, # 塗りつぶしの透明度 size = 0.5, # 線の太さ width = 0.9) + # 棒の幅 (0-1) geom_text(mapping = aes(label = new_cases %&gt;% sprintf(fmt = &quot;%0.1f&quot;)), # sprintf() 関数で数値の表示形式を指定 position = position_stack(vjust = 0.5), # position_stack() 関数で積み上げ棒グラフ上のラベル位置を指定 color = &quot;white&quot;, # テキストの色 family = &quot;YUGO&quot;, # テキストのフォント fontface = &quot;plain&quot;, # テキストの書体 (plain / bold / italic / bold.italic) size = 4.0) + # テキストのサイズ guides(fill = guide_legend(reverse = TRUE)) 100％積み上げ縦棒グラフ 複数の縦棒グラフを合計が100％になる積み上げ形式で作成するには、position引数にposition_fill()関数を指定します。 ggplot(data = data_owid_col, mapping = aes(x = location, y = new_cases, fill = year, group = rev(year))) + geom_col(position = position_fill(), # 割合積み上げポジション alpha = 1.0, # 塗りつぶしの透明度 size = 0.5, # 線の太さ width = 0.9) + # 棒の幅 (0-1) guides(fill = guide_legend(reverse = TRUE)) 100％積み上げ縦棒グラフにラベルを追加 data_owid_col %&gt;% dplyr::group_by(location) %&gt;% dplyr::mutate(percent = new_cases / sum(new_cases)) %&gt;% ggplot(mapping = aes(x = location, y = new_cases, fill = year, group = rev(year))) + geom_col(position = position_fill(), # 割合ポジション alpha = 1.0, # 塗りつぶしの透明度 size = 0.5, # 線の太さ width = 0.9) + # 棒の幅 (0-1) geom_text(mapping = aes(label = percent %&gt;% sprintf(fmt = &quot;%0.2f&quot;)), # sprintf() 関数で数値の表示形式を指定 position = position_fill(vjust = 0.5), # position_fill() 関数で割合棒グラフ上のラベル位置を指定 color = &quot;white&quot;, # テキストの色 family = &quot;YUGO&quot;, # テキストのフォント fontface = &quot;plain&quot;, # テキストの書体 (plain / bold / italic / bold.italic) size = 4.0) + # テキストのサイズ guides(fill = guide_legend(reverse = TRUE)) 5.14 円グラフ X軸：単一の値 Y軸：連続型変数 円グラフを作成するには、geom_col()関数で積み上げ棒グラフを作成した後に、coord_polar()関数で円グラフに転換します。 まず、プロット用のデータを作成します。 data_mpg_circle &lt;- mpg %&gt;% dplyr::group_by(class) %&gt;% dplyr::summarise(across(c(hwy), mean, na.rm = TRUE)) data_mpg_circle ## # A tibble: 7 x 2 ## class hwy ## &lt;chr&gt; &lt;dbl&gt; ## 1 2seater 24.8 ## 2 compact 28.3 ## 3 midsize 27.3 ## 4 minivan 22.4 ## 5 pickup 16.9 ## 6 subcompact 28.1 ## 7 suv 18.1 円グラフの基本形 ggplot(data = data_mpg_circle, mapping = aes(x = 1, y = hwy, fill = class, group = rev(class))) + geom_col(position = position_stack(), # 積み上げポジション alpha = 1.0, # 塗りつぶしの透明度 color = &quot;grey&quot;, # 線の色 size = 0.5) + # 線の太さ geom_text(mapping = aes(label = hwy %&gt;% sprintf(fmt = &quot;%0.1f&quot;)), # sprintf() 関数で数値の表示形式を指定 position = position_stack(vjust = 0.5), # position_stack() 関数で積み上げ棒グラフ上のラベル位置を指定 color = &quot;white&quot;, # テキストの色 family = &quot;YUGO&quot;, # テキストのフォント fontface = &quot;plain&quot;, # テキストの書体 (plain / bold / italic / bold.italic) size = 4.0) + # テキストのサイズ coord_polar(theta = &quot;y&quot;, # 円グラフを作成する軸 start = 0, # 円グラフの開始位置（ラジアン） direction = 1) + # 円グラフの方向（1：時計回り、-1：反時計回り） theme(panel.grid = element_blank(), # パネルの軸や目盛り線を表示しない axis.title = element_blank(), axis.text = element_blank(), axis.ticks = element_blank()) + guides(fill = guide_legend(reverse = FALSE)) 5.15 折れ線グラフ X軸：日付型変数 Y軸：連続型変数 折れ線グラフは時系列データを可視化する最も基本的なグラフで、geom_line()関数で作成します。 まず、プロット用のデータを作成します。 data_owid_line &lt;- data_owid %&gt;% dplyr::select(location, date, new_cases_smoothed) %&gt;% dplyr::filter(location %in% c(&quot;Japan&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Italy&quot;), date &gt;= &quot;2022-01-01&quot;) %&gt;% tidyr::drop_na(everything()) data_owid_line ## # A tibble: 876 x 3 ## location date new_cases_smoothed ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 France 2022-01-01 157705. ## 2 France 2022-01-02 162095. ## 3 France 2022-01-03 167381. ## 4 France 2022-01-04 180515. ## 5 France 2022-01-05 198252. ## 6 France 2022-01-06 206286. ## 7 France 2022-01-07 220003. ## 8 France 2022-01-08 232080. ## 9 France 2022-01-09 266032. ## 10 France 2022-01-10 269809. ## # ... with 866 more rows 折れ線グラフの基本形 ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_line(alpha = 1.0, # 線の透明度 color = &quot;darkblue&quot;, # 線の色 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) # 線の太さ 折れ線グラフにマーカーを追加 折れ線グラフを作成するgeom_line()関数と、散布図を作成するgeom_point()関数を併用します。 ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_line(alpha = 1.0, # 線の透明度 color = &quot;darkblue&quot;, # 線の色 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) + # 線の太さ geom_point(alpha = 1.0, # 塗りつぶしの透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 shape = 21, # マーカーの種類 size = 2.0, # マーカーの大きさ stroke = 0.5) # 線の太さ 折れ線グラフに系列ラベルを追加 折れ線グラフの数が多く凡例が分かりにくい場合などに、折れ線グラフの右側に系列名のラベルを追加します。ラベルを追加するには、ggrepelパッケージのgeom_text_repel関数を使用します。 ggplot(data = data_owid_line, mapping = aes(x = date, y = new_cases_smoothed, color = location)) + geom_line(alpha = 1.0, # 線の透明度 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) + # 線の太さ geom_text_repel(data = data_owid_line %&gt;% dplyr::group_by(location) %&gt;% dplyr::filter(date == max(date)), mapping = aes(x = date, y = new_cases_smoothed, label = location), seed = NA, # テキストの配置を決定するランダムシード direction = &quot;y&quot;, # テキストの整列方向 (both / x / y) hjust = 0.0, # 横方向の整列位置 (0-1) vjust = 0.5, # 縦方向の整列位置 (0-1) nudge_x = 5, # マーカーからの横方向のスペース (NULL, 0-) nudge_y = NULL, # マーカーからの縦方向のスペース (NULL, 0-) box.padding = 0.1, # テキスト周囲のスペース (0-) point.padding = 0.1, # マーカー周囲のスペース (0-) segment.alpha = 1.0, # 引き出し線の透明度 segment.color = &quot;grey&quot;, # 引き出し線の色 segment.size = 0.5, # 引き出し線の太さ min.segment.length = Inf, # 引き出し線の最低長 family = &quot;YUGO&quot;, # テキストのフォント fontface = &quot;plain&quot;, # テキストの書体 (plain / bold / italic / bold.italic) size = 3.0) + # テキストのサイズ scale_x_date(date_breaks = &quot;1 month&quot;, # 日付目盛の周期 date_labels = &quot;%y/%b&quot;, # %Y：4桁年、%y：2桁年、%m：2桁月、%b：1桁月、%d：日 limits = c(as.Date(&quot;2022/01/01&quot;), NA), # 始期・終期（指定しない場合はNA） expand = expansion(mult = c(0.00, 0.2), add = c(0, 0))) + # 始期・終期からの余白（multは余白率、addは余白幅） theme(legend.position = &quot;none&quot;) 5.16 ステップグラフ X軸：日付型変数 Y軸：連続型変数 ステップグラフは折れ線グラフの特殊形です。政策金利のように、段階的に値が変化するデータに適しています。ステップグラフはgeom_step()関数で作成します。 まず、サンプルデータを作成します。ここでは、Our World in Dataのdata_owidデータセットに含まれるStringency Indexのステップグラフを作成します。Stringency Indexは、各国当局が実施する新型コロナウイルス感染対策の厳格度を示す指数であり、段階的に値が変化します。 data_owid_step &lt;- data_owid %&gt;% dplyr::select(location, date, stringency_index) %&gt;% dplyr::filter(location %in% c(&quot;Japan&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Italy&quot;)) data_owid_step ## # A tibble: 4,410 x 3 ## location date stringency_index ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 France 2020-01-24 5.56 ## 2 France 2020-01-25 5.56 ## 3 France 2020-01-26 5.56 ## 4 France 2020-01-27 5.56 ## 5 France 2020-01-28 5.56 ## 6 France 2020-01-29 5.56 ## 7 France 2020-01-30 5.56 ## 8 France 2020-01-31 5.56 ## 9 France 2020-02-01 5.56 ## 10 France 2020-02-02 5.56 ## # ... with 4,400 more rows ステップグラフの基本形 ggplot(data = data_owid_step, mapping = aes(x = date, y = stringency_index, color = location)) + geom_step(alpha = 1.0, # 線の透明度 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) # 線の太さ 5.17 面グラフ X軸：日付型変数 Y軸：連続型変数 面グラフは折れ線グラフの特殊形です。面グラフには2種類あり、折れ線グラフとX軸で挟まれた範囲を塗りつぶすグラフはgeom_area()関数、2つの折れ線グラフで挟まれた範囲を塗りつぶすグラフはgeom_ribbon()関数で作成します。後者は特にリボングラフと呼ばれ、信頼区間の可視化に用いることができます。 まず、プロット用のデータを作成します。 data_owid_line &lt;- data_owid %&gt;% dplyr::select(location, date, new_cases_smoothed) %&gt;% dplyr::filter(location %in% c(&quot;Japan&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Italy&quot;), date &gt;= &quot;2022-01-01&quot;) %&gt;% tidyr::drop_na(everything()) data_owid_line ## # A tibble: 876 x 3 ## location date new_cases_smoothed ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 France 2022-01-01 157705. ## 2 France 2022-01-02 162095. ## 3 France 2022-01-03 167381. ## 4 France 2022-01-04 180515. ## 5 France 2022-01-05 198252. ## 6 France 2022-01-06 206286. ## 7 France 2022-01-07 220003. ## 8 France 2022-01-08 232080. ## 9 France 2022-01-09 266032. ## 10 France 2022-01-10 269809. ## # ... with 866 more rows 面グラフの基本形 ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_area(alpha = 1.0, # 線の透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) # 線の太さ 積み上げ面グラフ 複数の面グラフを積み上げ形式で作成するには、position引数にposition_stack()関数を指定します。 data_owid_line %&gt;% dplyr::mutate(location = factor(location, levels = c(&quot;Japan&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;France&quot;, &quot;Italy&quot;) %&gt;% rev())) %&gt;% ggplot(mapping = aes(x = date, y = new_cases_smoothed, fill = location)) + geom_area(position = position_stack(), alpha = 1.0, # 線の透明度 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) # 線の太さ リボングラフの基本形 リボングラフでは、aes()関数の中で塗りつぶし範囲の下端をymin引数、上端をymax引数に指定します。 data_owid_line %&gt;% dplyr::group_by(date) %&gt;% dplyr::summarise(new_cases_max = max(new_cases_smoothed, na.rm = TRUE), new_cases_min = min(new_cases_smoothed, na.rm = TRUE)) %&gt;% ggplot(mapping = aes(x = date, ymin = new_cases_min, ymax = new_cases_max)) + geom_ribbon(alpha = 1.0, # 線の透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 0.5) # 線の太さ リボングラフに折れ線グラフを追加 リボングラフに折れ線グラフを追加する際は、まずgeom_ribbon()関数でリボングラフを作成し、そのあとに+演算子でgeom_line()関数をつなげて折れ線グラフを追加します。 data_owid_line %&gt;% dplyr::group_by(date) %&gt;% dplyr::summarise(new_cases_max = max(new_cases_smoothed, na.rm = TRUE), new_cases_median = median(new_cases_smoothed, na.rm = TRUE), new_cases_min = min(new_cases_smoothed, na.rm = TRUE)) %&gt;% ggplot(mapping = aes(x = date, ymin = new_cases_min, ymax = new_cases_max, y = new_cases_median)) + geom_ribbon(alpha = 1.0, # 線の透明度 color = &quot;darkblue&quot;, # 線の色 fill = &quot;lightblue&quot;, # 塗りつぶしの色 linetype = &quot;solid&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 0.5) + # 線の太さ geom_line(alpha = 1.0, # 線の透明度 color = &quot;red&quot;, # 線の色 linetype = &quot;dashed&quot;, # 線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 1.0) # 線の太さ 5.18 箱ひげ図・ヴァイオリングラフ X軸：離散型変数 Y軸：連続型変数 データの分布範囲を可視化するには箱ひげ図やヴァイオリングラフを用います。箱ひげ図はgeom_boxplot()関数、ヴァイオリングラフはgeom_violin()関数で作成します。 また、geom_jitter()関数で作成するジッターグラフを併用し、箱ひげ図やヴァイオリングラフに個別データの位置をプロットすると、データの分布がより具体的に分かりやすくなります。 箱ひげ図の基本形 箱ひげ図は一般的に、ひげの下端が最小値、箱の下端が第1四分位数、箱内部の横線が中央値、箱の上端が第3四分位数、ひげの上端が最大値を表します。 しかし、ggplot2パッケージのgeom_boxplot()で作成すると、ひげの下端・上端は箱の下端・上端から1.5×IQRの範囲内にある最小・最大のサンプルの位置を表すことに注意が必要です。その範囲外にあるサンプルは外れ値として扱われます。なお、IQRは四分位範囲（第3四分位数-第1四分位数）を意味します。 ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot(outlier.alpha = 1.0, # 外れ値マーカーの塗りつぶしの透明度 outlier.color = &quot;darkblue&quot;, # 外れ値マーカーの線の色 outlier.fill = &quot;lightblue&quot;, # 外れ値マーカーの塗りつぶしの色 outlier.shape = 21, # 外れ値マーカーの種類（外れ値を表示しない場合はNA） outlier.size = 2.0, # 外れ値マーカーの大きさ outlier.stroke = 0.5, # 外れ値マーカーの線の太さ alpha = 0.5, # 箱の塗りつぶしの透明度 color = &quot;darkblue&quot;, # 箱ひげの線の色 fill = &quot;lightblue&quot;, # 箱の塗りつぶしの色 size = 0.5) # 箱ひげの線の太さ 箱ひげ図に個別サンプルを追加 箱ひげ図にジッターグラフで個別サンプルを追加する場合は、データの重複表示を避けるため、geom_boxplot()関数のoutlier.shape引数にNAを指定して、箱ひげ図による外れ値のマーカーを非表示にします。 ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot(outlier.shape = NA, # 外れ値マーカーの種類（外れ値を表示しない場合はNA） alpha = 0.5, # 箱の塗りつぶしの透明度 color = &quot;darkblue&quot;, # 箱ひげの線の色 fill = &quot;lightblue&quot;, # 箱の塗りつぶしの色 size = 0.5) + # 箱ひげの線の太さ geom_jitter(height = 0.3, # マーカーの縦方向の分布範囲 width = 0.3, # マーカーの横方向の分布範囲 alpha = 1.0, # マーカーの塗りつぶしの透明度 color = &quot;darkblue&quot;, # マーカーの線の色 fill = &quot;darkblue&quot;, # マーカーの塗りつぶしの色 shape = 21, # マーカーの種類 size = 1.0, # マーカーの大きさ stroke = 0.5) # マーカーの線の太さ ヴァイオリングラフの基本形 ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_violin(scale = &quot;area&quot;, # ヴァイオリンの大きさ（area：すべての面積が同じ、count：サンプル個数に比例、width：すべての幅が同じ） alpha = 0.5, # ヴァイオリンの塗りつぶしの透明度 color = &quot;darkblue&quot;, # ヴァイオリンの線の色 fill = &quot;lightblue&quot;, # ヴァイオリンの塗りつぶしの色 linetype = &quot;solid&quot;, # ヴァイオリンの線の種類 size = 0.5) # ヴァイオリンの線の太さ ヴァイオリングラフに個別サンプルを追加 ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_violin(scale = &quot;area&quot;, # ヴァイオリンの大きさ（area：すべての面積が同じ、count：サンプル個数に比例、width：すべての幅が同じ） alpha = 0.5, # ヴァイオリンの塗りつぶしの透明度 color = &quot;darkblue&quot;, # ヴァイオリンの線の色 fill = &quot;lightblue&quot;, # ヴァイオリンの塗りつぶしの色 linetype = &quot;solid&quot;, # ヴァイオリンの線の種類 size = 0.5) + # ヴァイオリンの線の太さ geom_jitter(height = 0.4, # マーカーの縦方向の分布範囲 width = 0.4, # マーカーの横方向の分布範囲 alpha = 1.0, # マーカーの塗りつぶしの透明度 color = &quot;darkblue&quot;, # マーカーの線の色 fill = &quot;darkblue&quot;, # マーカーの塗りつぶしの色 shape = 21, # マーカーの種類 size = 1.0, # マーカーの大きさ stroke = 0.5) # マーカーの線の太さ 5.19 ドットプロット X軸：離散型変数 Y軸：離散型変数 ドットプロットはgeom_dotplot()関数で作成します。実務では、FOMCで示される参加者の政策金利予想を可視化する際に使用されます。 ドットプロットの基本形 ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_dotplot(binaxis = &quot;y&quot;, binwidth = 0.5, stackdir = &quot;center&quot;, alpha = 1.0, # マーカーの塗りつぶしの透明度 color = &quot;darkblue&quot;, # マーカーの線の色 fill = &quot;lightblue&quot;, # マーカーの塗りつぶしの色 stroke = 0.5) # マーカーの線の太さ 5.20 色の設定 変数の値や属性に応じて色を自動で変化させるには、geom関数ファミリーでグラフを作成したあとに、+演算子でscale_color関数ファミリー（線の色）やscale_fill関数ファミリー（塗りつぶしの色）をつなぎます。色の変化に対応する変数が離散型か連続型かによって、どのscale_color/fill関数を用いるかが変わります。 まず、プロット用のデータを作成します。 data_mpg_color &lt;- mpg %&gt;% dplyr::group_by(class) %&gt;% dplyr::summarise(across(c(cty, hwy), mean, na.rm = TRUE)) data_mpg_color ## # A tibble: 7 x 3 ## class cty hwy ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2seater 15.4 24.8 ## 2 compact 20.1 28.3 ## 3 midsize 18.8 27.3 ## 4 minivan 15.8 22.4 ## 5 pickup 13 16.9 ## 6 subcompact 20.4 28.1 ## 7 suv 13.5 18.1 色の手動指定（離散型変数） 自分で色の割り当てを決める方法です。Rで使用できる色の種類については、こちらを参照してください。 ggplot(data = mpg, mapping = aes(x = fl, color = fl, fill = fl)) + geom_bar() + scale_color_manual(values = c(&quot;Red&quot;, &quot;Salmon&quot;, &quot;Gold&quot;, &quot;Forestgreen&quot;, &quot;Darkblue&quot;)) + # colorで指定した変数の離散値と同数の色を指定 scale_fill_manual(values = c(&quot;Red&quot;, &quot;Salmon&quot;, &quot;Gold&quot;, &quot;Forestgreen&quot;, &quot;Darkblue&quot;)) # fillで指定した変数の離散値と同数の色を指定 Brewerカラーパレット（離散型変数） RColorBrewerパッケージでは、様々な種類の美麗なプリセットカラーパレットが利用できます。 # カラーパレットの確認 RColorBrewer::display.brewer.all() ggplot(data = mpg, mapping = aes(x = fl, color = fl, fill = fl)) + geom_bar() + scale_color_brewer(palette = &quot;Paired&quot;, # カラーパレット名 direction = 1) + # 色の順序（-1で逆順） scale_fill_brewer(palette = &quot;Paired&quot;, # カラーパレット名 direction = 1) # 色の順序（-1で逆順） Viridisカラーパレット（離散型変数） 色覚障害に対応したカラーパレットです。パレットの種類などの詳細はこちらを参照してください。 ggplot(data = mpg, mapping = aes(x = fl, color = fl, fill = fl)) + geom_bar() + scale_color_viridis_d(option = &quot;viridis&quot;, # パレットの種類（magma / inferno / plasma / viridis / cividis） direction = 1) + # 色の順序（-1で逆順） scale_fill_viridis_d(option = &quot;viridis&quot;, # パレットの種類（magma / inferno / plasma / viridis / cividis） direction = 1) # 色の順序（-1で逆順） ggsciカラーパレット（離散型変数） 様々な科学ジャーナルで使用されるカラーパレットです。パレットの種類などの詳細はこちらをご覧ください。 ggplot(data = mpg, mapping = aes(x = fl, color = fl, fill = fl)) + geom_bar() + scale_color_npg() + scale_fill_npg() distillerカラーパレット（連続型変数） こちらは、RColorBrewerパッケージの連続型変数用の関数です。様々な種類の美麗なプリセットカラーパレットが利用できます。 # カラーパレットの確認 RColorBrewer::display.brewer.all() ggplot(data = mpg, mapping = aes(x = hwy, fill = ..x..)) + geom_dotplot() + scale_fill_distiller(palette = &quot;Blues&quot;, # カラーパレット名 direction = 1) # 色の順序（-1で逆順） Viridisカラーパレット（連続型変数） 色覚障害に対応したカラーパレットです。パレットの種類などの詳細はこちらを参照してください。 ggplot(data = mpg, mapping = aes(x = hwy, fill = ..x..)) + geom_dotplot() + scale_fill_viridis_c(option = &quot;viridis&quot;, # パレットの種類（magma / inferno / plasma / viridis / cividis） direction = 1) # 色の順序（-1で逆順） gradientカラーパレット（連続型変数） 自分で色を指定してグラデーションを作成するカラーパレットです。2色グラデーション、3色グラデーション、n色グラデーションの3種類の関数があります。n色グラデーションでは、事前にベースとなるカラーパレットをRColorBrewer::display.brewer.all()関数などで確認して使用します。 # 2色グラデーション ggplot(data = mpg, mapping = aes(x = hwy, fill = ..x..)) + geom_dotplot() + scale_fill_gradient(low = &quot;Red&quot;, # 最小値の色 high = &quot;Forestgreen&quot;) # 最大値の色 # 3色グラデーション ggplot(data = mpg, mapping = aes(x = hwy, fill = ..x..)) + geom_dotplot() + scale_fill_gradient2(low = &quot;Red&quot;, # 最小値の色 mid = &quot;Gold&quot;, # 中間値の色 high = &quot;Forestgreen&quot;, # 最大値の色 midpoint = 30) # 中間値 # パレットを指定したn色グラデーション ggplot(data = mpg, mapping = aes(x = hwy, fill = ..x..)) + geom_dotplot() + scale_fill_gradientn(colors = brewer.pal(name = &quot;RdYlGn&quot;, n = 9)) 5.21 軸の設定 X軸、Y軸の設定を行うには、scale_x/y関数ファミリーを使用します。X軸、Y軸に指定する変数の型によって、使用する関数が異なります。 まず、プロット用のデータを作成します。 data_owid_scale &lt;- data_owid %&gt;% dplyr::group_by(location) %&gt;% dplyr::summarise(across(c(new_cases, new_deaths), mean, na.rm = TRUE)) summary(data_owid_scale) ## location new_cases new_deaths ## Length:244 Min. : 0.0 Min. : 0.007 ## Class :character 1st Qu.: 40.8 1st Qu.: 0.436 ## Mode :character Median : 308.4 Median : 4.173 ## Mean : 11487.2 Mean : 135.023 ## 3rd Qu.: 2024.3 3rd Qu.: 23.647 ## Max. :611599.7 Max. :7087.797 ## NA&#39;s :15 NA&#39;s :21 X軸：連続型、Y軸：連続型 ggplot(data = data_owid_scale, mapping = aes(x = new_cases, y = new_deaths)) + geom_point() + geom_smooth() + scale_x_continuous(breaks = breaks_x &lt;- seq(0, 1e+06, 100000), # 目盛 labels = breaks_x, # 目盛ラベル limits = c(0, 7e+05), # 下限・上限値（指定しない場合はNA） expand = expansion(mult = c(0.05, 0.05), add = c(0, 0))) + # 下限・上限値からの余白（multは余白率、addは余白幅） scale_y_continuous(breaks = breaks_y &lt;- seq(0, 10000, 1000), # 目盛 labels = breaks_y, # 目盛ラベル limits = c(0, 8000), # 下限・上限値（指定しない場合はNA） expand = expansion(mult = c(0.05, 0.05), add = c(0, 0))) + # 下限・上限値からの余白（multは余白率、addは余白幅） labs(x = &quot;新規感染者数（1日当たり平均、人）&quot;, # X軸のタイトル y = &quot;新規死亡者数（1日当たり平均、人）&quot;) + # Y軸のタイトル theme(axis.title = element_text(size = 8), # 軸タイトルの文字サイズ axis.text.x = element_text(angle = 0, # X軸ラベルの角度 hjust = 0.5, # X軸ラベルの横整列位置（0-1） vjust = 0.5), # X軸ラベルの縦整列位置（0-1） axis.text.y = element_text(angle = 0, # Y軸ラベルの角度 hjust = 0.5, # Y軸ラベルの横整列位置（0-1） vjust = 0.5)) # Y軸ラベルの縦整列位置（0-1） ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 対数目盛 ggplot(data = data_owid_scale, mapping = aes(x = new_cases, y = new_deaths)) + geom_point() + geom_smooth() + scale_x_log10(breaks = breaks_x &lt;- 10 ** seq(0, 6, 1), # 目盛 labels = c(breaks_x[1:4], &quot;1万&quot;, &quot;10万&quot;, &quot;100万&quot;), # 目盛ラベル limits = c(1, 7e+05), # 下限・上限値（指定しない場合はNA） expand = expansion(mult = c(0.05, 0.05), add = c(0, 0))) + # 下限・上限値からの余白（multは余白率、addは余白幅） scale_y_log10(breaks = breaks_y &lt;- 10 ** seq(0, 4, 1), # 目盛 labels = c(breaks_y[1:4], &quot;1万&quot;), # 目盛ラベル limits = c(1, 8000), # 下限・上限値（指定しない場合はNA） expand = expansion(mult = c(0.05, 0.05), add = c(0, 0))) + # 下限・上限値からの余白（multは余白率、addは余白幅） labs(x = &quot;新規感染者数（1日当たり平均、人）&quot;, # X軸のタイトル y = &quot;新規死亡者数（1日当たり平均、人）&quot;) + # Y軸のタイトル theme(axis.title = element_text(size = 8), # 軸タイトルの文字サイズ axis.text.x = element_text(angle = 0, # X軸ラベルの角度 hjust = 0.5, # X軸ラベルの横整列位置（0-1） vjust = 0.5), # X軸ラベルの縦整列位置（0-1） axis.text.y = element_text(angle = 0, # Y軸ラベルの角度 hjust = 0.5, # Y軸ラベルの横整列位置（0-1） vjust = 0.5)) # Y軸ラベルの縦整列位置（0-1） ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; X軸：日付型、Y軸：連続型 # date_breaks引数を使用する場合 ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_line() + scale_x_date(date_breaks = &quot;3 month&quot;, # 日付目盛の周期 date_labels = &quot;%y/%b&quot;, # 日付フォーマット（%Y：4桁年、%y：2桁年、%m：2桁月、%b：1桁月、%d：日） limits = c(as.Date(&quot;2000/01/01&quot;), as.Date(&quot;2002/12/31&quot;)), # 始期・終期（指定しない場合はNA） expand = expansion(mult = c(0.00, 0.00), add = c(0, 0))) + # 始期・終期からの余白（multは余白率、addは余白幅） scale_y_continuous(breaks = breaks_y &lt;- seq(0, 50000, 1000), # 目盛 labels = breaks_y, # 目盛ラベル limits = c(5000, 10000), # 下限・上限値（指定しない場合はNA） expand = expansion(mult = c(0.05, 0.05), add = c(0, 0))) + # 下限・上限値からの余白（multは余白率、addは余白幅） labs(x = &quot;日付（年/月）&quot;, # X軸のタイトル y = &quot;失業者数（千人）&quot;) + # Y軸のタイトル theme(axis.title = element_text(size = 8), # 軸タイトルの文字サイズ axis.text.x = element_text(angle = 0, # X軸ラベルの角度 hjust = 0.5, # X軸ラベルの横整列位置（0-1） vjust = 0.5), # X軸ラベルの縦整列位置（0-1） axis.text.y = element_text(angle = 0, # Y軸ラベルの角度 hjust = 0.5, # Y軸ラベルの横整列位置（0-1） vjust = 0.5)) # Y軸ラベルの縦整列位置（0-1） # date_breaks引数を使用しない場合（結果は同じ） ggplot(data = economics, mapping = aes(x = date, y = unemploy)) + geom_line() + scale_x_date(breaks = breaks_x &lt;- seq(as.Date(&quot;1967-01-01&quot;), max(economics$date), by = &quot;3 months&quot;), # 日付目盛ベクトル date_labels = str_c(str_sub(lubridate::year(breaks_x), 3, 4), &quot;/&quot;, lubridate::month(breaks_x)), # 日付目盛ベクトルをラベル用に加工 limits = c(as.Date(&quot;2000/01/01&quot;), as.Date(&quot;2002/12/31&quot;)), # 始期・終期（指定しない場合はNA） expand = expansion(mult = c(0.00, 0.00), add = c(0, 0))) + # 始期・終期からの余白（multは余白率、addは余白幅） scale_y_continuous(breaks = breaks_y &lt;- seq(0, 50000, 1000), # 目盛 labels = breaks_y, # 目盛ラベル limits = c(5000, 10000), # 下限・上限値（指定しない場合はNA） expand = expansion(mult = c(0.05, 0.05), add = c(0, 0))) + # 下限・上限値からの余白（multは余白率、addは余白幅） labs(x = &quot;日付（年/月）&quot;, # X軸のタイトル y = &quot;失業者数（千人）&quot;) + # Y軸のタイトル theme(axis.title = element_text(size = 8), # 軸タイトルの文字サイズ axis.text.x = element_text(angle = 0, # X軸ラベルの角度 hjust = 0.5, # X軸ラベルの横整列位置（0-1） vjust = 0.5), # X軸ラベルの縦整列位置（0-1） axis.text.y = element_text(angle = 0, # Y軸ラベルの角度 hjust = 0.5, # Y軸ラベルの横整列位置（0-1） vjust = 0.5)) # Y軸ラベルの縦整列位置（0-1） 5.22 複合グラフ（ファセット） 複数のグラフをまとめたファセットを作成するには、facet関数ファミリーを使用します。どのようなファセットにするかで使用する関数が異なります。 行方向の複合グラフ 行方向に複合グラフを並べる場合は、facet_rep_grid()関数のrows引数にvars(離散型変数)の形でグラフを分けて作成したい変数名を指定します。 ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() + facet_rep_grid(rows = vars(class), # 変数class別にグラフを作成 scales = &quot;fixed&quot;, # 目盛設定（fixed：全グラフ共通、free：全グラフ独立、free_x：X軸のみ独立、free_y：Y軸のみ独立） repeat.tick.labels = FALSE) # 目盛表示（TRUE：すべてのグラフに表示、FALSE：端のグラフのみ表示 列方向の複合グラフ 列方向に複合グラフを並べる場合は、facet_rep_grid()関数のcols引数にvars(離散型変数)の形でグラフを分けて作成したい変数名を指定します。 ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() + facet_rep_grid(cols = vars(class), # 変数class別にグラフを作成 scales = &quot;fixed&quot;, # 目盛設定（fixed：全グラフ共通、free：全グラフ独立、free_x：X軸のみ独立、free_y：Y軸のみ独立） repeat.tick.labels = FALSE) # 目盛表示（TRUE：すべてのグラフに表示、FALSE：端のグラフのみ表示 行・列方向の複合グラフ 行・列方向に複合グラフを並べる場合は、facet_rep_grid()関数のrows引数とcols引数にそれぞれvars(離散型変数)の形でグラフを分けて作成したい変数名を指定します。 ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() + facet_rep_grid(rows = vars(year), # 変数year別に行方向のグラフを作成 cols = vars(class), # 変数class別に列方向のグラフを作成 scales = &quot;fixed&quot;, # 目盛設定（fixed：全グラフ共通、free：全グラフ独立、free_x：X軸のみ独立、free_y：Y軸のみ独立） repeat.tick.labels = TRUE) # 目盛表示（TRUE：すべてのグラフに表示、FALSE：端のグラフのみ表示 行数・列数を指定した複合グラフ 行数と列数を指定してグラフを順番に並べるには、facet_rep_wrap()関数のfacets引数に「~ 離散型変数」の形でグラフを分けて作成したい変数名を指定し、nrow引数とncol引数に行数・列数を指定します。 ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() + facet_rep_wrap(facets = ~ manufacturer, # 変数manufacturer別にグラフを作成 nrow = 3, # 行方向のグラフ数 ncol = 5, # 列方向のグラフ数 scales = &quot;fixed&quot;, # 目盛設定（fixed：全グラフ共通、free：全グラフ独立、free_x：X軸のみ独立、free_y：Y軸のみ独立） repeat.tick.labels = TRUE) # 目盛表示（TRUE：すべてのグラフに表示、FALSE：端のグラフのみ表示 複合グラフの設定 ファセットの各種設定を行うには、theme()関数内に必要事項を記入します。 # 行数・列数を指定した複合グラフの例 ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() + facet_rep_wrap(facets = ~ manufacturer) + # 変数manufacturer別にグラフを作成 theme(strip.background = element_rect(color = NA, # ファセットタイトル領域の枠の色 fill = &quot;White&quot;), # ファセットタイトル領域の塗りつぶしの色（NAで無色） strip.text = element_text(color = &quot;Black&quot;, # ファセットタイトルの色 face = &quot;bold&quot;, # ファセットタイトルの書体 size = 8, # ファセットタイトルのフォントサイズ hjust = 0.5, # ファセットタイトルの横方向の整列位置 vjust = 0.5), # ファセットタイトルの縦方向の整列位置 panel.spacing.x = unit(x = 2, units = &quot;mm&quot;), # ファセットのグラフ間の横方向のスペース panel.spacing.y = unit(x = 2, units = &quot;mm&quot;)) # ファセットのグラフ間の縦方向のスペース 5.23 地図ファセット 国別・州別・都道府県別のデータを、地図を模した複合グラフに表示するには、geofacetパッケージのfacet_geo()関数を使用します。 ここでは、日本の県内総生産データを使用します。 data_gdp_pref ## # A tibble: 611 x 5 ## pref_code pref_name year gdp_nominal gdp_nominal_pchg ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 北海道 2006 19316568 NA ## 2 1 北海道 2007 19137599 -0.927 ## 3 1 北海道 2008 18457858 -3.55 ## 4 1 北海道 2009 18219113 -1.29 ## 5 1 北海道 2010 18122675 -0.529 ## 6 1 北海道 2011 18071493 -0.282 ## 7 1 北海道 2012 17923502 -0.819 ## 8 1 北海道 2013 18242119 1.78 ## 9 1 北海道 2014 18579766 1.85 ## 10 1 北海道 2015 19128504 2.95 ## # ... with 601 more rows geofacetパッケージでは、都道府県名と地図上の位置を結びつけるjp_prefs_grid2データが用意されています。ただし都道府県名が英語表記でしか格納されていないため、日本語表記を名寄せして追加します。 # geofacetのjp_prefs_grid2に都道府県名の日本語表記を追加 data_prefs &lt;- data_gdp_pref %&gt;% dplyr::select(pref_code, pref_name) %&gt;% dplyr::distinct() %&gt;% dplyr::rename(code = pref_code) jp_prefs_grid2 %&lt;&gt;% dplyr::left_join(data_prefs, by = &quot;code&quot;) そのうえで、ファセット部分にfacet_geo()関数を用いると、都道府県別のデータを日本地図を模した形でグラフ化することができます。 ggplot(data = data_gdp_pref, mapping = aes(x = year, y = gdp_nominal_pchg)) + geom_line() + geom_point() + facet_geo(facets = ~ pref_name, # 変数pref_name別にグラフを作成 grid = &quot;jp_prefs_grid2&quot;, # 使用する地図グリッド scales = &quot;fixed&quot;) + # 目盛設定（fixed：全グラフ共通、free：全グラフ独立、free_x：X軸のみ独立、free_y：Y軸のみ独立） theme(strip.background = element_rect(color = NA, # ファセットタイトル領域の枠の色 fill = NA), # ファセットタイトル領域の塗りつぶしの色（NAで無色） strip.text = element_text(color = &quot;Black&quot;, # ファセットタイトルの色 face = &quot;bold&quot;, # ファセットタイトルの書体 size = 8, # ファセットタイトルのフォントサイズ hjust = 0.5, # ファセットタイトルの横方向の整列位置 vjust = 0.5), # ファセットタイトルの縦方向の整列位置 panel.spacing.x = unit(x = 1, units = &quot;mm&quot;), # ファセットのグラフ間の横方向のスペース panel.spacing.y = unit(x = 0.5, units = &quot;mm&quot;)) # ファセットのグラフ間の縦方向のスペース 5.24 その他設定・保存 タイトル、目盛線、凡例、図表全体のフォント、マージンなどの各種設定を行います。 タイトル・キャプション ggplot(data = mpg, mapping = aes(x = cty, y = hwy, fill = class)) + geom_point(shape = 21, size = 2.0) + labs(title = &quot;車体クラス別の一般道燃費と高速道燃費&quot;, # 図表タイトル caption = &quot;（出所）EPA.gov&quot;, # キャプション fill = &quot;車体クラス&quot;) + # 凡例に使用するscaleのタイトル theme(plot.title = element_text(size = 10, # 図表タイトルの文字サイズ face = &quot;bold&quot;, # 図表タイトルの書体 hjust = 0.5), # 図表タイトルの横整列位置 plot.caption = element_text(size = 8, # キャプションの文字サイズ face = &quot;plain&quot;, # キャプションの書体 hjust = 0.0)) # キャプションの横整列位置 パネル目盛線 ggplot(data = mpg, mapping = aes(x = cty, y = hwy, fill = class)) + geom_point(shape = 21, size = 2.0) + theme(panel.grid.major = element_line(color = &quot;grey&quot;, # 主目盛線の色 linetype = &quot;dashed&quot;, # 主目盛線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 0.2), # 主目盛線の太さ panel.grid.minor = element_blank()) # 補助目盛り線は表示しない 凡例 ggplot(data = mpg, mapping = aes(x = cty, y = hwy, fill = class)) + geom_point(shape = 21, size = 2.0) + theme(legend.title = element_text(size = 8, # 凡例タイトルの文字サイズ face = &quot;bold&quot;, # 凡例タイトルの書体 hjust = 0.0), # 凡例タイトルの横整列位置 legend.text = element_text(size = 6), # 凡例ラベルの文字サイズ legend.box.background = element_rect(color = &quot;grey&quot;, # 凡例の枠線の色 size = 0.5), # 凡例の枠線の太さ legend.margin = margin(t = 1, # 凡例の上マージン b = 1, # 凡例の下マージン r = 1, # 凡例の右マージン l = 1, # 凡例の左マージン unit = &quot;mm&quot;), # 凡例マージンの単位 legend.justification = c(1.0, 0.0), # 凡例の横整列位置・縦整列位置 legend.position = c(0.95, 0.05)) + # 凡例の横位置・縦位置 guides(fill = guide_legend(keywidth = unit(3, units = &quot;mm&quot;), # 凡例キーの幅 keyheight = unit(3, units = &quot;mm&quot;), # 凡例キーの高さ direction = &quot;vertical&quot;, # 凡例の整列方向（horizontal / vertical） nrow = 3, # 凡例の行数 ncol = 3, # 凡例の列数 reverse = FALSE)) # 凡例順序の逆転 フォント・マージン設定 ggplot(data = mpg, mapping = aes(x = cty, y = hwy, fill = class)) + geom_point(shape = 21, size = 2.0) + theme(text = element_text(family = &quot;YUGO&quot;, # 図表全体のフォント size = 8), # 図表全体の無事サイズ plot.margin = margin(t = 1, # 図表の上マージン b = 1, # 図表の下マージン r = 1, # 図表の右マージン l = 1, # 図表の左マージン unit = &quot;mm&quot;)) # 図表マージンの単位 保存 ggplot2パッケージで作成した図表を画像形式で保存するには、ggsave()関数を使用します。 ggsave(filename = &quot;directory/filename.png&quot;, # 図表のファイル名 width = 12.00, # 図表の横サイズ height = 9.00, # 図表の縦サイズ units = &quot;cm&quot;, # 図表のサイズ単位 dpi = 300) # 図表の解像度 5.25 実例 実例1：世界の新型コロナ死亡率の箱ひげ図 # プロット用のデータの作成 data_plot &lt;- data_owid %&gt;% dplyr::select(location, date, new_cases, new_deaths) %&gt;% dplyr::filter(date &lt;= max(date) - 28) %&gt;% dplyr::mutate(year = lubridate::year(date)) %&gt;% dplyr::group_by(location, year) %&gt;% dplyr::summarise(across(c(new_cases, new_deaths), mean, na.rm = TRUE)) %&gt;% dplyr::mutate(mort_rate = 100 * new_deaths / new_cases, year = str_c(year, &quot;年&quot;)) # プロット ggplot(data = data_plot, mapping = aes(x = year, y = mort_rate, color = year, fill = year)) + geom_hline(yintercept = 0, # 水平線の縦軸との交点 color = &quot;gray&quot;, # 水平線の色 size = 0.5) + # 水平線の太さ geom_boxplot(outlier.shape = NA, alpha = 0.25, size = 0.5) + geom_jitter(alpha = 0.5, size = 1.0, shape = 21) + scale_y_continuous(breaks = breaks_y &lt;- seq(0, 100, 0.5), # 目盛 labels = breaks_y %&gt;% sprintf(fmt = &quot;%0.1f&quot;), # 目盛ラベル limits = c(0, 5), # 下限・上限値（指定しない場合はNA） expand = expansion(mult = c(0.05, 0.05), add = c(0, 0))) + # 下限・上限値からの余白（multは余白率、addは余白幅） labs(x = element_blank(), # X軸のタイトル y = &quot;新型コロナ感染者の致死率（％）&quot;) + # Y軸のタイトル theme(axis.title = element_text(size = 8)) + # 軸タイトルの文字サイズ labs(title = &quot;世界各国の新型コロナ感染者の致死率（年別）&quot;, # 図表タイトル caption = &quot;（注）箱の中の横線は中央値を示す。2022年は直近4週間のサンプルを除外。\\n（出所）Our World in Data、@naohat23&quot;) + # キャプション theme(plot.title = element_text(size = 10, # 図表タイトルの文字サイズ face = &quot;bold&quot;, # 図表タイトルの書体 hjust = 0.5), # 図表タイトルの横整列位置 plot.caption = element_text(size = 8, # キャプションの文字サイズ face = &quot;plain&quot;, # キャプションの書体 hjust = 0.0)) + # キャプションの横整列位置 theme(panel.grid.major = element_line(color = &quot;grey&quot;, # 主目盛線の色 linetype = &quot;dashed&quot;, # 主目盛線の種類（solid / dashed / dotted / dotdash / twodash / longdash） size = 0.2), # 主目盛線の太さ panel.grid.minor = element_blank()) + # 補助目盛り線は表示しない theme(legend.position = &quot;none&quot;) + # 凡例の横位置・縦位置 theme(text = element_text(family = &quot;YUGO&quot;, # 図表全体のフォント size = 8), # 図表全体の無事サイズ plot.margin = margin(t = 1, # 図表の上マージン b = 1, # 図表の下マージン r = 1, # 図表の右マージン l = 1, # 図表の左マージン unit = &quot;mm&quot;)) # 図表マージンの単位 # 保存 ggsave(filename = &quot;directory/filename.png&quot;, # 図表のファイル名 width = 12.00, # 図表の横サイズ height = 9.00, # 図表の縦サイズ units = &quot;cm&quot;, # 図表のサイズ単位 dpi = 600) # 図表の解像度 "],["探索的データ分析.html", "6 探索的データ分析 6.1 第6章の準備 6.2 データの中身（記述統計量） 6.3 データの分布 6.4 データの関係性 6.5 相関関係・ペアプロット 6.6 探索的データ分析の一括実行", " 6 探索的データ分析 第6章「探索的データ分析（Exploratory Data Analysis）」では、データの内容を理解するための方法を解説します。これは、本格的な統計モデルを構築する方針を立てるための重要なプロセスです。 Wickham &amp; Grolemund（2017）は、探索的データ分析について次のように説明しています。 分析対象のデータについて問いを立てる。 可視化、変換、モデル化により、問いに対する解を探る。 得られた解をもとに、新たな問いを立てる。 このサイクルを繰り返す。 このように、探索的データ分析には本来決まったやり方が存在するわけではありません。とはいえ、「問いの立て方」や「解の探り方」には一般的によく利用される手法があるため、この章ではそうした手法について解説します。 6.1 第6章の準備 パッケージのインポート library(corrplot) library(corrr) library(DataExplorer) library(GGally) library(magrittr) library(SmartEDA) library(tidyverse) library(psych) ggplot2の設定 ## ggplotのテーマ設定（Excelのグラフと類似したテーマを選択） theme_set(theme_light()) ## Windowsにおけるggplot2の日本語フォント設定 windowsFonts(&quot;MEIRYO&quot; = windowsFont(&quot;Meiryo UI&quot;)) windowsFonts(&quot;YUGO&quot; = windowsFont(&quot;Yu Gothic UI&quot;)) 6.2 データの中身（記述統計量） まず、データが何を含んでいるか確認します。 summary()関数は、各変数の記述統計量を出力する関数です。数値型の変数は、平均、中央値、最大値、最小値、四分位数が、文字列等のカテゴリカル変数は、要素毎のサンプル数が出力されます。 psych::describe()関数は、各変数の記述統計量や分布に関する情報を出力する関数です。平均、中央値、標準偏差に加え、刈り込み平均（trimmed）、中央絶対偏差（mad）、レンジ（最大値と最小値の差）、歪度（skew）、尖度（kurtosis）、標準誤差（se）が出力されます。 # データをコンソールに出力 diamonds ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4 4.05 2.39 ## # ... with 53,930 more rows # データの変数名を出力 colnames(diamonds) ## [1] &quot;carat&quot; &quot;cut&quot; &quot;color&quot; &quot;clarity&quot; &quot;depth&quot; &quot;table&quot; &quot;price&quot; ## [8] &quot;x&quot; &quot;y&quot; &quot;z&quot; # データの記述統計量を出力 summary(diamonds) ## carat cut color clarity depth ## Min. :0.2000 Fair : 1610 D: 6775 SI1 :13065 Min. :43.00 ## 1st Qu.:0.4000 Good : 4906 E: 9797 VS2 :12258 1st Qu.:61.00 ## Median :0.7000 Very Good:12082 F: 9542 SI2 : 9194 Median :61.80 ## Mean :0.7979 Premium :13791 G:11292 VS1 : 8171 Mean :61.75 ## 3rd Qu.:1.0400 Ideal :21551 H: 8304 VVS2 : 5066 3rd Qu.:62.50 ## Max. :5.0100 I: 5422 VVS1 : 3655 Max. :79.00 ## J: 2808 (Other): 2531 ## table price x y ## Min. :43.00 Min. : 326 Min. : 0.000 Min. : 0.000 ## 1st Qu.:56.00 1st Qu.: 950 1st Qu.: 4.710 1st Qu.: 4.720 ## Median :57.00 Median : 2401 Median : 5.700 Median : 5.710 ## Mean :57.46 Mean : 3933 Mean : 5.731 Mean : 5.735 ## 3rd Qu.:59.00 3rd Qu.: 5324 3rd Qu.: 6.540 3rd Qu.: 6.540 ## Max. :95.00 Max. :18823 Max. :10.740 Max. :58.900 ## ## z ## Min. : 0.000 ## 1st Qu.: 2.910 ## Median : 3.530 ## Mean : 3.539 ## 3rd Qu.: 4.040 ## Max. :31.800 ## # データの記述統計量や分布に関する情報を出力 psych::describe(diamonds) ## vars n mean sd median trimmed mad min max ## carat 1 53940 0.80 0.47 0.70 0.73 0.47 0.2 5.01 ## cut* 2 53940 3.90 1.12 4.00 4.04 1.48 1.0 5.00 ## color* 3 53940 3.59 1.70 4.00 3.55 1.48 1.0 7.00 ## clarity* 4 53940 4.05 1.65 4.00 3.91 1.48 1.0 8.00 ## depth 5 53940 61.75 1.43 61.80 61.78 1.04 43.0 79.00 ## table 6 53940 57.46 2.23 57.00 57.32 1.48 43.0 95.00 ## price 7 53940 3932.80 3989.44 2401.00 3158.99 2475.94 326.0 18823.00 ## x 8 53940 5.73 1.12 5.70 5.66 1.38 0.0 10.74 ## y 9 53940 5.73 1.14 5.71 5.66 1.36 0.0 58.90 ## z 10 53940 3.54 0.71 3.53 3.49 0.85 0.0 31.80 ## range skew kurtosis se ## carat 4.81 1.12 1.26 0.00 ## cut* 4.00 -0.72 -0.40 0.00 ## color* 6.00 0.19 -0.87 0.01 ## clarity* 7.00 0.55 -0.39 0.01 ## depth 36.00 -0.08 5.74 0.01 ## table 52.00 0.80 2.80 0.01 ## price 18497.00 1.62 2.18 17.18 ## x 10.74 0.38 -0.62 0.00 ## y 58.90 2.43 91.20 0.00 ## z 31.80 1.52 47.08 0.00 6.3 データの分布 次に、データに含まれる変数がどのように分布しているかを、第5章で解説したggplot2パッケージの関数を使用して可視化します。 離散型変数の度数分布 離散型変数の度数分布を出力するにはdplyr::count()関数を使用します。 diamonds %&gt;% dplyr::count(cut) ## # A tibble: 5 x 2 ## cut n ## &lt;ord&gt; &lt;int&gt; ## 1 Fair 1610 ## 2 Good 4906 ## 3 Very Good 12082 ## 4 Premium 13791 ## 5 Ideal 21551 離散型変数の度数分布を可視化するには、度数棒グラフを使用します。 diamonds %&gt;% ggplot(mapping = aes(x = cut)) + geom_bar() 連続型変数の度数分布 連続型変数の度数分布を出力するには、dplyr::count()関数とggplot2::cut_width()関数を使用します。 diamonds %&gt;% dplyr::count(ggplot2::cut_width(carat, 0.5)) ## # A tibble: 11 x 2 ## `ggplot2::cut_width(carat, 0.5)` n ## &lt;fct&gt; &lt;int&gt; ## 1 [-0.25,0.25] 785 ## 2 (0.25,0.75] 29498 ## 3 (0.75,1.25] 15977 ## 4 (1.25,1.75] 5313 ## 5 (1.75,2.25] 2002 ## 6 (2.25,2.75] 322 ## 7 (2.75,3.25] 32 ## 8 (3.25,3.75] 5 ## 9 (3.75,4.25] 4 ## 10 (4.25,4.75] 1 ## 11 (4.75,5.25] 1 連続型変数の度数分布を可視化するには、ヒストグラムを使用します。 diamonds %&gt;% ggplot(mapping = aes(x = carat)) + geom_histogram(binwidth = 0.5) 連続型変数の度数分布をグループ別に可視化するには、geom_freqpoly()関数を使用します。 diamonds %&gt;% ggplot(mapping = aes(x = carat, color = cut)) + geom_freqpoly(binwidth = 0.1) 連続型変数の度数を標準化して密度をグループ別に可視化するには、mapping = aes(y = ..density..)を指定して、geom_fredpoly()関数を使用します。 diamonds %&gt;% ggplot(mapping = aes(x = price, y = ..density.., color = cut)) + geom_freqpoly(binwidth = 500) 外れ値 外れ値や異常値をグラフで確認するには、ヒストグラムを使用し、coord_cartesian()関数のylim引数にY軸の下限・上限値を指定して、Y軸方向に図表を拡大します。 なお、scale_y_continuous()関数のlimits引数に下限・上限を指定する方法でもY軸の表示範囲を変えることができますが、下限・上限の範囲外にあるデータが表示されなくなるため、単に拡大するだけであればcoord_cartesian()関数を用いるほうが良いでしょう。 diamonds %&gt;% ggplot(mapping = aes(x = y)) + geom_histogram() + coord_cartesian(ylim = c(0, 50)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. グループ別に外れ値を可視化する場合は、箱ひげ図を使用します。 diamonds %&gt;% ggplot(mapping = aes(x = cut, y = carat)) + geom_boxplot() 6.4 データの関係性 データに含まれる変数が互いにどのような関係にあるかを、ggplot2パッケージの関数を使用して可視化します。 離散型変数の関係性 離散型変数の観測値の組み合わせの分布を可視化するには、geom_count()関数の度数バブルチャートや、geom_tile()関数のヒートマップを使用します。 diamonds %&gt;% ggplot(mapping = aes(x = cut, y = color)) + geom_count() diamonds %&gt;% dplyr::count(cut, color) %&gt;% ggplot(mapping = aes(x = cut, y = color, fill = n)) + geom_tile() 連続型変数の関係性 連続型変数の観測値の組み合わせの分布を可視化するには、geom_point()関数の散布図や、geom_bin2d()関数、geom_hex()関数のヒートマップを使用します。 データサイズが大きい場合は、geom_point()関数の実行に時間がかかるため、geom_bin2d()関数やgeom_hex()関数を用いるのが効果的です。 diamonds %&gt;% ggplot(mapping = aes(x = carat, y = price)) + geom_point(alpha = 0.05) diamonds %&gt;% ggplot(mapping = aes(x = carat, y = price)) + geom_bin2d(bins = 100) # X軸・Y軸の階級数（デフォルトは30） diamonds %&gt;% ggplot(mapping = aes(x = carat, y = price)) + geom_hex(bins = 50) # X軸・Y軸の階級数（デフォルトは30） 6.5 相関関係・ペアプロット 相関係数行列 cor()関数で相関係数行列を出力します。ここではサンプルデータセットとしてmtcarsデータセットを使用しています。 cor(mtcars) ## mpg cyl disp hp drat wt ## mpg 1.0000000 -0.8521620 -0.8475514 -0.7761684 0.68117191 -0.8676594 ## cyl -0.8521620 1.0000000 0.9020329 0.8324475 -0.69993811 0.7824958 ## disp -0.8475514 0.9020329 1.0000000 0.7909486 -0.71021393 0.8879799 ## hp -0.7761684 0.8324475 0.7909486 1.0000000 -0.44875912 0.6587479 ## drat 0.6811719 -0.6999381 -0.7102139 -0.4487591 1.00000000 -0.7124406 ## wt -0.8676594 0.7824958 0.8879799 0.6587479 -0.71244065 1.0000000 ## qsec 0.4186840 -0.5912421 -0.4336979 -0.7082234 0.09120476 -0.1747159 ## vs 0.6640389 -0.8108118 -0.7104159 -0.7230967 0.44027846 -0.5549157 ## am 0.5998324 -0.5226070 -0.5912270 -0.2432043 0.71271113 -0.6924953 ## gear 0.4802848 -0.4926866 -0.5555692 -0.1257043 0.69961013 -0.5832870 ## carb -0.5509251 0.5269883 0.3949769 0.7498125 -0.09078980 0.4276059 ## qsec vs am gear carb ## mpg 0.41868403 0.6640389 0.59983243 0.4802848 -0.55092507 ## cyl -0.59124207 -0.8108118 -0.52260705 -0.4926866 0.52698829 ## disp -0.43369788 -0.7104159 -0.59122704 -0.5555692 0.39497686 ## hp -0.70822339 -0.7230967 -0.24320426 -0.1257043 0.74981247 ## drat 0.09120476 0.4402785 0.71271113 0.6996101 -0.09078980 ## wt -0.17471588 -0.5549157 -0.69249526 -0.5832870 0.42760594 ## qsec 1.00000000 0.7445354 -0.22986086 -0.2126822 -0.65624923 ## vs 0.74453544 1.0000000 0.16834512 0.2060233 -0.56960714 ## am -0.22986086 0.1683451 1.00000000 0.7940588 0.05753435 ## gear -0.21268223 0.2060233 0.79405876 1.0000000 0.27407284 ## carb -0.65624923 -0.5696071 0.05753435 0.2740728 1.00000000 corrplotパッケージ R標準のcor()関数の出力結果では見にくいため、corrplotパッケージを使用して相関係数行列を可視化します。 # cor()関数で相関係数行列を計算し、その結果をcorrplot::corrplot()関数に渡す mtcars %&gt;% cor() %&gt;% corrplot::corrplot(method = &quot;square&quot;, # 可視化方法（&quot;circle&quot;, &quot;square&quot;, &quot;ellipse&quot;, &quot;number&quot;, &quot;shade&quot;, &quot;color&quot;, &quot;pie&quot;） type = &quot;full&quot;, # 表示形式（&quot;full&quot;, &quot;upper&quot;, &quot;lower&quot;） addCoef.col = &quot;black&quot;, # 相関係数の値の色 diag = FALSE, # 対角要素を表示するか number.cex = 0.8, # 相関係数の値のフォントサイズ number.digits = 2) # 相関係数の値の小数点以下桁数 corrplot::cor.mtest()関数を使用すると、「相関係数が0である」との帰無仮説に対するp値を計算し、その結果を可視化することができます。 # 相関係数の検定を行いp値を計算 mtcars_p &lt;- corrplot::cor.mtest(mtcars) # p値の計算結果を指定して検定結果を可視化 mtcars %&gt;% cor() %&gt;% corrplot::corrplot(method = &quot;square&quot;, # 可視化方法（&quot;circle&quot;, &quot;square&quot;, &quot;ellipse&quot;, &quot;number&quot;, &quot;shade&quot;, &quot;color&quot;, &quot;pie&quot;） type = &quot;full&quot;, # 表示形式（&quot;full&quot;, &quot;upper&quot;, &quot;lower&quot;） p.mat = mtcars_p$p, # p値の計算結果 sig.level = 0.05, # 有意水準 addCoef.col = &quot;black&quot;, # 相関係数の値の色 diag = FALSE, # 対角要素を表示するか number.cex = 0.8, # 相関係数の値のフォントサイズ number.digits = 2) # 相関係数の値の小数点以下桁数 corrrパッケージ 次に、corrrパッケージを使用して相関係数を可視化します。 corrr::correlate()関数で相関係数行列を格納したcor_dfオブジェクトを作成します。 mtcars_cor &lt;- corrr::correlate(mtcars, method = &quot;pearson&quot;) # 相関係数の算出法（&quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot;） ## ## Correlation method: &#39;pearson&#39; ## Missing treated using: &#39;pairwise.complete.obs&#39; mtcars_cor ## # A tibble: 11 x 12 ## term mpg cyl disp hp drat wt qsec vs am ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 mpg NA -0.852 -0.848 -0.776 0.681 -0.868 0.419 0.664 0.600 ## 2 cyl -0.852 NA 0.902 0.832 -0.700 0.782 -0.591 -0.811 -0.523 ## 3 disp -0.848 0.902 NA 0.791 -0.710 0.888 -0.434 -0.710 -0.591 ## 4 hp -0.776 0.832 0.791 NA -0.449 0.659 -0.708 -0.723 -0.243 ## 5 drat 0.681 -0.700 -0.710 -0.449 NA -0.712 0.0912 0.440 0.713 ## 6 wt -0.868 0.782 0.888 0.659 -0.712 NA -0.175 -0.555 -0.692 ## 7 qsec 0.419 -0.591 -0.434 -0.708 0.0912 -0.175 NA 0.745 -0.230 ## 8 vs 0.664 -0.811 -0.710 -0.723 0.440 -0.555 0.745 NA 0.168 ## 9 am 0.600 -0.523 -0.591 -0.243 0.713 -0.692 -0.230 0.168 NA ## 10 gear 0.480 -0.493 -0.556 -0.126 0.700 -0.583 -0.213 0.206 0.794 ## 11 carb -0.551 0.527 0.395 0.750 -0.0908 0.428 -0.656 -0.570 0.0575 ## # ... with 2 more variables: gear &lt;dbl&gt;, carb &lt;dbl&gt; corrr::rearrange()関数を使用すると、高い相関を持つ変数を近くに配置するよう、変数の順序を自動で変更します。 mtcars_cor %&gt;% corrr::rearrange() ## Registered S3 methods overwritten by &#39;registry&#39;: ## method from ## print.registry_field proxy ## print.registry_entry proxy ## # A tibble: 11 x 12 ## term mpg vs drat am gear qsec carb hp wt ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 mpg NA 0.664 0.681 0.600 0.480 0.419 -0.551 -0.776 -0.868 ## 2 vs 0.664 NA 0.440 0.168 0.206 0.745 -0.570 -0.723 -0.555 ## 3 drat 0.681 0.440 NA 0.713 0.700 0.0912 -0.0908 -0.449 -0.712 ## 4 am 0.600 0.168 0.713 NA 0.794 -0.230 0.0575 -0.243 -0.692 ## 5 gear 0.480 0.206 0.700 0.794 NA -0.213 0.274 -0.126 -0.583 ## 6 qsec 0.419 0.745 0.0912 -0.230 -0.213 NA -0.656 -0.708 -0.175 ## 7 carb -0.551 -0.570 -0.0908 0.0575 0.274 -0.656 NA 0.750 0.428 ## 8 hp -0.776 -0.723 -0.449 -0.243 -0.126 -0.708 0.750 NA 0.659 ## 9 wt -0.868 -0.555 -0.712 -0.692 -0.583 -0.175 0.428 0.659 NA ## 10 disp -0.848 -0.710 -0.710 -0.591 -0.556 -0.434 0.395 0.791 0.888 ## 11 cyl -0.852 -0.811 -0.700 -0.523 -0.493 -0.591 0.527 0.832 0.782 ## # ... with 2 more variables: disp &lt;dbl&gt;, cyl &lt;dbl&gt; corrr::rplot()関数を使用して、相関係数行列を散布図で可視化します。corrr::shave()関数は、相関係数行列の左下半分のみを抽出する関数です。 mtcars_cor %&gt;% corrr::rearrange() %&gt;% corrr::shave() %&gt;% corrr::rplot(print_cor = TRUE) # 散布図上に相関係数の値を表示する ## Don&#39;t know how to automatically pick scale for object of type noquote. Defaulting to continuous. ## Don&#39;t know how to automatically pick scale for object of type noquote. Defaulting to continuous. corrr::network_plot()関数を使用すると、変数の相関関係をネットワーク図で可視化することができます。ネットワーク図では相関が強い変数が近くに配置されます。 mtcars_cor %&gt;% corrr::network_plot(min_cor = 0.6) # 表示する最小の相関係数の値 GGallyパッケージ GGallyパッケージのGGally::ggpairs()関数を使用すると、変数のペアプロット（pairwise plot）を簡単に出力することができます。なお、GGallyパッケージにはペアプロット以外にも様々な機能があります。詳細は公式ウェブサイトを参照してください。 mtcars %&gt;% dplyr::select(mpg, cyl, disp, hp, gear) %&gt;% GGally::ggpairs(progress = FALSE) # コンソールにプログラスバーを表示するか また、mapping = aes()内の引数にグループ化する変数を指定することで、グループ別のペアプロットを出力できます。ここではサンプルデータセットとしてirisデータセットを用いています。 iris %&gt;% GGally::ggpairs(mapping = aes(color = Species, alpha = 0.5), progress = FALSE) # コンソールにプログラスバーを表示するか ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 6.6 探索的データ分析の一括実行 これまで一つずつ実施してきた探索的データ分析を一括して実行するパッケージを紹介します。 DataExplorerパッケージ DataExplorerパッケージのcreate_report()関数を使用すると、データセットに含まれる変数、データ構造、欠損値、ヒストグラム、QQプロット、相関係数行列、主成分分析（PCA）などを自動で作成して、HTML形式のレポートをブラウザに出力します。ウェブサイト上では実行できないため、各自で試してみてください。 # irisデータセットに対し被説明変数を指定せずに探索的データ分析を実施 DataExplorer::create_report(data = iris) # diamondsデータセットに対し被説明変数をpriceに指定して探索的データ分析を実施 DataExplorer::create_report(data = diamonds, y = &quot;price&quot;) SmartEDAパッケージ SmartEDAパッケージのExpReport()関数を使用すると、データセットに含まれる変数、ヒストグラム、QQプロット、相関係数行列などを自動で作成して、HTML形式のレポートファイルを作成します。ウェブサイト上では実行できないため、各自で試してみてください。 なお、データセットのサイズが大きい場合は処理に時間がかかるため、注意が必要です。 # irisデータセットに対し被説明変数を指定せずに探索的データ分析を実施 SmartEDA::ExpReport(data = iris, op_file = &quot;report.html&quot;) # diamondsデータセットに対し被説明変数をpriceに指定して探索的データ分析を実施 SmartEDA::ExpReport(data = diamonds, Target = &quot;price&quot;, op_file = &quot;report.html&quot;) また、SmartEDA::ExpCatStat()では、Target引数で指定した被説明変数に対する各変数の予測力を計算することができます。 # mtcarsデータセットに対し被説明変数をamに指定して各変数の予測力を計算 SmartEDA::ExpCatStat(data = mtcars, Target = &quot;am&quot;, plot = TRUE) ## Variable Target Unique Chi-squared p-value df IV Value Cramers V ## 1 cyl am 3 8.741 0.013 2 1.32 0.52 ## 2 vs am 2 0.348 0.556 1 0.11 0.10 ## 3 gear am 3 20.945 0.000 2 0.44 0.81 ## 4 carb am 6 6.237 0.284 5 0.17 0.44 ## 5 mpg am 10 20.945 0.013 9 0.14 0.81 ## 6 disp am 10 21.636 0.010 9 0.35 0.82 ## 7 hp am 10 17.490 0.042 9 0.47 0.74 ## 8 drat am 10 21.497 0.011 9 0.12 0.82 ## 9 wt am 10 20.254 0.016 9 0.46 0.80 ## 10 qsec am 10 11.824 0.223 9 0.54 0.61 ## Degree of Association Predictive Power ## 1 Strong Highly Predictive ## 2 Weak Somewhat Predictive ## 3 Strong Highly Predictive ## 4 Strong Somewhat Predictive ## 5 Strong Somewhat Predictive ## 6 Strong Highly Predictive ## 7 Strong Highly Predictive ## 8 Strong Somewhat Predictive ## 9 Strong Highly Predictive ## 10 Strong Highly Predictive "],["線形回帰.html", "7 線形回帰 7.1 第7章の準備 7.2 用語の説明 7.3 最小2乗法（OLS） 7.4 モデルの種類と係数の解釈 7.5 重回帰モデルの注意点 7.6 Rの単回帰モデル推定 7.7 Rの重回帰モデル推定", " 7 線形回帰 第7章「線形回帰」では、計量経済学の基本である線形回帰モデルについて解説します。この章の説明は、山本（2015）、西山 他（2019）、末石（2015）をもとにしています。詳細は各参考文献を参照してください。また、実証例のRコードは北川（2020）のウェブサイトを参考にしています。 7.1 第7章の準備 パッケージのインポート library(estimatr) library(GGally) library(magrittr) library(tidyquant) library(tidyverse) 外部データセットの取得 この章では、西山 他（2019）の実証例のデータセットを使用します。西山 他（2019）のサポートウェブサイトからデータファイルを取得し、各自の実行環境のワーキングディレクトリ直下にdata_nishiyamaフォルダを作成して、その中に格納してください。 7.2 用語の説明 まず、統計学・計量経済学で使用される基本的な用語を説明します。 標本と推定 母集団： 調べる対象全体（population） 標本： 母集団から取り出した対象の一部（sample） 推定： 標本を使って母集団の分布に関する未知の値を言い当てること（estimation） 未知パラメータ： 推定すべき未知の値。一般的に\\(\\theta\\)で表す（unknown parameter） 統計量： 未知の値に依存せず、標本があれば値が計算できるデータの関数（statistic） 推定量： 推定に用いる統計量（estimator） 推定値： 未知の値について、実際にデータから計算して得た値（estimate） 点推定： 未知パラメータの値を1点で言い当てること（point estimation） 区間推定： 統計誤差を考慮して未知パラメータの値を区間で言い当てること（interval estimation） 統計誤差： 母集団全体でなく標本を用いることで推定結果に生じる誤差（statistical error） 推定量の望ましい性質 不偏性： 推定量の期待値が推定対象の未知パラメータの真の値に等しいこと（unbiasedness） 一致制： サンプルサイズが大きくなると、推定量が未知パラメータの真の値となる確率が1に近づくこと（consistency） 漸近正規性： サンプルサイズが大きいとき、そのサンプルから構成される確率変数が近似的に正規分布に従うこと（asymptomatic normality） 効率性： 推定量の分散が小さく、未知パラメータの真の値に近い値をとりやすいこと（efficiency） 頑健性： 異常値があっても推定量が影響を受けにくいこと（robustness） 7.3 最小2乗法（OLS） 次に、線形回帰の推定方法である最小2乗法と、統計的仮説検定について解説します。 変数\\(X\\)を用いて変数\\(Y\\)を推定する、次のようなモデルを考えます。 \\[ Y_i = \\beta_0 + \\beta_1X_i + u_i \\quad (i = 1,\\, \\ldots,\\, n) \\] ここで、\\(Y_i\\)は被説明変数（dependent variable）、\\(X_i\\)は説明変数（independent variable）、\\(u_i\\)は誤差項（error term）と呼ばれます。誤差項は\\(X_i\\)以外で\\(Y_i\\)に影響を与える要因をひとまとめにしたものと解釈できます。 最小2乗法の仮定 次の3つの仮定が成立するとき、OLS推定量は推定の望ましい性質である「不偏性」、「一致性」、「漸近正規性」を満たします。 仮定1：データが無作為抽出 標本が同一の母集団から無作為抽出（ランダムサンプリング）されているという仮定であり、数学的には、\\(Y_i\\)と\\(X_i\\)が独立かつ同一の分布に従う（independently and identically distributed、i.i.d）と定義されます。 多くのクロスセクションデータでは仮定1が成立しますが、時系列データや、時系列の要素を含むパネルデータでは仮定1が成立しないと考えるのが自然です。家計の消費支出の慣性効果など、経済主体の行動は過去からの影響を受けやすく、過去と現在のデータに相関があることが多いためです。 仮定1が成立しない場合、誤差項に自己相関が発生します。 仮定2：異常値が少ない 標本に含まれる異常値（データの絶対値が平均から大幅に離れている値）が少ないという仮定であり、数学的には変数の4次のモーメントが有限（\\(0 &lt; E(X_i^4) &lt; \\infty, \\quad 0 &lt; E(Y_i^4) &lt; \\infty\\)）と定義されます。すなわち、データの分布の裾が厚くない（ファット・テールでない）ということです。 一部の金融データなどでは異常値を取ることが多く（分布の裾が厚く）、仮定2が満たされない可能性があります。 仮定2が成立しない場合、OLS推定量が漸近正規性を満たさなくなります。漸近正規性は、直接的に推定量の良し悪しに関わる性質ではありませんが、係数に関する仮説検定や区間推定を行う基礎になる重要な性質です。 仮定3：説明変数と誤差項が無相関 外生性と呼ばれる仮定であり、\\(Y_i\\)の変動要因のうち\\(X_i\\)以外の部分（すなわち誤差項\\(u_i\\)）が平均的には\\(X_i\\)と無関係であることを意味します。数学的には、誤差項の条件付き期待値が説明変数に依存しない（\\(E(u_i|X_i) = 0\\)）と定義されます。 仮定3が成立していれば、モデルが因果関係を表していると解釈できます（ただし、仮定3が成立しているかどうかを回帰分析の結果から判断することはできません）。 仮定3が成立しないケースは多く、例えば、説明変数に本来含まれるべき変数が欠落している欠落変数バイアス、被説明変数が説明変数の変動要因になっている内生性バイアス（逆の因果性）などがあります。 仮定3は非常に重要です。仮定3が成立しない場合、OLS推定量は不偏性と一致性を満たさず、未知パラメータの値をきちんと推定することができない深刻な問題が発生します。対処方法として、他の説明変数の追加（重回帰モデル）による欠落変数バイアスの解消、パネルデータを用いた固定効果モデルの推定、2段階最小2乗法や操作変数法による内生性バイアスの解消を検討する必要があります。 均一分散の仮定 被説明変数\\(Y_i\\)のデータの散らばり具合が説明変数\\(X_i\\)の値によらず一定であるとき、誤差項\\(u_i\\)の分散が一定、すなわち均一分散（homoskedasticity）であるといいます（\\(Var(u|X) = E(u^2|X) = \\sigma^2\\)）。 仮定1～3に加えて、均一分散の仮定が成立している場合、OLS推定量は線形な不偏推定量の中で「効率性」が最も高くなります（ガウス＝マルコフの定理）。これは、推定量の分散が最も小さく、推定量が真の値に近い値を取りやすいことを意味します。この時の推定量を、最良線形不偏推定量（best linear unbiased estimator, BLUE）と呼びます。 しかし、経済データ（特にクロスセクションデータ）で均一分散の仮定が成立することは少なく、誤差項\\(u_i\\)の分散が説明変数\\(X_i\\)に依存する不均一分散（heteroskedasticity）の方がむしろ一般的と考えられます。例えば、複数の家計の所得・消費データから消費関数を推定する際、所得水準が高いほど消費スタイルの違いによる消費額のばらつきが大きいことが想定されますが、その場合は均一分散の仮定が成立しません。 均一分散の仮定が成立しない（不均一分散が生じている）場合は、推定量の効率性が悪化し、ばらつきが大きくなってしまう問題があります。そのような場合に、均一分散を仮定して標準誤差（推定量の標準偏差を推定した値）を計算すると分散の大きさを過小評価してしまうため、不均一分散の可能性を考慮した不均一分散に頑健な標準誤差（ホワイトの標準誤差）を用いる必要があります。 検定と信頼区間 帰無仮説と対立仮説 モデル\\(Y_i = \\beta_0 + \\beta_1 X_i + u_i\\)について、次のような帰無仮説\\(H_0\\)（null hypothesis）と対立仮説\\(H_1\\)（alternative hypothesis）を考えます。 \\[ H_0 : \\beta_1 = 0 \\\\ H_1 : \\beta_1 \\neq 0 \\] 推定にあたり、我々が本当に興味があるのは未知パラメータ\\(\\beta_1\\)の真の値であり、またそれを言い当てるための推定値と標準誤差であるわけですが、ここでは「少なくとも未知パラメータの真の値がゼロではない（有意である）」ことを統計的に確認するために、こうした検定を行います。 t値 検定にはt統計量（t値）を用います。t統計量は、未知パラメータの推定量と帰無仮説の設定値の差を、標準誤差（推定量の標準偏差を推定した値）で割ったものです。 \\[ t = \\frac{推定量 - 帰無仮説の設定値（ここではゼロ）}{標準誤差} \\] t値が大きいほど、推定値に対して相対的に標準誤差が小さいことを意味します。目安として、t値が1.9や1.6など絶対値で2に近い値より大きければ、推定値の標準誤差は未知パラメータの符号条件を変えるほど大きくなく、未知パラメータの真の値がゼロである可能性は低い（推定値が統計的に有意である）と判断できます。 p値 このt値を確率に置き換えたものがp値です。p値は「帰無仮説が正しいとしたときの確率分布のもとで、t値が観測したデータ（標本）から計算した値より極端な値をとる確率」を示したもので、t値が大きくなるほどp値は小さくなります。 p値は、直感的にいうと「未知パラメータの推定値がゼロになる確率」であり、p値がある一定の水準より小さければ、観測したデータは帰無仮説下では起こりにくいと判断し、帰無仮説\\(H_0\\)を棄却して対立仮説\\(H_1\\)を採択します。その際の「一定の水準」を有意水準と言い、一般的に5％や1％といった水準が用いられます。 ここで注意が必要なのは、計算したp値が有意水準より大きく（例えば15％など）、帰無仮説を棄却できなかった場合に、帰無仮説が正しい（未知パラメータの真の値がゼロ）と結論付けられるわけではないということです（McAlinn（2022）P.50）。この場合は、「未知パラメータの推定値が統計的に有意であることが確認できず、判断を留保する」と結論することになります。 信頼区間 信頼区間（confidence interval、CI）は、推定結果の精度を幅で示すものです。具体的には、未知パラメータの推定値と標準誤差を用い、ある一定の確率の下で未知パラメータの真の値を含む区間を計算します。その際の「一定の確率」を信頼係数といい、要求される推定の精度に応じ、一般的に95％や99％といった水準が用いられます。 信頼区間の解釈には注意が必要です。例えば、標本から未知パラメータの95％信頼区間が10～20と計算されたとき、これは「パラメータの真の値が95％の確率で10～20の間にある」ことを意味するものではありません。パラメータの真の値は定数であり、動かないのに対し、信頼区間は標本から計算した実現値のうちの一つであり、標本の選び方によりランダムに変わるためです。95％信頼区間の意味は、「同一の母集団から独立な標本が100回得られて、信頼区間を100回計算することができれば、そのうち95回はパラメータの真の値を含む」ということです（末石（2015）P.11）。 7.4 モデルの種類と係数の解釈 ここでは線形回帰モデルの具体的な推定式として、実務で頻繁に用いる水準モデル、対数モデル、変化率モデル、多項式モデル、交互作用モデル、ダミー変数モデルを取り上げ、それぞれの内容と係数の解釈方法を説明します。 水準モデル \\[ Y = \\beta_0 + \\beta_1 X + u \\] 被説明変数\\(Y\\)、説明変数\\(X\\)ともにレベルの場合、係数\\(\\beta_1\\)は、説明変数\\(X\\)が1単位変化すると被説明変数\\(Y\\)が\\(\\beta_1\\)単位変化することを示します。 例えば、\\(Y\\)が実質賃金（円）、\\(X\\)が労働生産性（円）のとき、労働生産性が1円上昇すると実質賃金は\\(\\beta_1\\)円上昇します。 対数モデル 両辺が自然対数の場合 \\[ \\ln Y = \\beta_0 + \\beta_1 \\ln X + u \\] 被説明変数\\(\\ln Y\\)、説明変数\\(\\ln X\\)ともに自然対数の場合、係数\\(\\beta_1\\)は、説明変数\\(X\\)が1％変化したときに被説明変数\\(Y\\)が\\(\\beta_1\\)％変化することを示します。このとき、\\(\\beta_1\\)を弾性値（弾力性）と呼びます。 このように解釈できる理由は、次の通りです。変数\\(X\\)がある小さい量\\(\\Delta x\\)だけ変化したときの\\(\\ln X\\)の変化量を\\(\\Delta \\ln X\\)とすると、対数関数の性質を用いて、 \\[ \\Delta \\ln X = \\ln (X + \\Delta x) - \\ln X = \\ln (1 + \\frac{\\Delta x}{X}) \\approx \\frac{\\Delta x}{X} \\] となります。\\(\\Delta x / X\\)は\\(X\\)の変化率なので、この式から、\\(X\\)が1％変化することと\\(\\ln X\\)が0.01変化することはほぼ同じであることがわかります。すると、「\\(X\\)が1％変化する」＝「\\(\\ln X\\)が\\(0.01\\)変化する」＝「\\(\\ln Y\\)が\\(0.01 \\times \\beta_1\\)変化する」＝「\\(Y\\)が\\(\\beta_1\\)％変化する」となります（西山 他（2019）P.107）。 どちらか一方の辺が自然対数の場合 \\[ \\ln Y = \\beta_0 + \\beta_1 X + u \\\\ Y = \\beta_0 + \\beta_1 \\ln X + u \\] 被説明変数\\(\\ln Y\\)が自然対数、説明変数\\(X\\)がレベルのとき、係数\\(\\beta_1\\)は、説明変数\\(X\\)が1単位変化したときに被説明変数\\(Y\\)が\\(\\beta_1\\)％変化することを示します。このとき、\\(\\beta_1\\)を偏弾性値と呼びます。 逆に、被説明変数\\(Y\\)がレベル、説明変数\\(\\ln X\\)が自然対数の場合、係数\\(\\beta_1\\)は、説明変数\\(X\\)が1％変化したときに被説明変数\\(Y\\)が\\(\\beta_1/100\\)単位変化することを示します。 変化率モデル \\[ 100 \\times \\frac{\\Delta Y_t}{Y_{t-1}} = \\beta_0 + \\beta_1 \\times 100 \\times \\frac{\\Delta X_t}{X_{t-1}} + u \\\\ 100 \\times \\Delta \\ln Y_t = \\beta_0 + \\beta_1 \\times 100 \\times \\Delta \\ln X_t + u \\] 時系列データについて、ある変数\\(X_t\\)と、その1期ラグ付き変数\\(X_{t-1}\\)の差\\(X_t - X_{t-1}\\)を階差と呼び、\\(\\Delta X_t = X_t - X_{t-1}\\)と表します。階差\\(\\Delta X_t\\)を1期ラグ付き変数\\(X_{t-1}\\)で割り、100を掛けてパーセント表示にした系列\\(100 \\times \\Delta X_t / X_{t-1}\\)を変化率と呼びます。 また、上記の対数モデルで見た\\(\\Delta \\ln X \\approx \\Delta X / X\\)を用いると、時系列データの変数\\(X_t\\)について自然対数の階差をとった\\(\\Delta \\ln X_t = \\ln X_t - \\ln X_{t-1}\\)に100を掛けた系列は、変化率\\(100 \\times \\Delta X_t / X_{t-1}\\)に近似できます。すなわち、\\(100 \\times \\Delta \\ln X_t \\approx 100 \\times \\Delta X_t / X_{t-1}\\)です。この\\(100 \\times \\Delta \\ln X_t\\)を対数階差変化率と呼びます。 被説明変数と説明変数がともに変化率もしくは対数階差変化率のとき、係数\\(\\beta_1\\)は、説明変数（変化率）が1％ポイント変化したときに、被説明変数（変化率）が\\(\\beta_1\\)％ポイント変化することを示します。なお、このときの係数\\(\\beta_1\\)は、対数モデルの係数の解釈である弾力性とは全く異なるものである点に注意してください。 多項式モデル \\[ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + u \\] 多項式の推定式では、説明変数\\(X\\)が入る項が複数あるため、\\(\\beta_1\\)、\\(\\beta_2\\)単独では\\(X\\)の変化による\\(Y\\)への影響を測ることができません。\\(X\\)の変化による\\(Y\\)への影響は、右辺を\\(X\\)で微分した結果である \\[ \\frac{\\partial(\\beta_0 + \\beta_1 X + \\beta_2 X^2)}{\\partial X} = \\beta_1 + 2 \\beta_2 X \\] で表されます。これを限界効果と呼びます。ただし、限界効果の大きさは\\(X\\)の値に依存するので、一定ではありません。そこで、限界効果の\\(X\\)を\\(X\\)の平均値\\(\\overline{X}\\)で置き換えた平均限界効果\\(\\beta_1 + 2 \\beta_2 \\overline{X}\\)も、\\(X\\)の変化による\\(Y\\)への影響を測る値をして使用されます。 なお、上記の例では、限界効果がゼロ、すなわち\\(\\beta_1 + 2 \\beta_2 X = 0\\)とおいて、\\(X\\)について解くと、\\(X = -\\beta_1 / 2 \\beta_2\\)が\\(Y\\)を最大もしくは最小にする\\(X\\)の値であることが計算できます。 交互作用モデル \\[ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_1 X_2 + u \\] 交互作用モデルには、複数の変数の掛け算である交差項（ここでは\\(X_1 X_2\\)）が入っています。これは、説明変数\\(X_1\\)と\\(X_2\\)が互いに影響しながら相乗効果として被説明変数\\(Y\\)に影響するメカニズムを捉えています。 例えば、被説明変数\\(Y\\)が給与額、説明変数\\(X_1\\)と\\(X_2\\)がそれぞれ教育年数と勤続年数の交互作用モデルを推定すると、給与額は教育年数、勤続年数それぞれ単独の影響だけでなく、教育年数と勤続年数の相乗効果の影響も受けることを想定していることになります（山本（2015）P.40）。 上記の交互作用モデルにおける説明変数\\(X_1\\)の限界効果は\\(\\beta_1 + \\beta_3 X_2\\)、平均限界効果は\\(\\beta_1 + \\beta_3 \\overline{X_2}\\)となります。 ダミー変数 切片ダミーの場合 \\[ Y = \\beta_0 + \\beta_1 D + \\beta_2 X + u \\] 切片ダミーは、データの属性を区別するダミー変数\\(D\\)が単独の項として推定式に入っているモデルであり、被説明変数\\(Y\\)の平均的な水準がデータの属性により異なるメカニズムを捉えます。 例えば、被説明変数\\(Y\\)が給与額、説明変数\\(X\\)が勤続年数のモデルで、男性なら1、女性なら0をとる「男性ダミー変数」\\(D\\)を考えます。このとき、男性の給与額は\\(Y = (\\beta_0 + \\beta_1) + \\beta_2 X\\)、女性の給与額は\\(Y = \\beta_0 + \\beta_2 X\\)で表されるため、男性ダミー\\(D\\)の係数\\(\\beta_1\\)は給与額の男性プレミアム（またはディスカウント）を捉えたものと解釈できます。 なお、「男性ダミー変数」\\(D\\)の係数\\(\\beta_1\\)が捉えているのは、比較の基準である女性の給与額との差であり、男性の給与額の絶対的な水準を示すものではありません。また、\\(\\beta_1\\)は比較の基準である女性の給与額に関する情報は一切もっていません。 傾きダミーの場合 \\[ Y = \\beta_0 + \\beta_1 X + \\beta_2 D X+ u \\] 傾きダミーは、ダミー変数\\(D\\)が説明変数\\(X\\)との交差項として推定式に入っているモデルであり、説明変数\\(X\\)の影響が属性により異なるメカニズムを捉えます。 例えば、被説明変数\\(Y\\)が給与額、説明変数\\(X\\)が勤続年数のモデルで、男性なら1、女性なら0をとる「男性ダミー変数」\\(D\\)を考えます。このとき、男性の給与額は\\(Y = \\beta_0 + (\\beta_1 + \\beta_2) X\\)、女性の給与額は\\(Y = \\beta_0 + \\beta_1 X\\)で表されるため、男性ダミー\\(D\\)の係数\\(\\beta_2\\)は給与額に対する勤続年数の効果を増幅（または縮小）させる影響を捉えたものと解釈できます。 なお、「男性ダミー変数」\\(D\\)の係数\\(\\beta_2\\)が捉えているのは、比較の基準である女性の勤続年数効果との差であり、男性の勤続年数効果を示すものではありません。また、\\(\\beta_2\\)は比較の基準である女性の勤続年数効果に関する情報は一切もっていません。 7.5 重回帰モデルの注意点 重回帰モデルは、次のように説明変数を2つ以上もつ回帰モデルのことです。 \\[ Y_i = \\beta_0 + \\beta_1X_{1i} + \\beta_2X_{2i} + \\dots + \\beta_kX_{ki} + u_i \\quad (i = 1,\\, \\ldots,\\, n) \\] 欠落変数バイアス 重回帰モデルを使用する主な目的は、最小2乗法の仮定3「説明変数と誤差項が無相関」が成立しない原因の一つである欠落変数バイアス（omitted variable bias）に対処するためです。 欠落変数バイアスは、被説明変数\\(Y_i\\)に影響を及ぼす変数を説明変数に含んでいないことによって起こります。こうした変数を交絡因子（confounding factor）と呼びます。 重回帰分析では、交絡因子の可能性がある変数を説明変数に追加し、欠落変数バイアスの問題を回避します。この作業をコントロールと呼び、追加される変数をコントロール変数と言います。コントロール変数は欠落変数バイアスを回避するためにモデルに追加されるため、コントロール変数が被説明変数に与える影響を推定することは主たる目的ではありません。 多重共線性 多重共線性には2つのケースがあります。 一つは完全な多重共線性（perfect multicollinearity）で、ある説明変数が他の説明変数の線形和によって表される場合が該当します。このとき、最小2乗推定量が一意に定まらないため、推定不能になります。 もう一つは不完全な多重共線性で、説明変数間に強い相関がある場合が該当します。一般的に多重共線性というときはこちらを差すことが多いでしょう。多重共線性が発生すると、推定量の分散が大きくなり、係数の正確な推定が困難になります。 多重共線性には有効な解決策はありません。重回帰モデルでは欠落変数バイアスを回避するためにコントロール変数を追加していることが多く、多重共線性に対処するためにコントロール変数を除外すれば、欠落変数バイアスを回避することができなくなるためです。 末石（2015）P.18では、「明らかに不要な説明変数が入っているときは別として、多重共線性をなくそうとあれこれと工夫をするよりも、多くの場合は放置しておくのが無難」、「多重共線性はないに越したことはないが、完全な多重共線性とは異なり、論理的な欠陥ではない」、「推定量の分散は大きくなるが、それは標準誤差に反映されるので、検定をしたり信頼区間を求める際には、特に問題にならない」としています。 変数選択の指針 ここでは、重回帰分析にとって重要な「どの変数を推定式に含めるべきか」について解説します。詳細は西山 他（2019）P.185を参照してください。 1. 欠落変数バイアスを避けられるか 興味がある説明変数が被説明変数に与える影響を正しく推定するためには、その説明変数と相関し、かつ被説明変数に影響を与える変数をコントロール変数として回帰モデルに含める必要があります。コントロール変数について注意すべき点は次の通りです。 コントロール変数は分析対象として興味がなくても良い。 興味のある説明変数と無関係なコントロール変数を入れる必要はない。 コントロール変数に関する欠落変数バイアスを考慮する必要はない。 コントロール変数の係数は一致推定できず、係数の解釈は困難である（符号条件などが直感に反する結果でも気にする必要はない）。 2. 興味のある説明変数の影響の解釈が変わりうるか 重回帰分析では、モデルにどの変数を入れるかによって、係数の解釈が変わりえます。特に、興味ある説明変数が被説明変数に影響を与える経路の中間にある変数（中間経路の変数）をモデルに含めると、係数が本来の研究対象とは異なる解釈を持つ可能性があります。これを過剰制御と呼びます。 例えば、被説明変数を賃金、興味がある説明変数を教育として、教育が賃金に与える影響を分析する場合を考えます。ここで、変数として職業を入れると、職業は教育が賃金に影響を与える経路の中間に位置します。この時、教育の係数は、職業を固定した場合に教育の変化が賃金に与える影響を表すと解釈できますが、教育の変化は職業の変化を通じて賃金にも影響すると想定されるため、教育の係数は教育が賃金に与える影響すべてを捉えることができなくなります。 3. 推定量の分散を小さくできるか 重回帰モデルに変数を追加する場合、興味がある説明変数と相関している変数を追加すると、興味がある説明変数の係数の推定精度が悪化します。一方で、被説明変数に影響を与える変数を追加すると、モデルの推定誤差が改善します。このように、変数の追加にはトレードオフがあります。 1～3のどの基準を優先すべきか 重回帰分析をどのような目的で用いるかによって、変数選択の際に優先すべき基準が変化します。 興味がある説明変数の係数を推定する場合： 欠落変数バイアスの回避（1）と、説明変数の影響の解釈（2）を優先すべきで、推定量の分散（3）は副次的な問題になります。 被説明変数の予測を行う場合： モデルの推定誤差を減少させること（3）を優先すべきで、欠落変数バイアスの回避（1）や、説明変数の影響の解釈（2）は副次的な問題になります。 7.6 Rの単回帰モデル推定 線形単回帰モデル\\(Y = \\beta_0 + \\beta_1 X + u\\)を最小2乗法で推定するには、estimatrパッケージのlm_robust()関数でformula引数をY ~ Xと設定します。 se_type引数は計算する標準誤差の種類を指定します。classicalを指定すると均一分散を仮定した標準誤差を使用しますが、上記の通り経済データは不均一分散であることが一般的であるため、不均一分散に頑健な標準誤差（ホワイトの標準誤差）のHC1か、デフォルトのHC2を使用するとよいでしょう。se_type引数の指定方法に関する数学的な解説は、公式ウェブサイトを参照してください。 lm_robust()関数が返すオブジェクトをsummary()関数で出力すると、係数の推定値、標準誤差、t値、p値、信頼区間の下限・上限値、決定係数、F検定の結果が表示されます。 実証例4.1 線形単回帰 西山 他（2019）P.128～129の実証例4.1のデータを用い、実質賃金（wage）を被説明変数、労働生産性（productivity）を説明変数として、線形単回帰モデルを推定します。標準誤差はse_type = \"HC1\"と設定し、不均一分散に対して頑健な標準誤差（ホワイトの標準誤差）を使用します。 この結果は、\\(実質賃金の推定量 = 276.13 + 0.55\\,労働生産性\\) を意味しており、定数項と労働生産性の係数はどちらもp値が0.05より小さく、有意水準5％で帰無仮説が棄却されます。この結果から、統計的には労働生産性が100円上昇すると賃金が55円上がる傾向があると解釈できます。 # CSVデータを読み込み data &lt;- readr::read_csv(file = &quot;data_nishiyama/ch04/ch04_wage.csv&quot;, col_names = TRUE, col_types = &quot;ddd&quot;, skip = 0) # GGally::ggpairs()関数でペアプロットを出力 data %&gt;% dplyr::select(productivity, wage) %&gt;% GGally::ggpairs() # estimatr::lm_robust()関数でwageをproductivityに回帰 result &lt;- estimatr::lm_robust(formula = wage ~ productivity, data = data, se_type = &quot;HC1&quot;, # 標準誤差の設定（classical, HC0, HC1, HC2, HC3, CR0, CR2） alpha = 0.05) # 有意水準 # 回帰した結果を出力 summary(result) ## ## Call: ## estimatr::lm_robust(formula = wage ~ productivity, data = data, ## se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 276.1296 71.25559 3.875 1.019e-03 126.990 425.2693 19 ## productivity 0.5468 0.02046 26.722 1.553e-16 0.504 0.5896 19 ## ## Multiple R-squared: 0.9635 , Adjusted R-squared: 0.9616 ## F-statistic: 714.1 on 1 and 19 DF, p-value: &lt; 2.2e-16 # 回帰した結果をデータフレーム形式で出力 estimatr::tidy(result) ## term estimate std.error statistic p.value conf.low ## 1 (Intercept) 276.1296070 71.25558981 3.875199 1.018919e-03 126.9899435 ## 2 productivity 0.5468196 0.02046305 26.722296 1.553174e-16 0.5039899 ## conf.high df outcome ## 1 425.2692704 19 wage ## 2 0.5896492 19 wage 対数・変化率モデルの推定 実証例4.1のデータセットを利用して、両辺が自然対数のモデル、両辺が対数階差変化率のモデル、両辺が変化率のモデルを推定します。 自然対数はlog()関数で計算します。対数階差変化率は対数変換した値にtidyquant::CHANGE()関数を適用して対数階差を計算します。変化率はtidyquant::PCT_CHANGE()関数で求めることができます。 # 自然対数、対数階差変化率、変化率を計算 data %&lt;&gt;% dplyr::mutate(ln_wage = log(wage), ln_productivity = log(productivity), dlog_wage = 100 * tidyquant::CHANGE(ln_wage), dlog_productivity = 100 * tidyquant::CHANGE(ln_productivity), pch_wage = 100 * tidyquant::PCT_CHANGE(wage), pch_productivity = 100 * tidyquant::PCT_CHANGE(productivity)) 対数モデルにおける労働生産性の係数0.874は、労働生産性が1％変化すると実質賃金が0.874％変化することを示しています（弾性値）。また、同係数のp値は0.05を下回っており、統計的に有意であるといえます。 # 対数モデル result &lt;- estimatr::lm_robust(formula = ln_wage ~ ln_productivity, data = data, se_type = &quot;HC1&quot;, # 標準誤差の設定（classical, HC0, HC1, HC2, HC3, CR0, CR2） alpha = 0.05) # 有意水準 summary(result) ## ## Call: ## estimatr::lm_robust(formula = ln_wage ~ ln_productivity, data = data, ## se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 0.5576 0.26022 2.143 4.530e-02 0.01292 1.102 19 ## ln_productivity 0.8742 0.03191 27.397 9.782e-17 0.80745 0.941 19 ## ## Multiple R-squared: 0.9649 , Adjusted R-squared: 0.9631 ## F-statistic: 750.6 on 1 and 19 DF, p-value: &lt; 2.2e-16 対数階差変化率は変化率の近似値なので、対数階差変化率モデルと変化率モデルはほぼ同じ推定結果になります。労働生産性の係数のp値はどちらも0.05を上回っており、有意ではありません。 # 対数階差変化率モデル result &lt;- estimatr::lm_robust(formula = dlog_wage ~ dlog_productivity, data = data, se_type = &quot;HC1&quot;, # 標準誤差の設定（classical, HC0, HC1, HC2, HC3, CR0, CR2） alpha = 0.05) # 有意水準 summary(result) ## ## Call: ## estimatr::lm_robust(formula = dlog_wage ~ dlog_productivity, ## data = data, se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 0.7637 0.2900 2.633 0.01687 0.1544 1.3730 18 ## dlog_productivity 0.2251 0.1791 1.257 0.22497 -0.1512 0.6014 18 ## ## Multiple R-squared: 0.1154 , Adjusted R-squared: 0.06623 ## F-statistic: 1.579 on 1 and 18 DF, p-value: 0.225 # 変化率モデル result &lt;- estimatr::lm_robust(formula = pch_wage ~ pch_productivity, data = data, se_type = &quot;HC1&quot;, # 標準誤差の設定（classical, HC0, HC1, HC2, HC3, CR0, CR2） alpha = 0.05) # 有意水準 summary(result) ## ## Call: ## estimatr::lm_robust(formula = pch_wage ~ pch_productivity, data = data, ## se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 0.7725 0.2940 2.627 0.01708 0.1548 1.3902 18 ## pch_productivity 0.2225 0.1801 1.236 0.23247 -0.1558 0.6009 18 ## ## Multiple R-squared: 0.1121 , Adjusted R-squared: 0.06276 ## F-statistic: 1.527 on 1 and 18 DF, p-value: 0.2325 7.7 Rの重回帰モデル推定 重回帰モデルも、単回帰モデルと同様にestimatrパッケージのlm_robust()関数で推定します。重回帰モデルの場合は、formula引数にY ~ X1 + X2といった形で複数の説明変数を設定します。 実証例5.1・5.4 線形重回帰 西山 他（2019）P.151～152の都道府県別データを用い、信頼関係の強さと規範意識が経済成長に与える影響を、教育水準と初期時点での豊かさをコントロールして推定します。使用する変数は次の通りです。詳細は、西山 他（2019）第5章の9節（P.191）と補論A（P.203）を参照してください。 y80： 1980年時点の人口1人当たりGDP（100万円） y99： 1999年時点の人口1人当たりGDP（100万円） trust80： 1980年時点の信頼関係の強さ（標準化した値） norm80： 1980年時点の規範意識の強さ（標準化した値） education80： 1980年時点の教育水準（標準化した値） did： 人口集中地区に居住する人口の割合 # CSVデータを読み込み data &lt;- readr::read_csv(file = &quot;data_nishiyama/ch05/youdou.csv&quot;, col_names = TRUE, col_types = NULL, skip = 0) ## Rows: 47 Columns: 23 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## dbl (22): id, y80, y90, y99, education80, trust80, trust96, norm80, norm96, ... ## lgl (1): X ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. # 西山 他（2019）P.143～144に従い、各都道府県の人口1人当たりGDPの年平均経済成長率を計算 data %&lt;&gt;% dplyr::mutate(ln_y80 = log(y80), ln_y99 = log(y99), gr_80_99 = 100 * (ln_y99 - ln_y80) / 19) # GGally::ggpairs()関数でペアプロットを出力 data %&gt;% dplyr::select(gr_80_99, trust80, norm80, education80, ln_y80, ln_y99, did) %&gt;% GGally::ggpairs() まず、1980～1999年の年平均経済成長率を、信頼関係の強さと規範意識それぞれで説明する単回帰モデルを推定します。 これらモデルは、信頼関係の強さと規範意識の係数のp値がともに0.05より小さく、係数が有意であることを示しています。 result &lt;- estimatr::lm_robust(formula = gr_80_99 ~ trust80, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) summary(result) ## ## Call: ## estimatr::lm_robust(formula = gr_80_99 ~ trust80, data = data, ## se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 3.1394 0.06044 51.943 8.188e-42 3.01763 3.2611 45 ## trust80 0.2247 0.06640 3.384 1.491e-03 0.09094 0.3584 45 ## ## Multiple R-squared: 0.179 , Adjusted R-squared: 0.1608 ## F-statistic: 11.45 on 1 and 45 DF, p-value: 0.001491 result &lt;- estimatr::lm_robust(formula = gr_80_99 ~ norm80, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) summary(result) ## ## Call: ## estimatr::lm_robust(formula = gr_80_99 ~ norm80, data = data, ## se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 3.0905 0.04826 64.033 7.544e-46 2.9933 3.1878 45 ## norm80 0.5597 0.07058 7.931 4.348e-10 0.4176 0.7019 45 ## ## Multiple R-squared: 0.4563 , Adjusted R-squared: 0.4442 ## F-statistic: 62.9 on 1 and 45 DF, p-value: 4.348e-10 次に、説明変数に、教育水準と、豊かさの代理変数として1980年時点の対数GDP水準を追加した重回帰モデルを推定します。 信頼関係の強さの係数の推定値は、単回帰モデルの0.22から0.02へと大幅に低下していることが確認できます。単回帰モデルでは、教育水準や豊かさが経済成長率に与える影響が、誤って信頼関係の強さの影響として推定されていた可能性が示唆されます。また、信頼関係の強さの係数のp値は0.79と大きく、係数は有意ではありません。 result &lt;- estimatr::lm_robust(formula = gr_80_99 ~ trust80 + education80 + ln_y80, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) summary(result) ## ## Call: ## estimatr::lm_robust(formula = gr_80_99 ~ trust80 + education80 + ## ln_y80, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 6.04885 0.42643 14.1849 8.041e-18 5.189 6.9088 43 ## trust80 0.02058 0.07564 0.2721 7.868e-01 -0.132 0.1731 43 ## education80 2.61208 2.70857 0.9644 3.403e-01 -2.850 8.0744 43 ## ln_y80 -2.38309 0.49147 -4.8489 1.658e-05 -3.374 -1.3920 43 ## ## Multiple R-squared: 0.5619 , Adjusted R-squared: 0.5313 ## F-statistic: 20.21 on 3 and 43 DF, p-value: 2.531e-08 一方、規範意識の係数の推定値は重回帰モデルでも0.34と小さくなく、経済学的に意味のある結果（規範意識は経済成長率にとって重要な要素）であると考えられます。また係数のp値は0.018と、有意水準5％で統計的に有意であるといえます。 result &lt;- estimatr::lm_robust(formula = gr_80_99 ~ norm80 + education80 + ln_y80, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) summary(result) ## ## Call: ## estimatr::lm_robust(formula = gr_80_99 ~ norm80 + education80 + ## ln_y80, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 5.2909 0.6682 7.918 6.204e-10 3.94324 6.6385 43 ## norm80 0.3383 0.1370 2.469 1.758e-02 0.06202 0.6145 43 ## education80 4.3872 1.9611 2.237 3.051e-02 0.43233 8.3421 43 ## ln_y80 -1.9911 0.5746 -3.465 1.213e-03 -3.14987 -0.8324 43 ## ## Multiple R-squared: 0.6391 , Adjusted R-squared: 0.614 ## F-statistic: 41.04 on 3 and 43 DF, p-value: 1.11e-12 実証例5.5 多項式モデル 1980～1999年の年平均経済成長率を、1980年時点のGDP水準（対数をとらない値）の2次多項式で説明するモデルを推定します。 2乗の項は、あらかじめdplyr::mutate()関数などを使用して計算しておくか、もしくはI(変数 ^ 2)としてlm_robust()関数の回帰式に含めます。 推定結果は、1980年時点GDPの項、その2乗項ともに係数のp値が0.05より大きく、有意ではありません。ただし、それだけでは1980年時点GDPが経済成長率に影響を与えるかどうかは判断できません。判断するためには、1980年時点GDPの項と2乗項の係数がどちらも同時にゼロであるという結合仮説をF検定する必要があります。 推定結果においてF検定のp値をみると0.05より小さく、「1980年時点GDPの項と2乗項の係数がどちらも同時にゼロ（＝1980年時点GDPの影響はない）」という帰無仮説が棄却されます。 result &lt;- estimatr::lm_robust(formula = gr_80_99 ~ y80 + I(y80 ^ 2), data = data, se_type = &quot;HC1&quot;, alpha = 0.05) summary(result) ## ## Call: ## estimatr::lm_robust(formula = gr_80_99 ~ y80 + I(y80^2), data = data, ## se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 6.51866 1.38538 4.705 2.535e-05 3.72662 9.3107 44 ## y80 -1.22615 0.70791 -1.732 9.027e-02 -2.65285 0.2005 44 ## I(y80^2) 0.08935 0.08861 1.008 3.188e-01 -0.08923 0.2679 44 ## ## Multiple R-squared: 0.5503 , Adjusted R-squared: 0.5299 ## F-statistic: 27.39 on 2 and 44 DF, p-value: 1.879e-08 なお、推定結果から、限界効果は\\(-1.226 + 2 \\times0.089 \\times 1980年時点GDP\\)と計算できます。平均限界効果は、1980年時点GDPの平均値が3.876なので、\\(-1.226 + 2 \\times0.089 \\times 3.876 \\approx -0.536\\)となります。 # 平均限界効果の計算 result$coefficients[&quot;y80&quot;] + 2 * result$coefficients[&quot;I(y80^2)&quot;] * mean(data$y80) ## y80 ## -0.5335568 # 多項式モデルを推定した回帰曲線をプロット data %&gt;% dplyr::mutate(fitted = result$fitted.values) %&gt;% ggplot() + geom_point(mapping = aes(x = y80, y = gr_80_99)) + geom_line(mapping = aes(x = y80, y = fitted)) 実証例5.6 ダミー・交互作用モデル 1980～1999年の年平均経済成長率を、1980年時点の対数GDP水準で説明するモデルに、切片ダミー変数と傾きダミー変数を追加します。 追加するダミー変数は、人口集中地区に居住する割合を示す変数（did）が0.4より大きいときに1をとる「都市化ダミー」です。 # 都市化ダミー変数を追加 data %&lt;&gt;% dplyr::mutate(dummy_1 = 1 * (did &gt; 0.4)) 傾きダミー変数と1980年時点の対数GDP水準の交差項は、dummy * ln_y80としてlm_robust()関数の回帰式に含めます。 推定結果をみると、切片ダミーの係数は-0.176、傾きダミーの係数は0.064となっていますが、p値はどちらも0.05より大きく有意ではありません。 なお、1980年時点の対数GDP水準の係数-1.911は、1980年時点のGDPが1％増加すると、1980～1999年の年平均経済成長率が1.911％ポイント低下することを意味しています。 result &lt;- estimatr::lm_robust(formula = gr_80_99 ~ dummy_1 + ln_y80 + dummy_1 * ln_y80, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) summary(result) ## ## Call: ## estimatr::lm_robust(formula = gr_80_99 ~ dummy_1 + ln_y80 + dummy_1 * ## ln_y80, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 5.74905 0.8019 7.1692 7.325e-09 4.132 7.3663 43 ## dummy_1 -0.17551 0.9498 -0.1848 8.543e-01 -2.091 1.7399 43 ## ln_y80 -1.91120 0.6545 -2.9199 5.554e-03 -3.231 -0.5912 43 ## dummy_1:ln_y80 0.06441 0.7481 0.0861 9.318e-01 -1.444 1.5730 43 ## ## Multiple R-squared: 0.5564 , Adjusted R-squared: 0.5254 ## F-statistic: 20.39 on 3 and 43 DF, p-value: 2.26e-08 実証例5.7 ダミー・交互作用モデル 1980～1999年の年平均経済成長率を、実証例5.6で作成した都市化ダミー変数と、1980年時点の対数GDP水準が1.4より大きい場合に1をとる「豊かさダミー変数」で説明するモデルを推定します。 # 豊かさダミー変数を追加 data %&lt;&gt;% dplyr::mutate(dummy_2 = 1 * (ln_y80 &gt; 1.4)) result &lt;- estimatr::lm_robust(formula = gr_80_99 ~ dummy_1 + dummy_2 + dummy_1 * dummy_2, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) summary(result) ## ## Call: ## estimatr::lm_robust(formula = gr_80_99 ~ dummy_1 + dummy_2 + ## dummy_1 * dummy_2, data = data, se_type = &quot;HC1&quot;, alpha = 0.05) ## ## Standard error type: HC1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## (Intercept) 3.45474 0.07453 46.3533 2.398e-38 3.3044 3.605044 43 ## dummy_1 -0.23329 0.11212 -2.0808 4.345e-02 -0.4594 -0.007186 43 ## dummy_2 -0.58003 0.20057 -2.8919 5.985e-03 -0.9845 -0.175540 43 ## dummy_1:dummy_2 0.04725 0.23525 0.2009 8.418e-01 -0.4272 0.521687 43 ## ## Multiple R-squared: 0.4982 , Adjusted R-squared: 0.4631 ## F-statistic: 15.3 on 3 and 43 DF, p-value: 6.445e-07 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
