# 時系列データ操作

第4章「時系列データ操作」では、時系列データに特有の操作方法について解説します。時系列データ特有の操作とは、変化率やラグなどのデータ変換、日次・月次などの頻度変換、季節調整、トレンド抽出などです。

Rで時系列データを扱う方法には、主に次の2つがあります。

まず、第3章で使用した**tibble型**です。tibble型は複数の列を含むデータフレームの形状をしており、データそのものを格納する列と、日付型データを格納する列を組み合わせることで、時系列データを扱います。

もう一つは**ts型**です。ts型はデータと日付があらかじめセットになった一次元のデータ構造で、季節調整を行う`seasonal`パッケージなどで使用されます。

## パッケージのインポート

```{r}
library(forecast)
library(mgcv)
library(pbapply)
library(seasonal)
library(seasonalview)
```

## データ変換

ここでは、時系列データのラグ・リード系列、変化率、移動平均を計算する方法を解説します。

まず、Our World in DataのCOVID-19データセット`data_owid`から使用するサンプルデータを作成します。

```{r}
data_owid_jp <- data_owid %>% 
  dplyr::select(location, date, new_cases, new_deaths) %>% 
  dplyr::filter(location == "Japan",
                date >= "2022-01-01")
```

### ラグ・リード系列の作成 {.unnumbered}

`dplyr::lag()`関数と`dplyr::leag()`関数で、既存の列のラグ・リード系列を作成します。

```{r}
# 1期ラグの系列を追加
data_owid_jp %>% 
  dplyr::mutate(new_cases_lag = dplyr::lag(new_cases, n = 1)) 
```

### 変化率系列の作成 {.unnumbered}

`dplyr::lag()`関数で、既存の列の変化率系列を作成します。

```{r}
# 前期比変化率（％表示）の系列を追加
data_owid_jp %>% 
  dplyr::mutate(new_cases_chg = 100 * (new_cases / dplyr::lag(new_cases, n = 1) - 1)) 
```

### 移動平均系列の作成 {.unnumbered}

`zoo::rollmean()`関数で、移動平均系列を作成します。

```{r}
# 後方7日移動平均の系列を追加
data_owid_jp %>% 
  dplyr::mutate(new_cases_7dma = zoo::rollmean(new_cases, # 移動平均を作成するもとの系列名
                                               k = 7, # 移動平均の期間
                                               na.pad = TRUE, # 系列の先端部分で移動平均を計算できない箇所をNAで埋めるか
                                               align = "right")) # left：前方移動平均、center：中央移動平均、right：後方移動平均
```

## 時系列データの頻度変換

`tidyverse`と整合性がある金融時系列データ分析用のパッケージである`tidyquant`パッケージの`tq_transmute()`関数を用いて、時系列データの頻度変換（高頻度データから低頻度データへの変換）を行います。

なお、`tidyquant`は頻度変換以外にも様々な分析機能があります。詳しくは[公式ウェブサイト](https://business-science.github.io/tidyquant/)を参照してください。

まず、Our World in DataのCOVID-19データセット`data_owid`から、使用するサンプルデータを作成します。`tq_transmute()`関数にわたす時系列データは、原則として横型データである点に留意してください。

```{r}
# サンプルデータ（日次）
data_owid_cases_wide <- data_owid %>% 
  dplyr::select(location, date, new_cases) %>% 
  dplyr::filter(date >= "2021-01-01") %>% 
  dplyr::arrange(date) %>% 
  tidyr::pivot_wider(id_cols = "date", names_from = "location", values_from = "new_cases")
```

### 日次データを週次データに変換 {.unnumbered}

`tidyquant::tq_transmute()`関数を使用して日次データを週次データに変換すると、月曜～日曜のデータが`FUN`に指定した関数で集計され、日曜の日付で記録されます。

```{r}
data_owid_cases_wide %>% 
  tidyquant::tq_transmute(select = -date, mutate_fun = apply.weekly, FUN = mean, na.rm = TRUE)
```

なお、日曜～土曜のデータを集計し日曜の日付で記録したい場合は、`rollmean()`関数を使用して前方7日移動平均を計算し、日曜の値を抽出します。

```{r}
data_owid_cases_wide %>%
  dplyr::mutate(across(-date, rollmean, k = 7, na.pad = TRUE, align = "left")) %>% 
  dplyr::filter(lubridate::wday(date) == 1)
```

### 日次データを月次データに変換 {.unnumbered}

`tidyquant::tq_transmute()`関数を使用して日次データを月次データに変換すると、月初～月末のデータが`FUN`に指定した関数で集計され、月末の日付で記録されます。

```{r}
data_owid_cases_wide %>% 
  tidyquant::tq_transmute(select = -date, mutate_fun = apply.monthly, FUN = mean, na.rm = TRUE)
```

### 日次データを四半期データに変換 {.unnumbered}

`tidyquant::tq_transmute()`関数を使用して日次データを四半期データに変換すると、期初～期末のデータが`FUN`に指定した関数で集計され、期末の日付で記録されます。

```{r}
data_owid_cases_wide %>% 
  tidyquant::tq_transmute(select = -date, mutate_fun = apply.quarterly, FUN = mean, na.rm = TRUE)
```

## 季節調整（X-13）

ここでは、`seasonal`パッケージを用いた時系列データへの季節調整方法について解説します。

`seasonal`パッケージでは、米国商務省センサス局が開発したX-13ARIMA-SEATSを用いて、ts型の月次データ、四半期データ、半期データに対し季節調整を適用することができます。

`seasonal`パッケージや、X-13ARIMA-SEATSの詳細については、[Sax and Eddelbuettel ](https://cran.r-project.org/web/packages/seasonal/vignettes/seas.pdf)や、[奥本 (2016) ](https://opac.ll.chiba-u.jp/da/curator/900119389/09127216_30_4_1-42.pdf)を参照してください。

サンプルデータとして、ts型データである`seasonal::unemp`データセットを用い、`seasonal`パッケージの使用方法を確認します。

### ts型データの可視化

季節調整の前に、データを確認します。ts型データは`plot()`関数で可視化できます。

```{r}
plot(seasonal::unemp)
```

### X-13ARIMA-SEATSの実施方法 {-}

`seasonal`パッケージでは、`seas()`関数を使用してts型データにX-13ARIMA-SEATSを適用します。`seas()`関数は、季節調整の結果を格納したseas型のオブジェクトを返します。

```{r}
# seas()関数で季節調整を実行
m <- seasonal::seas(x = seasonal::unemp)

# 季節調整の結果を出力
summary(m)
```

`plot()`関数で、現数値と季節調整値を可視化できます。黒色の線が原数値、赤色の線が季節調整値です。外れ値がある場合はグラフ中に外れ値が表示されます。

```{r}
plot(m)
```

季節調整値を出力するには、`seasonal::final()`関数を使用します。

```{r}
# 季節調整値をunemp_saに格納
unemp_sa <- seasonal::final(m)

# unemp_saの折れ線グラフを作成
plot(unemp_sa, type = "l")
```

`monthplot()`関数を使用すると、季節変動（Seasonal component）と不規則変動（Seasonal irregular component）を月別に確認することができます。

```{r}
monthplot(m)
```

### 実例：月次データの季節調整 {-}

ここでは、日本の産業別就業者数データセット`data_labor`に対し、月次の季節調整を適用します。`data_labor`はtibble形式のデータフレームの中に、日付型の列と、複数の数値型のデータ列が格納されています。

1. tibble形式のデータフレームに格納されている数値型データをts型データに変換する
2. tibble形式のデータフレームをリスト形式に変換する
3. `pblapply()`で一括して`seas()`関数の季節調整を適用する。季節調整エラーは`try()`関数で処理する
4. 季節調整エラーを取得する
5. 季節調整値を取得する
6. エラーが生じた系列は原数値を取得する

```{r}
# data_laborから一部を抽出
data_labor_nsa <- data_labor %>% 
  dplyr::select(date, `総数`, `製造`, `卸・小売`)

# 数値型データをts型データに変換
data_labor_ts <- data_labor_nsa %>% 
  dplyr::select(-date) %>% 
  ts(frequency = 12, # 月次データの場合は12を指定
     start = c(lubridate::year(data_labor$date[1]), lubridate::month(data_labor$date[1]))) # データ開始年月を指定

# tibble形式をリスト形式に変換
data_labor_ts %<>% 
  as.list()

# pblapply()関数で一括してseas()関数の季節調整を適用
# 季節調整でエラーが発生する可能性があるため、try()関数でエラー処理を行う
result <- pblapply(data_labor_ts,
                   function(e) try(suppressMessages(seas(e, transform.function = "auto")),
                                   silent = TRUE))

# 季節調整エラーを取得
result_iserror <- sapply(result, class) == "try-error"

# 季節調整値を取得し、tibble形式データフレームのdata_labor_saに格納
data_labor_sa <- do.call(cbind, lapply(result[!result_iserror], final)) %>% 
  tibble::as_tibble() %>% 
  dplyr::bind_cols(data_labor[, 1], .)

# エラーが生じた系列は原数値を取得してdata_labor_saに追加
for (col in which(result_iserror)) {
  data_labor_sa <- data_labor[, names(result[col])] %>% 
    dplyr::bind_cols(data_labor_sa)
}

# data_labor_saの列をdata_labor_nsaの列順で並べ替え
data_labor_sa %<>% 
  dplyr::select(all_of(names(data_labor_nsa)))
```

個別系列の季節調整結果を可視化するには、`plot()`関数を使用します。一部の系列は季節性がないと判断されるため、季節調整が行われていません。

```{r}
plot(result[[which(names(result) == "総数")]])

plot(result[[which(names(result) == "製造")]])

plot(result[[which(names(result) == "情報通信")]])
```

## 季節調整（STL分解）

X-13ARIMA-SEATSは月次データ、四半期データ、半期データに適用できますが、週次データや日次データには適用できません。そこで、週次データや日次データの季節調整を行うために`stats`パッケージの`stl()`関数によるSTL分解を使用します。

STL分解とは、Seasonal Decomposition of Time Series by Loessの略で、時系列データを季節変動、トレンド変動、不規則変動に分解することができます。

### STL分解の実施方法

STL分解を行うには、`stats`パッケージの`stl()`関数を使用します。`stl()`関数はSTL分解の結果を格納したstl型のオブジェクトを返します。

```{r}
# stl()関数でSTL分解を実行
m <- stats::stl(x = seasonal::unemp,
                s.window = "periodic")

# STL分解の結果を可視化
plot(m)
```

季節調整値を出力するには、`stl()`関数が返すstl型オブジェクトに格納されている`time.series`にアクセスします。`time.series`には、季節変動（`seasonal`）、トレンド変動（`trend`）、不規則変動（`remainder``）の順番にデータが格納されています。

```{r}
# 季節調整値（トレンド）をunemp_saに格納
unemp_sa <- m$time.series[, "trend"]

# unemp_saの折れ線グラフを作成
plot(unemp_sa, type = "l")
```

### 週次データのSTL分解 {-}

STL分解は、`seasonal::unemp`のような月次データだけでなく、より高頻度なデータにも適用できるのが特徴です。

ここでは、週次データである`fpp2::gasoline`データセットに対し、STL分解を適用します。週次データは`ts()`関数における`frequency`引数が52.18となっています。これは、うるう年を考慮した1年の平均日数365.25日を7で割った値であり、週次データは一周期が52.18週であることを示しています。

```{r}
# データの確認
head(fpp2::gasoline)
```

```{r}
# データの可視化
plot(fpp2::gasoline)
```

```{r}
# stl()関数でSTL分解を実行
m <- stats::stl(x = fpp2::gasoline,
                s.window = "periodic")

# STL分解の結果を可視化
plot(m)
```

### 日次データのSTL分解（単一周期） {-}

さらに、STL分解は日次データにも適用可能です。日次データの周期性は通常、週、月、年の3種類あると考えられます。ただし、ts型では一種類の周期性しか指定できないため、ここでは週を一周期に設定し、`ts()`関数の`frequency`引数に7を指定して、STL分解を行います。

使用するデータは、Our World in Dataの新型コロナデータセットにおける、日本の新規感染者数です。

```{r}
# data_owidから日本の新規感染者数（日次）を抽出
data_cases_jp <- data_owid %>% 
  dplyr::filter(location == "Japan") %>% 
  tidyr::drop_na(new_cases) %>%
  dplyr::pull(new_cases)

# 1週＝7日の周期を設定したts型データに変換
data_cases_jp_ts <- data_cases_jp %>% 
  ts(start = c(2020, 1, 22),
     frequency = 7)

# STL分解の結果をmに格納
m <- stats::stl(x = data_cases_jp_ts,
                s.window = "periodic")

# STL分解の結果を可視化
plot(m)
```

### 日次データのSTL分解（複数周期） {-}

データに複数の周期性を設定したい場合は、ts型の拡張版であるmsts型データを用います。msts型データは`forecast`パッケージの`msts()`関数で作成できます。

ここでは、日次データに対し、1週間＝7日と、1年＝365.25日の2種類の周期性を設定しています。

msts型データに対するSTL分解は、`forecast`パッケージの`mstl()`関数を使用します。

```{r}
# data_owidから日本の新規感染者数（日次）を抽出
data_cases_jp <- data_owid %>% 
  dplyr::filter(location == "Japan") %>% 
  tidyr::drop_na(new_cases) %>%
  dplyr::pull(new_cases)

# 1週間＝7日と1年＝365.25日の周期を設定したmsts型データに変換
data_cases_jp_msts <- data_cases_jp %>%  
  forecast::msts(seasonal.period = c(7, 365.25),
                 start = c(2020, 1, 22))

# STL分解の結果をmに格納
m <- forecast::mstl(x = data_cases_jp_ts, s.window = "periodic")

# STL分解の結果を可視化
plot(m)
```

## トレンド推定

### 一般化加法モデル（GAM）

一般化加法モデル（Generalizes Additive Model、GAM）は、線形モデルがもつ解釈性の良さを保ったまま、非線形モデルのような高い説明力を両立させる手法です。

具体的には次のように、被説明変数$Y$を、説明変数$X$を要素とする非線形関数$f(X)$の和として説明するモデルです。非線形関数を用いることにより、説明変数と被説明変数の間の複雑な関係を説明できる一方で、被説明変数がそれぞれの非線形関数の和になっていることで、被説明変数の変動要因を説明変数毎に分解することができ、高い解釈性を維持している点が特徴です。

$$
Y_i = \beta_0 + f_1(X_{1i}) + f_2(X_{2i}) + \dots + f_k(X_{ki}) + u_i
$$

ここでは$X$として時系列インデックスを用いることでトレンドを推定しますが、GAMはトレンド推定以外にも様々な用途に使用可能です。例えば、[服部直樹（2020）「新型コロナウイルス感染症（COVID-19）の感染拡大要因は何か」](https://www.mizuho-rt.co.jp/publication/mhri/research/pdf/report/report20-1021.pdf)では、GAMの拡張版である「交互作用項付き一般化加法モデル（GA2M）」を使用して、新型コロナウイルス感染者数の変動要因の説明を試みています（ただし、同レポートではPythonによるGA2Mの実装を用いています）。

一般化加法モデルは、`mgcv`パッケージの`gam()`関数で推定します。事前に時系列インデックスを作成し、`gem()`関数の`formula`引数で`被説明変数 ~ s(時系列インデックス)`と指定します。

ここでは、`seasonal`パッケージのサンプルデータセット`unemp`（米国の失業者数、原数値）のトレンド推定を行います。

```{r}
# unempデータをベクトル形式に変換してdataに格納
data <- tibble::tibble(
  date = seq(from = as.Date("1990-01-01"), to = as.Date("2016-11-01"), by = "1 month"),
  unemp = seasonal::unemp %>% as.vector()
  )

# dataに時系列インデックスtimeを追加
data %<>% 
  dplyr::mutate(time = seq_along(date))

# GAMでトレンド推定
result <- mgcv::gam(formula = unemp ~ s(time),
                    data = data)

# 推定結果を出力
summary(result)
```


```{r}
data %<>% 
  dplyr::mutate(unemp_fitted = result$fitted.values)

data %>% 
  dplyr::select(date, unemp, unemp_fitted) %>% 
  tidyr::pivot_longer(cols = -date) %>% 
  ggplot(mapping = aes(x = date, y = value, color = name)) +
  geom_line()
```

